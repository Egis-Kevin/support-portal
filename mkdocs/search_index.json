{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to PaperTrail Support Portal", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-papertrail-support-portal", 
            "text": "", 
            "title": "Welcome to PaperTrail Support Portal"
        }, 
        {
            "location": "/Configuration/Backups/", 
            "text": "Backups\n\n\nWhat needs to be backed up?\n\n\n\n\nDatabase\n and transaction logs\n\n\nFile Repository\n (Everything under PT_Repo)\n\n\nSSL Certificate\n e.g. conf/keystore (If configured)\n\n\nEncryption Keys\n e.g. conf/keys.* If File store encryption is\n    configured\n\n\nIndexes\n Only for very large installations where an index rebuild\n    is too time-consuming\n\n\n\n\nHow to backup?\n\n\nTo backup in PostgreSQL \n\n\ncd \nC:\\Program Files\n\ncd PostgreSQL\\9.2\\bin\npg_dump \u2013U postgres \u2013h localhost {postgresdb} \n \u201dC:\\{location}\\{location}{backupname}.sql\u201d\npsql -U postgres -h localhost {pt8} \n C:\\{location}\\{location}{backupname}.restore.sql\n\n\n\n\nTo backup in MySQL \n\n\ncd MySQL\\MySQL Server 5.1\\bin\nC:\\ProgramFiles\\MySQL\\MySQL Server 5.1\\bin\nmysql -u {username} -p {password} {MYSQL db} \n \ne:\\database.sql\n\n\n\n\n\nBackups in MSSQL can be done from the management console.\n\n\nSchedule Database Backups using PaperTrail\n\n\nPapertrail can automatically backup databases on schedule configured\nunder\u00a0Services\u00a0\u00a0\u2192\u00a0Properties\u00a0\u00a0\u2192\u00a0Backup \u2192\u00a0DB Schedule\n(db.backup.schedule).\n\n\nPaperTrail will run the pgdump, mysql_dump or SQL Server Backup\nDatabase command \u00a0and store the result in the file repository.\u00a0\n\n\nNote: Backups can only be made of local database\n\n\nConfiguring cloud backups\n\n\nCloud backups lets you back up the PaperTrail file repository (and\noptionally the PaperTrail database) in near real time to the Amazon S3\ncloud (http://aws.amazon.com/s3/).\n\n\nIf you set up the Amazon S3 account, use the information from that\naccount to configure cloud backups. For Egis managed backups, Egis will\nsupply the information to you.\n\n\n\n\nFrom Services \u00a0\u2192\u00a0\u00a0Tasks\u00a0\u2192\u00a0 Wizards, select Configure cloud backups.\nEnter the values of the Amazon S3 account in these fields:\\\n\n\nBucket\n The Amazon S3 bucket to use, for example:\nacme.papertrail\\\n\n\nAccess key\n An access key that has read and write permissions to\nthe bucket.\\\n\n\nSecret key\n\n\n\n\nConfiguring periodic Windows file share backups\n\n\nPaperTrail creates an incremental backup ZIP file and copies the ZIP\nfile to the specified shared folder.  \n\n\nSpecify these options under the Backup Settings page of the\ninstallation wizard or after installation via Services\u00a0\u2192\u00a0 Tasks\u00a0\u2192\u00a0\nWizards \u00a0\u2192\u00a0\n\n\nConfigure Windows Share backups\n\n\n\n\nHost \u2013 the hostname of the Windows or SMB/CIFS based fileserver\\\n\n\nBackup Dir \u2013 The share and path location (e.g.,\nBackups/Papertrail Relative to the file share, not relative the root\ndirector)\n\n\nUsername and Password if applicable\n\n\n\n\nAd-Hoc Backup\n\n\nTypically, do an ad-hoc backup before you upgrade PaperTrail or before\nyou migrate to a different server.\n\n An ad-hoc backup will export all the files in the repository to a local\nor windows file share location. Multiple ZIP files will be created; a\nlog file for each ZIP file will also be created containing the names of\nthe files in the corresponding ZIP file.  \n\n\nAn ad-hoc backup can be re-run using the same destination path, the\nlogs files will be read and only new files added will be backed up.\n\n1. Under Services \u2192 Tasks \u2192 Backups \u2192 Backup Repository\n\n2. Destination: Local or windows file share\n(\nsmb://user@pass:host/Share/folder\n)\n\n3.\u00a0Optional: Check verify to verify the backup once complete\n\n4.\u00a0Max File Size: Enter a maximum file size. Once a backup file\nreaches this limit (it may not be exact depending on the size of\nindividual files) a new backup file will start.\n\n\nRestoring from backup\n\n\nSelect Restore from Windows File Share or Cloud from the installation\nwizard.\n\n\n3rd Party backup\n\n\n\n\nBackup the database and applicable transaction logs.\n\n\nBackup the PT_Repo directory (defaults to C:\\Data\\PT_Repo).\n\n\n\n\n\n\nNote: PaperTrail does not update files in the PT_Repo directory so once\nbacked up a file does not need to backed-up again.\n\n\n\n\n3.\u00a0\u00a0 \u00a0For large installations the indexes can also be backed up to\ndecrease restore times\n\n Under Services \u00a0\u2192\u00a0Properties \u00a0\u2192\u00a0Backup \u00a0Specify an Index Backup\nSchedule \n Directory\n\n\nNative restore from backup\n\n\n\n\nRestore database and file repository to original locations\n\n\nInstall PaperTrail\n\n\nCheck new installation and enter existing database details", 
            "title": "Backups"
        }, 
        {
            "location": "/Configuration/Backups/#backups", 
            "text": "", 
            "title": "Backups"
        }, 
        {
            "location": "/Configuration/Backups/#what-needs-to-be-backed-up", 
            "text": "Database  and transaction logs  File Repository  (Everything under PT_Repo)  SSL Certificate  e.g. conf/keystore (If configured)  Encryption Keys  e.g. conf/keys.* If File store encryption is\n    configured  Indexes  Only for very large installations where an index rebuild\n    is too time-consuming", 
            "title": "What needs to be backed up?"
        }, 
        {
            "location": "/Configuration/Backups/#how-to-backup", 
            "text": "To backup in PostgreSQL   cd  C:\\Program Files \ncd PostgreSQL\\9.2\\bin\npg_dump \u2013U postgres \u2013h localhost {postgresdb}   \u201dC:\\{location}\\{location}{backupname}.sql\u201d\npsql -U postgres -h localhost {pt8}   C:\\{location}\\{location}{backupname}.restore.sql  To backup in MySQL   cd MySQL\\MySQL Server 5.1\\bin\nC:\\ProgramFiles\\MySQL\\MySQL Server 5.1\\bin mysql -u {username} -p {password} {MYSQL db}    e:\\database.sql   Backups in MSSQL can be done from the management console.", 
            "title": "How to backup?"
        }, 
        {
            "location": "/Configuration/Backups/#schedule-database-backups-using-papertrail", 
            "text": "Papertrail can automatically backup databases on schedule configured\nunder\u00a0Services\u00a0\u00a0\u2192\u00a0Properties\u00a0\u00a0\u2192\u00a0Backup \u2192\u00a0DB Schedule\n(db.backup.schedule).  PaperTrail will run the pgdump, mysql_dump or SQL Server Backup\nDatabase command \u00a0and store the result in the file repository.\u00a0  Note: Backups can only be made of local database", 
            "title": "Schedule Database Backups using PaperTrail"
        }, 
        {
            "location": "/Configuration/Backups/#configuring-cloud-backups", 
            "text": "Cloud backups lets you back up the PaperTrail file repository (and\noptionally the PaperTrail database) in near real time to the Amazon S3\ncloud (http://aws.amazon.com/s3/).  If you set up the Amazon S3 account, use the information from that\naccount to configure cloud backups. For Egis managed backups, Egis will\nsupply the information to you.   From Services \u00a0\u2192\u00a0\u00a0Tasks\u00a0\u2192\u00a0 Wizards, select Configure cloud backups.\nEnter the values of the Amazon S3 account in these fields:\\  Bucket  The Amazon S3 bucket to use, for example:\nacme.papertrail\\  Access key  An access key that has read and write permissions to\nthe bucket.\\  Secret key", 
            "title": "Configuring cloud backups"
        }, 
        {
            "location": "/Configuration/Backups/#configuring-periodic-windows-file-share-backups", 
            "text": "PaperTrail creates an incremental backup ZIP file and copies the ZIP\nfile to the specified shared folder.    Specify these options under the Backup Settings page of the\ninstallation wizard or after installation via Services\u00a0\u2192\u00a0 Tasks\u00a0\u2192\u00a0\nWizards \u00a0\u2192", 
            "title": "Configuring periodic Windows file share backups"
        }, 
        {
            "location": "/Configuration/Backups/#configure-windows-share-backups", 
            "text": "Host \u2013 the hostname of the Windows or SMB/CIFS based fileserver\\  Backup Dir \u2013 The share and path location (e.g.,\nBackups/Papertrail Relative to the file share, not relative the root\ndirector)  Username and Password if applicable", 
            "title": "Configure Windows Share backups"
        }, 
        {
            "location": "/Configuration/Backups/#ad-hoc-backup", 
            "text": "Typically, do an ad-hoc backup before you upgrade PaperTrail or before\nyou migrate to a different server. \n An ad-hoc backup will export all the files in the repository to a local\nor windows file share location. Multiple ZIP files will be created; a\nlog file for each ZIP file will also be created containing the names of\nthe files in the corresponding ZIP file.    An ad-hoc backup can be re-run using the same destination path, the\nlogs files will be read and only new files added will be backed up. \n1. Under Services \u2192 Tasks \u2192 Backups \u2192 Backup Repository \n2. Destination: Local or windows file share\n( smb://user@pass:host/Share/folder ) \n3.\u00a0Optional: Check verify to verify the backup once complete \n4.\u00a0Max File Size: Enter a maximum file size. Once a backup file\nreaches this limit (it may not be exact depending on the size of\nindividual files) a new backup file will start.", 
            "title": "Ad-Hoc Backup"
        }, 
        {
            "location": "/Configuration/Backups/#restoring-from-backup", 
            "text": "Select Restore from Windows File Share or Cloud from the installation\nwizard.", 
            "title": "Restoring from backup"
        }, 
        {
            "location": "/Configuration/Backups/#3rd-party-backup", 
            "text": "Backup the database and applicable transaction logs.  Backup the PT_Repo directory (defaults to C:\\Data\\PT_Repo).    Note: PaperTrail does not update files in the PT_Repo directory so once\nbacked up a file does not need to backed-up again.   3.\u00a0\u00a0 \u00a0For large installations the indexes can also be backed up to\ndecrease restore times \n Under Services \u00a0\u2192\u00a0Properties \u00a0\u2192\u00a0Backup \u00a0Specify an Index Backup\nSchedule   Directory", 
            "title": "3rd Party backup"
        }, 
        {
            "location": "/Configuration/Backups/#native-restore-from-backup", 
            "text": "Restore database and file repository to original locations  Install PaperTrail  Check new installation and enter existing database details", 
            "title": "Native restore from backup"
        }, 
        {
            "location": "/Configuration/Barcode/", 
            "text": "Barcode Recognition Setup\n\n\nSetup an extractFromBarcode rule on at he appropriate node\nInstall the Softek SDK**  Download the latest version from:\n\n\nWindows SDK\nv8.1.2\n\n\nLinux SDK v8.1.2\n\n\nLibraries need to be copied to /usr/lib/java, /usr/lib/ or\nC:\\Windows\\System32 or to where the java.library.path is pointing\\\n\n\nFor a list of all versions goto http://www.bardecode.com/en1/quick-download/ although a different\nlicense may need to be loaded via the License property\n\n\nSupported Barcodes\n\n\n\n\nCodabar also known as Code 2 of 7, Codeabar, Ames Code, NW-7 and Monarch (ReadCodabar)\n\n\nCode 128 Symbol Sets A, B and C (ReadCode128)\n\n\nCode 128 Short Format (ReadShortCode128)\n\n\nCode 2 of 5 Datalogic (ReadCode25ni)\n\n\nCode 2 of 5 Iata1 (ReadCode25ni)\n\n\nCode 2 of 5 Iata2 (ReadCode25ni)\n\n\nCode 2 of 5 Industrial (ReadCode25ni)\n\n\nCode 2 of 5 Interleaved (ReadCode25)\n\n\nCode 2 of 5 Matrix (ReadCode25ni)\n\n\nCode 3 of 9 (ReadCode39)\n\n\nCode 3 of 9 Extended (ReadCode39 and ExtendedCode39)\n\n\nCode 93 (ReadCode93)\n\n\nEAN-8, European Article Number/International Article Number (ReadEAN8)\n\n\nEAN-13 and UPC-A, European Article Number/International Article Number (ReadEAN13)\n\n\nGS1-128, UCC-128, EAN-128 (ReadCode128)\n\n\nGS1-Databar (please see 2-D section below)\n\n\nPatch Code Symbols (ReadPatchCodes)\n\n\nUPC-A, Universal Product Code (ReadEAN13 and ReadUPCA)\n\n\nUPC-E, Universal Product Code (ReadUPCE)\n\n\nQR-Code (ReadQRCode)\n\n\nData Matrix ECC200 sizes 8x8 to 144x144 (ReadDataMatrix)\n\n\nGS1-Databar\n\n\nMicro-PDF-417 (ReadMicroPDF417)\n\n\nPDF-417, Portable Data File (ReadPDF417)\n\n\n\n\nProperties\n\n\nAllowDuplicateValues\n  Barcodes containing the same text on the same\npage\n\n\nBarcodesAtTopOfPage\n  Search from the top of a page downwards\n\n\nCode128Lenient\n  relax some of the requirements for Code 128 barcodes\n\n\nCode25Checksum\n  Code 25 barcodes include checksum character\n\n\nCode25MinLengthOccurrence\n  control for false positive readings for\nCode 25 barcodes\n\n\nCode39Checksum\n  Code 39 barcodes include checksum character\n\n\nCode39MaxRatioPcnt\n  set the max ratio between the wide and narrow\nbars\n\n\nCode39NeedStartStop\n  Require start and stop * characters for a Code\n39 barcode\n\n\nColorProcessingLevel\n  control the amount of processing time spent\nreading barcode values from color images\n\n\nColorThreshold\n  Contrast setting for color images\n\n\nConvertUPCEToEAN13\n  Output UPC-E barcodes in EAN-13 format\n\n\nDatabarOptions\n  set the advanced options for reading GS1 Databar\nbarcodes\n\n\nDataMatrixAutoUTF8\n  Automatic detection of UTF8 data in datamatrix\nbarcodes\n\n\nDespeckle\n  Clean up images containing specks of black and white\n\n\nEncoding\n  character encoding for barcode values\n\n\nErrorCorrection\n  Correct errors in barcodes\n\n\nExtendedCode39\n  Read Code 39 barcodes in the extended symbol set\n\n\nGammaCorrection\n  gamma correction value for color images\n\n\nLineJump\n  Frequency of line sampling in an image\n\n\nMaxLength\n  Maximum string length of a barcode\n\n\nMaxRectOverlap\n  maximum number of threads\n\n\nMaxThreads\n  maximum overlap for bounding rectangles\n\n\nMedianFilter\n  Apply a median filter to the image\n\n\nMedianFilterBias\n  Lighten/darken an image during a median filter\n\n\nMinLength\n  Minimum string length of a barcode\n\n\nMinOccurrence\n  Minimum number of hits needed to read a barcode\n\n\nMinSeparation\n  Minimum distance between similar barcodes\n\n\nMinSpaceBarWidth\n  Minimum width of a space in a barcode\n\n\nMultipleRead\n  Read more than one barcode\n\n\nNoiseReduction\n  Clean up images containing un-wanted black marks\n\n\nPageNo\n  Page number to scan in an image\n\n\nPattern\n  Regular expression to search for\n\n\nPDF417AutoUTF8\n  Automatic identification of UTF8 data in PDF-417\nbarcodes\n\n\nPdf417ChannelMode\n  Control the way macros are handled in PDF417\nbarcodes\n\n\nPdf417MacroEscapeBackslash\n  Handling of back slash characters in\nPDF417 macros\n\n\nPhotometric\n  Photometric interpretation for a black and white bitmap\n\n\nPrefOccurrence\n  Preferred number of hits for a barcode\n\n\nQRCodeAutoUTF8\n  Automatic identification of UTF8 data in QrCode\nbarcodes\n\n\nQRCodeBWAutoMedianFilter\n  automatic use of median filter for QrCode\ndetection\n\n\nQuietZoneSize\n  Size of quiet zone around a barcode\n\n\nReadCodabar\n  Read Codabar barcodes\n\n\nReadCode128\n  Read Code 128 barcodes\n\n\nReadCode25\n  Read Code 25 (interlaced) barcodes\n\n\nReadCode25ni\n  Read Code 25 (non-interlaced) barcodes\n\n\nReadCode39\n  Read Code 39 barcodes\n\n\nReadDatabar\n  Read GS1 Databar barcodes\n\n\nReadDataMatrix\n  Read Data Matrix barcodes\n\n\nReadEAN13\n  Read EAN-13 barcodes\n\n\nReadEAN8\n  Read EAN-8 barcodes\n\n\nReadMicroPDF417\n  Read micro-PDF-417 barcodes\n\n\nReadNumeric\n  Only read numeric barcodes\n\n\nReadPatchCodes\n  Read Patch Codes\n\n\nReadPDF417\n Read PDF-417 barcodes\n\n\nReadShortCode128\n  Read short Code 128 barcodes\n\n\nReadUPCA\n Read UPC-A barcodes\n\n\nReadUPCE\n Read UPC-E barcodes\n\n\nReportUnreadBarcodes\n Report barcodes that could not be decoded\n\n\nScanDirection\n  Orientation to scan for a barcode\n\n\nShortCode128MinLength\n  Minimum length for a barcode of type\n\"SHORTCODE128\"\n\n\nShowCheckDigit\n  Display check digits\n\n\nSkewedDatamatrix\n  Check for skewed linear barcodes\n\n\nSkewedLinear\n  Check for skewed datamatrix barcodes\n\n\nSkewLineJump\n  Frequency of line sampling for skewed barcodes\n\n\nSkewTolerance\n  Search for barcodes at an angle to horizontal or\nvertical\n\n\nTifSplitMode\n  Controls how a TIF file should be split\n\n\nTifSplitPath\n  Split a TIF file into smaller parts based on the\nlocation of barcodes in the image\n\n\nTimeOut\n  Set a time out for barcode detection\n\n\nUseFastScan\n  Do a quick scan prior to a deeper search.\n\n\nUseOverSampling\n  Another method for cleaning up 'noisy' images\n\n\nWeightLongerBarcodes\n  boost the hit count for longer barcodes.", 
            "title": "Barcode"
        }, 
        {
            "location": "/Configuration/Barcode/#barcode-recognition-setup", 
            "text": "Setup an extractFromBarcode rule on at he appropriate node\nInstall the Softek SDK**  Download the latest version from:  Windows SDK\nv8.1.2  Linux SDK v8.1.2  Libraries need to be copied to /usr/lib/java, /usr/lib/ or\nC:\\Windows\\System32 or to where the java.library.path is pointing\\  For a list of all versions goto http://www.bardecode.com/en1/quick-download/ although a different\nlicense may need to be loaded via the License property", 
            "title": "Barcode Recognition Setup"
        }, 
        {
            "location": "/Configuration/Barcode/#supported-barcodes", 
            "text": "Codabar also known as Code 2 of 7, Codeabar, Ames Code, NW-7 and Monarch (ReadCodabar)  Code 128 Symbol Sets A, B and C (ReadCode128)  Code 128 Short Format (ReadShortCode128)  Code 2 of 5 Datalogic (ReadCode25ni)  Code 2 of 5 Iata1 (ReadCode25ni)  Code 2 of 5 Iata2 (ReadCode25ni)  Code 2 of 5 Industrial (ReadCode25ni)  Code 2 of 5 Interleaved (ReadCode25)  Code 2 of 5 Matrix (ReadCode25ni)  Code 3 of 9 (ReadCode39)  Code 3 of 9 Extended (ReadCode39 and ExtendedCode39)  Code 93 (ReadCode93)  EAN-8, European Article Number/International Article Number (ReadEAN8)  EAN-13 and UPC-A, European Article Number/International Article Number (ReadEAN13)  GS1-128, UCC-128, EAN-128 (ReadCode128)  GS1-Databar (please see 2-D section below)  Patch Code Symbols (ReadPatchCodes)  UPC-A, Universal Product Code (ReadEAN13 and ReadUPCA)  UPC-E, Universal Product Code (ReadUPCE)  QR-Code (ReadQRCode)  Data Matrix ECC200 sizes 8x8 to 144x144 (ReadDataMatrix)  GS1-Databar  Micro-PDF-417 (ReadMicroPDF417)  PDF-417, Portable Data File (ReadPDF417)", 
            "title": "Supported Barcodes"
        }, 
        {
            "location": "/Configuration/Barcode/#properties", 
            "text": "AllowDuplicateValues   Barcodes containing the same text on the same\npage  BarcodesAtTopOfPage   Search from the top of a page downwards  Code128Lenient   relax some of the requirements for Code 128 barcodes  Code25Checksum   Code 25 barcodes include checksum character  Code25MinLengthOccurrence   control for false positive readings for\nCode 25 barcodes  Code39Checksum   Code 39 barcodes include checksum character  Code39MaxRatioPcnt   set the max ratio between the wide and narrow\nbars  Code39NeedStartStop   Require start and stop * characters for a Code\n39 barcode  ColorProcessingLevel   control the amount of processing time spent\nreading barcode values from color images  ColorThreshold   Contrast setting for color images  ConvertUPCEToEAN13   Output UPC-E barcodes in EAN-13 format  DatabarOptions   set the advanced options for reading GS1 Databar\nbarcodes  DataMatrixAutoUTF8   Automatic detection of UTF8 data in datamatrix\nbarcodes  Despeckle   Clean up images containing specks of black and white  Encoding   character encoding for barcode values  ErrorCorrection   Correct errors in barcodes  ExtendedCode39   Read Code 39 barcodes in the extended symbol set  GammaCorrection   gamma correction value for color images  LineJump   Frequency of line sampling in an image  MaxLength   Maximum string length of a barcode  MaxRectOverlap   maximum number of threads  MaxThreads   maximum overlap for bounding rectangles  MedianFilter   Apply a median filter to the image  MedianFilterBias   Lighten/darken an image during a median filter  MinLength   Minimum string length of a barcode  MinOccurrence   Minimum number of hits needed to read a barcode  MinSeparation   Minimum distance between similar barcodes  MinSpaceBarWidth   Minimum width of a space in a barcode  MultipleRead   Read more than one barcode  NoiseReduction   Clean up images containing un-wanted black marks  PageNo   Page number to scan in an image  Pattern   Regular expression to search for  PDF417AutoUTF8   Automatic identification of UTF8 data in PDF-417\nbarcodes  Pdf417ChannelMode   Control the way macros are handled in PDF417\nbarcodes  Pdf417MacroEscapeBackslash   Handling of back slash characters in\nPDF417 macros  Photometric   Photometric interpretation for a black and white bitmap  PrefOccurrence   Preferred number of hits for a barcode  QRCodeAutoUTF8   Automatic identification of UTF8 data in QrCode\nbarcodes  QRCodeBWAutoMedianFilter   automatic use of median filter for QrCode\ndetection  QuietZoneSize   Size of quiet zone around a barcode  ReadCodabar   Read Codabar barcodes  ReadCode128   Read Code 128 barcodes  ReadCode25   Read Code 25 (interlaced) barcodes  ReadCode25ni   Read Code 25 (non-interlaced) barcodes  ReadCode39   Read Code 39 barcodes  ReadDatabar   Read GS1 Databar barcodes  ReadDataMatrix   Read Data Matrix barcodes  ReadEAN13   Read EAN-13 barcodes  ReadEAN8   Read EAN-8 barcodes  ReadMicroPDF417   Read micro-PDF-417 barcodes  ReadNumeric   Only read numeric barcodes  ReadPatchCodes   Read Patch Codes  ReadPDF417  Read PDF-417 barcodes  ReadShortCode128   Read short Code 128 barcodes  ReadUPCA  Read UPC-A barcodes  ReadUPCE  Read UPC-E barcodes  ReportUnreadBarcodes  Report barcodes that could not be decoded  ScanDirection   Orientation to scan for a barcode  ShortCode128MinLength   Minimum length for a barcode of type\n\"SHORTCODE128\"  ShowCheckDigit   Display check digits  SkewedDatamatrix   Check for skewed linear barcodes  SkewedLinear   Check for skewed datamatrix barcodes  SkewLineJump   Frequency of line sampling for skewed barcodes  SkewTolerance   Search for barcodes at an angle to horizontal or\nvertical  TifSplitMode   Controls how a TIF file should be split  TifSplitPath   Split a TIF file into smaller parts based on the\nlocation of barcodes in the image  TimeOut   Set a time out for barcode detection  UseFastScan   Do a quick scan prior to a deeper search.  UseOverSampling   Another method for cleaning up 'noisy' images  WeightLongerBarcodes   boost the hit count for longer barcodes.", 
            "title": "Properties"
        }, 
        {
            "location": "/Configuration/Branding/", 
            "text": "Branding PaperTrail\n\n\n\n\nImages are placed in the System/images node.\n\n\nImages must end in .png (if they are a .jpeg or .gif they can be\n    safely renamed).\n\n\nImages should be the correct size, if the image is bigger or smaller\n    it should be manually resized before importing into System/images.\n\n\nTo prevent the images from being overwritten after upgrades, they\n    should be permanently checked out.\n\n\n\n\nlogin_background.png (320x365)\n\n\nThe honeycomb that sits behind the login and password boxes.\n\n\npapertrail.png (110x26)\n\n\nThe logo that sits in the top left of the main application screen.\\\n The background should be transparent.\n\n\nlogo.png (320x50)\n\n\nThe logo that sits above the honeycomb.\\\n Add white space to the left of image to center it above the honeycomb.\n\n\negis.png (75x25)\n\n\nThe egis logo on the bottom right of the screen.", 
            "title": "Branding"
        }, 
        {
            "location": "/Configuration/Branding/#branding-papertrail", 
            "text": "Images are placed in the System/images node.  Images must end in .png (if they are a .jpeg or .gif they can be\n    safely renamed).  Images should be the correct size, if the image is bigger or smaller\n    it should be manually resized before importing into System/images.  To prevent the images from being overwritten after upgrades, they\n    should be permanently checked out.", 
            "title": "Branding PaperTrail"
        }, 
        {
            "location": "/Configuration/Branding/#login95backgroundpng-320x365", 
            "text": "The honeycomb that sits behind the login and password boxes.", 
            "title": "login_background.png (320x365)"
        }, 
        {
            "location": "/Configuration/Branding/#papertrailpng-110x26", 
            "text": "The logo that sits in the top left of the main application screen.\\\n The background should be transparent.", 
            "title": "papertrail.png (110x26)"
        }, 
        {
            "location": "/Configuration/Branding/#logopng-320x50", 
            "text": "The logo that sits above the honeycomb.\\\n Add white space to the left of image to center it above the honeycomb.", 
            "title": "logo.png (320x50)"
        }, 
        {
            "location": "/Configuration/Branding/#egispng-75x25", 
            "text": "The egis logo on the bottom right of the screen.", 
            "title": "egis.png (75x25)"
        }, 
        {
            "location": "/Configuration/EasyPDF/", 
            "text": "EasyPDF deployment and configuration\n ========================================\n\n\nThe following combination of software will need to be installed on the EasyPDF server\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Windows Server 2008 32/64 bit.\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 PaperTrail 32 bit (latest release available).\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 EasyPDF version 6/7 32 bit.\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 EasyPDF PaperTrail Addon 32 bit (EasyPDF 6 requires Addon r5453\nand\u00a0EasyPDF 7 requires Addon r8738).\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Microsoft Office 2010.\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Any other native applications that may need to be converted to\nPDF by EasyPDF (i.e. AutoCAD).\n\n\nNote : UAC should be disabled on the machine before any software is\ninstalled.\n\n\nLocal installation\n (Both PaperTrail and EasyPDF running on same\nhost) :\n\n\n1.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF application.\n\n\n2.\u00a0\u00a0\u00a0\u00a0 Install PaperTrail release.\n\n\n3.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF PaperTrail Addon.\n\n\n4.\u00a0\u00a0\u00a0\u00a0 Set the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.\n\n\n5.\u00a0\u00a0\u00a0\u00a0 Start PaperTrail and confirm that installation was successful.\n\n\n6.\u00a0\u00a0\u00a0\u00a0 Add the following line to the easypdf.properties file and restart\nPaperTrail thereafter :\n\n\neasypdf.word.nativeOfficePDF=true\n\n\n7.\u00a0\u00a0\u00a0\u00a0 Import test documents to confirm that all is set up correctly.\n\n\n\u00a0\n\n\nRemote installation\n (PaperTrail and EasyPDF running on separate\nhosts) :\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nEasyPDF server\n :\n\n\n1.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF application.\n\n\n2.\u00a0\u00a0\u00a0\u00a0 Install PaperTrail release.\n\n\n3.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF PaperTrail Addon.\n\n\n4.\u00a0\u00a0\u00a0\u00a0 Set the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.\n\n\n5.\u00a0\u00a0\u00a0\u00a0 Start PaperTrail and confirm that installation was successful.\n\n\n6.\u00a0\u00a0\u00a0\u00a0 Add the following line to the easypdf.properties file and restart\nPaperTrail thereafter :\n\n\neasypdf.word.nativeOfficePDF=true\n\n\n7.\u00a0\u00a0\u00a0\u00a0 Import test documents locally to confirm that all is set up\ncorrectly.\n\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nPaperTrail application server\n :\n\n\n1.\u00a0\u00a0\u00a0\u00a0 Once PaperTrail is up and running, set the below properties in\nthe papertrail.properties file to enable remote conversions :\n\n\nconversion.filetype.\\*=remote\nconversion.filetype.pdf=pdf\nconversion.remote.host=http://host1:8080\n\n\n\n\n2.\u00a0\u00a0\u00a0\u00a0 Import test documents on application server to confirm that all\nis set up correctly.\n\n\nTroubleshooting\n\n\nIf any conversion issue are being experienced, create a .vbs\nfile which can be run to test conversions outside of PaperTrail. The\npaths in the properties are input and output files, and should be\nconfigured accordingly :\n\n\nSet oPrinter = CreateObject(\neasyPDF.Printer.7\n)\nSet oPrintJob = oPrinter.PrintJob\noPrintJob.PrintOut \nC:\\\\test.txt\n, \nC:\\\\output.pdf\n\n\n\n\n\nAnother way to test the conversions is to navigate to\n\nC:\\Users\\Public\\Documents\\BCL Technologies\\easyPDF SDK\n7\\Samples\\Visual C#\\EasyPDFPrinterTest\n and then running\nEasyPDFPrinterTest.exe. This will allow you to select an input document\nto convert and specify the output path of the PDF.\n\n\nFor any more information, the user manual can be accessed at\n\nhttp://www.pdfonline.com/easypdf/sdk/usermanual/", 
            "title": "EasyPDF"
        }, 
        {
            "location": "/Configuration/EasyPDF/#the-following-combination-of-software-will-need-to-be-installed-on-the-easypdf-server", 
            "text": "\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Windows Server 2008 32/64 bit.  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 PaperTrail 32 bit (latest release available).  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 EasyPDF version 6/7 32 bit.  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 EasyPDF PaperTrail Addon 32 bit (EasyPDF 6 requires Addon r5453\nand\u00a0EasyPDF 7 requires Addon r8738).  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Microsoft Office 2010.  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Any other native applications that may need to be converted to\nPDF by EasyPDF (i.e. AutoCAD).  Note : UAC should be disabled on the machine before any software is\ninstalled.  Local installation  (Both PaperTrail and EasyPDF running on same\nhost) :  1.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF application.  2.\u00a0\u00a0\u00a0\u00a0 Install PaperTrail release.  3.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF PaperTrail Addon.  4.\u00a0\u00a0\u00a0\u00a0 Set the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.  5.\u00a0\u00a0\u00a0\u00a0 Start PaperTrail and confirm that installation was successful.  6.\u00a0\u00a0\u00a0\u00a0 Add the following line to the easypdf.properties file and restart\nPaperTrail thereafter :  easypdf.word.nativeOfficePDF=true  7.\u00a0\u00a0\u00a0\u00a0 Import test documents to confirm that all is set up correctly.  \u00a0  Remote installation  (PaperTrail and EasyPDF running on separate\nhosts) :  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0  EasyPDF server  :  1.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF application.  2.\u00a0\u00a0\u00a0\u00a0 Install PaperTrail release.  3.\u00a0\u00a0\u00a0\u00a0 Install EasyPDF PaperTrail Addon.  4.\u00a0\u00a0\u00a0\u00a0 Set the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.  5.\u00a0\u00a0\u00a0\u00a0 Start PaperTrail and confirm that installation was successful.  6.\u00a0\u00a0\u00a0\u00a0 Add the following line to the easypdf.properties file and restart\nPaperTrail thereafter :  easypdf.word.nativeOfficePDF=true  7.\u00a0\u00a0\u00a0\u00a0 Import test documents locally to confirm that all is set up\ncorrectly.  \u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0  PaperTrail application server  :  1.\u00a0\u00a0\u00a0\u00a0 Once PaperTrail is up and running, set the below properties in\nthe papertrail.properties file to enable remote conversions :  conversion.filetype.\\*=remote\nconversion.filetype.pdf=pdf\nconversion.remote.host=http://host1:8080  2.\u00a0\u00a0\u00a0\u00a0 Import test documents on application server to confirm that all\nis set up correctly.  Troubleshooting  If any conversion issue are being experienced, create a .vbs\nfile which can be run to test conversions outside of PaperTrail. The\npaths in the properties are input and output files, and should be\nconfigured accordingly :  Set oPrinter = CreateObject( easyPDF.Printer.7 )\nSet oPrintJob = oPrinter.PrintJob\noPrintJob.PrintOut  C:\\\\test.txt ,  C:\\\\output.pdf   Another way to test the conversions is to navigate to C:\\Users\\Public\\Documents\\BCL Technologies\\easyPDF SDK\n7\\Samples\\Visual C#\\EasyPDFPrinterTest  and then running\nEasyPDFPrinterTest.exe. This will allow you to select an input document\nto convert and specify the output path of the PDF.  For any more information, the user manual can be accessed at http://www.pdfonline.com/easypdf/sdk/usermanual/", 
            "title": "The following combination of software will need to be installed on the EasyPDF server"
        }, 
        {
            "location": "/Configuration/LDAP/", 
            "text": "LDAP Configuration\n\n\nOpenLDAP\n\n\nConfigure User format = uid=${user},o=Directory\n\n\n\nNote:\n Active directory will return less results and attributes when\nusing port 3268 vs 389\n\n\n\\\n Multiple LDAP Servers\n\n\n\n\nConfigured by addition a set of properties per domain:\n\n\nldap.extra.domain1-corp.local.host=\nldap.extra.domain1-corp.local.user=\nldap.extra.domain1-corp.local.pass=\n\nldap.extra.domain2-corp.local.host=\nldap.extra.domain2-corp.local.user=\nldap.extra.domain2-corp.local.pass=\n\n\n\n\nSynchronizing With LDAP / Active Directory\n\n\nCheck LDAP -> Auto Create users to create new users from LDAP when\nthey login\\\n Check LDAP -> Auto Sync Groups \u00a0to synchronize group membership, this\nwill sync on user create and on the interval specified under\nAuthentication -> Group Sync Interval\n\n\nTroubleshooting\n\n\n\n\nGet the LDAP queries that PaperTrail is executing by increasing the\n    log level: \u00a0com.egis.utils.ldap\u00a0in\u00a0\\\n8.8.4 or\n    com.egis.security.ldap\u00a0in 8.8.4+\n\n\n\n\nDEBUG to see the results of queries\\\n TRACE to see the actual query being run and authentication requests\n\n\n\n\nUse an off the shelf tool to check what options work when\n    connecting:\n\n\n\n\nGUI:\n\n\nhttp://jxplorer.org/\n\n\nhttp://www.ldapsoft.com/ldapbrowser/ldapadmintool.html\n\n\nCLI:\n\n\nldapsearch -h 172.16.237.131 -D \"administrator@corp.egis-software.com\" -w password -b \"cn=users,dc=corp,dc=egis-software,dc=com\" -s sub \"(\n(objectClass=user)(mail=*))\" '*'\n  \n\n\nUse tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the\nprotocol level.\\\n \u00a0\n\n\n\n\nAdjust the LDAP query string in Services -> Properties -> LDAP as\n    appropriate", 
            "title": "LDAP"
        }, 
        {
            "location": "/Configuration/LDAP/#ldap-configuration", 
            "text": "", 
            "title": "LDAP Configuration"
        }, 
        {
            "location": "/Configuration/LDAP/#openldap", 
            "text": "Configure User format = uid=${user},o=Directory  Note:  Active directory will return less results and attributes when\nusing port 3268 vs 389  \\\n Multiple LDAP Servers   Configured by addition a set of properties per domain:  ldap.extra.domain1-corp.local.host=\nldap.extra.domain1-corp.local.user=\nldap.extra.domain1-corp.local.pass=\n\nldap.extra.domain2-corp.local.host=\nldap.extra.domain2-corp.local.user=\nldap.extra.domain2-corp.local.pass=", 
            "title": "OpenLDAP"
        }, 
        {
            "location": "/Configuration/LDAP/#synchronizing-with-ldap-active-directory", 
            "text": "Check LDAP -> Auto Create users to create new users from LDAP when\nthey login\\\n Check LDAP -> Auto Sync Groups \u00a0to synchronize group membership, this\nwill sync on user create and on the interval specified under\nAuthentication -> Group Sync Interval", 
            "title": "Synchronizing With LDAP / Active Directory"
        }, 
        {
            "location": "/Configuration/LDAP/#troubleshooting", 
            "text": "Get the LDAP queries that PaperTrail is executing by increasing the\n    log level: \u00a0com.egis.utils.ldap\u00a0in\u00a0\\ 8.8.4 or\n    com.egis.security.ldap\u00a0in 8.8.4+   DEBUG to see the results of queries\\\n TRACE to see the actual query being run and authentication requests   Use an off the shelf tool to check what options work when\n    connecting:   GUI:  http://jxplorer.org/  http://www.ldapsoft.com/ldapbrowser/ldapadmintool.html  CLI:  ldapsearch -h 172.16.237.131 -D \"administrator@corp.egis-software.com\" -w password -b \"cn=users,dc=corp,dc=egis-software,dc=com\" -s sub \"( (objectClass=user)(mail=*))\" '*'     Use tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the\nprotocol level.\\\n \u00a0   Adjust the LDAP query string in Services -> Properties -> LDAP as\n    appropriate", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/Configuration/WebScan/", 
            "text": "Web Scan\n\n\nWeb Scan Profile Settings\n\n\nseparation\n\n\ntype - \nstring\n\n\nPossible values:\n\n\n\n\n\n\nNone\n - combine all images to single PDF file;\n\n\n\n\n\n\nPage\n - put each image to new PDF file, so each PDF file will contain single page;\n\n\n\n\n\n\nBlank\n - create new PDF when blank image appeared. For instance, there is images sequence:\n\n\n\n\n\n\nimage1, image2, blank image, image3, image4, image5, blank image, image6\n\n\nAs a result of \nBlank\n separation, scan addon will return 3 PDF files: 2 pages (image1, image2), 3 pages (image3, image4, image5) and 1 page (image6).\n\n\n\n\nBarcode\n - create new PDF when image with unique barcode appeared. For instance, there is images sequence:\n\n\n\n\nimage1, image with barcode1, image2, image3, image with barcode3\n\n\nAs a result of \nBlank\n separation, scan addon will return 3 PDF files: 1 page (image1), 3 pages (image with barcode1, image2, image3) and 1 page (image with barcode3).\n\n\nresolution\n\n\ntype - \nobject\n\n\nFields:\n\n\n\n\n\n\nx\n - integer, \nx\n value of resolution. Common possible values: 100 - 600\n\n\n\n\n\n\ny\n - integer, \ny\n value of resolution. Common possible values: 100 - 600\n\n\n\n\n\n\nunits\n - string, measure units for \nx\n and \ny\n. Possible values:\n\n\n\n\n\n\nInches\n\n\n\n\n\n\nCentimeters\n\n\n\n\n\n\nPoints\n\n\n\n\n\n\nPixels\n\n\n\n\n\n\nImportant note:\n list of supported values for \nresolution\n may vary depending on scanner model\n\n\ncompressionMode\n\n\ntype - \nstring\n\n\nCommon values:\n\n\n\n\n\n\nNone\n - don't use any compression mode;\n\n\n\n\n\n\nJpeg\n - intended for the compression of color photographs\n\n\n\n\n\n\nLzw\n - a compression licensed by UNISYS\n\n\n\n\n\n\nJbig\n - intended for bi-tonal and grayscale document images\n\n\n\n\n\n\nPng\n - Portable Network Graphic\n\n\n\n\n\n\nGroup4\n - CCITT Group 4 fax encoding, intended for document images\n\n\n\n\n\n\nImportant note:\n list of supported values for \ncompressionMode\n may vary depending on scanner model\n\n\npdfDecoder\n\n\ntype - \nobject\n\n\nFields:\n\n\n\n\nresolution\n - integer, resolution at which to render a PDF page. Minimum - 1, maximum - 3600.\n\n\n\n\nbarcodeSettings\n\n\ntype - \nobject\n\n\nSee (Barcode Configuration)[http://support.papertrail.co.za/Configuration/Barcode/] for list of supported properties\n\n\nExamples\n\n\nSplit images into PDF files by barcode and use 300x300px scan resolution\n\n\n{\n  \nseparation\n: \nBarcode\n,\n  \nresolution\n: {\n    \nx\n: 300,\n    \ny\n: 300,\n    \nunits\n: \nPixels\n\n  }\n}\n\n\n\n\nCreate single PDF file from scanned images and render it with 80 resolution\n\n\n{\n  \nseparation\n: \nNone\n,\n  \npdfDecoder\n: {\n    \nresolution\n: 80\n  }\n}", 
            "title": "WebScan"
        }, 
        {
            "location": "/Configuration/WebScan/#web-scan", 
            "text": "", 
            "title": "Web Scan"
        }, 
        {
            "location": "/Configuration/WebScan/#web-scan-profile-settings", 
            "text": "", 
            "title": "Web Scan Profile Settings"
        }, 
        {
            "location": "/Configuration/WebScan/#separation", 
            "text": "type -  string  Possible values:    None  - combine all images to single PDF file;    Page  - put each image to new PDF file, so each PDF file will contain single page;    Blank  - create new PDF when blank image appeared. For instance, there is images sequence:    image1, image2, blank image, image3, image4, image5, blank image, image6  As a result of  Blank  separation, scan addon will return 3 PDF files: 2 pages (image1, image2), 3 pages (image3, image4, image5) and 1 page (image6).   Barcode  - create new PDF when image with unique barcode appeared. For instance, there is images sequence:   image1, image with barcode1, image2, image3, image with barcode3  As a result of  Blank  separation, scan addon will return 3 PDF files: 1 page (image1), 3 pages (image with barcode1, image2, image3) and 1 page (image with barcode3).", 
            "title": "separation"
        }, 
        {
            "location": "/Configuration/WebScan/#resolution", 
            "text": "type -  object  Fields:    x  - integer,  x  value of resolution. Common possible values: 100 - 600    y  - integer,  y  value of resolution. Common possible values: 100 - 600    units  - string, measure units for  x  and  y . Possible values:    Inches    Centimeters    Points    Pixels    Important note:  list of supported values for  resolution  may vary depending on scanner model", 
            "title": "resolution"
        }, 
        {
            "location": "/Configuration/WebScan/#compressionmode", 
            "text": "type -  string  Common values:    None  - don't use any compression mode;    Jpeg  - intended for the compression of color photographs    Lzw  - a compression licensed by UNISYS    Jbig  - intended for bi-tonal and grayscale document images    Png  - Portable Network Graphic    Group4  - CCITT Group 4 fax encoding, intended for document images    Important note:  list of supported values for  compressionMode  may vary depending on scanner model", 
            "title": "compressionMode"
        }, 
        {
            "location": "/Configuration/WebScan/#pdfdecoder", 
            "text": "type -  object  Fields:   resolution  - integer, resolution at which to render a PDF page. Minimum - 1, maximum - 3600.", 
            "title": "pdfDecoder"
        }, 
        {
            "location": "/Configuration/WebScan/#barcodesettings", 
            "text": "type -  object  See (Barcode Configuration)[http://support.papertrail.co.za/Configuration/Barcode/] for list of supported properties", 
            "title": "barcodeSettings"
        }, 
        {
            "location": "/Configuration/WebScan/#examples", 
            "text": "Split images into PDF files by barcode and use 300x300px scan resolution  {\n   separation :  Barcode ,\n   resolution : {\n     x : 300,\n     y : 300,\n     units :  Pixels \n  }\n}  Create single PDF file from scanned images and render it with 80 resolution  {\n   separation :  None ,\n   pdfDecoder : {\n     resolution : 80\n  }\n}", 
            "title": "Examples"
        }, 
        {
            "location": "/Configuration/basic/", 
            "text": "Adding nodes (folders)\n\n\nCreating users and groups\n\n\nAdding permisions to a node\n\n\nMore Links\n\n\nAdvanced Configuration", 
            "title": "Basic"
        }, 
        {
            "location": "/Configuration/basic/#adding-nodes-folders", 
            "text": "", 
            "title": "Adding nodes (folders)"
        }, 
        {
            "location": "/Configuration/basic/#creating-users-and-groups", 
            "text": "", 
            "title": "Creating users and groups"
        }, 
        {
            "location": "/Configuration/basic/#adding-permisions-to-a-node", 
            "text": "More Links  Advanced Configuration", 
            "title": "Adding permisions to a node"
        }, 
        {
            "location": "/Configuration/security/", 
            "text": "Security Settings\n\n\nPaperTrail can be run in 4 distinct\u00a0security modes:\n\n\nLow (Default)\n\n\nSuitable for intranet based deployments without confidential data\u00a0\n\n\nMedium\n\n\nAccess to the various API's used for replication and clustering is\nrestricted based on Trusted Server entries, some of the endpoints\nrestricted include:\n \u00a0\n\n\n\n\nconversion\n\n\nsignature/upload\n\n\nindex/replication\n\n\nstore\n\n\nreplicate\n\n\n\n\nHigh\n\n\nIncludes all the restrictions of Medium and:\n \u00a0\n\n\n\n\ndisables the /script/console endpoint (used by\n    /web/admin/console.html and pt script\u00a0CLI)\n\n\n\n\nprevents updates to the following properties via the web UI, they\n    need to be set via papertrail.properties file:\n\n\nldap.host\nwaffle.enable\nspnego.enable\nspnego.kdc\nsmtp.debug\nemail.spool\nsmtp.host\nsms.url\nweb.login.sms.otp\nindex.store\nhttp.ssl\ndisabled.audits\ndisabled.entity.audits\nopenoffice.path\ntiff2pdf.process\npdf2swf.process\nsecurity.level\n\n\n\n\n\n\nVery High\n\n\nIncludes all the restrictions of High and further restricts:\n\n\n\n\nLoading jar files via System/jars folder\n\n\nLoading scripts via System/scripts folder\n\n\nLoading UI plugins via System/plugins folder\n\n\nScripted data sources\n\n\nrunScript, dbLookup and commandLineProcess rules\n\n\nCustom options in Meta Model Fields\n\n\nPQL Expressions", 
            "title": "Security"
        }, 
        {
            "location": "/Configuration/security/#security-settings", 
            "text": "PaperTrail can be run in 4 distinct\u00a0security modes:", 
            "title": "Security Settings"
        }, 
        {
            "location": "/Configuration/security/#low-default", 
            "text": "Suitable for intranet based deployments without confidential data", 
            "title": "Low (Default)"
        }, 
        {
            "location": "/Configuration/security/#medium", 
            "text": "Access to the various API's used for replication and clustering is\nrestricted based on Trusted Server entries, some of the endpoints\nrestricted include:\n \u00a0   conversion  signature/upload  index/replication  store  replicate", 
            "title": "Medium"
        }, 
        {
            "location": "/Configuration/security/#high", 
            "text": "Includes all the restrictions of Medium and:\n \u00a0   disables the /script/console endpoint (used by\n    /web/admin/console.html and pt script\u00a0CLI)   prevents updates to the following properties via the web UI, they\n    need to be set via papertrail.properties file:  ldap.host\nwaffle.enable\nspnego.enable\nspnego.kdc\nsmtp.debug\nemail.spool\nsmtp.host\nsms.url\nweb.login.sms.otp\nindex.store\nhttp.ssl\ndisabled.audits\ndisabled.entity.audits\nopenoffice.path\ntiff2pdf.process\npdf2swf.process\nsecurity.level", 
            "title": "High"
        }, 
        {
            "location": "/Configuration/security/#very-high", 
            "text": "Includes all the restrictions of High and further restricts:   Loading jar files via System/jars folder  Loading scripts via System/scripts folder  Loading UI plugins via System/plugins folder  Scripted data sources  runScript, dbLookup and commandLineProcess rules  Custom options in Meta Model Fields  PQL Expressions", 
            "title": "Very High"
        }, 
        {
            "location": "/Configuration/solution-pack/", 
            "text": "Solution Packs\n\n\nSolution packs provide a simplemechanism to export the configuration and deployment from one server to another\n\n\nExporting\n\n\nTo export a solution pack browse to \n/solutions/export/\n while logged on as an adminstrator - A solution pack (.zip) file will be downloaded with the following contents:\n\n\n\n\nNode Structure\n\n\nTemplates\n\n\nForms\n\n\nSystem/scripts/\n\n\nSystem/templates\n\n\nWorkflows\n\n\n\n\nThe .zip can be manually edited and updated as required.\n\n\nImporting\n\n\nTo import a solution pack drop it into the \nplugins\n folder or import via the CLI:\n\n\npt deploy solution-pack.zip", 
            "title": "Solution pack"
        }, 
        {
            "location": "/Configuration/solution-pack/#solution-packs", 
            "text": "Solution packs provide a simplemechanism to export the configuration and deployment from one server to another", 
            "title": "Solution Packs"
        }, 
        {
            "location": "/Configuration/solution-pack/#exporting", 
            "text": "To export a solution pack browse to  /solutions/export/  while logged on as an adminstrator - A solution pack (.zip) file will be downloaded with the following contents:   Node Structure  Templates  Forms  System/scripts/  System/templates  Workflows   The .zip can be manually edited and updated as required.", 
            "title": "Exporting"
        }, 
        {
            "location": "/Configuration/solution-pack/#importing", 
            "text": "To import a solution pack drop it into the  plugins  folder or import via the CLI:  pt deploy solution-pack.zip", 
            "title": "Importing"
        }, 
        {
            "location": "/Configuration/ssl/", 
            "text": "Configuring HTTPS (Server Side Only)\n\n\nTo configure PaperTrail to use HTTPS:\n\n\n\n\nCreate a Java key store (JKS) with a name of \nkeystore\n and place it in the \nconf\n directory\n\n\nSpecify the keystore password via \nhttp.ssl.password\n\n\nCheck Properties -\n HTTPS -\n Enable (\nhttp.ssl\n) to true\n\n\nSet the HTTPS port (\nhttp.ssl.port\n) to 443 or 8443\n\n\nCheck Force SSL (\nhttp.ssl.force\n) to always redirect from HTTP to HTTPS\n\n\n\n\nConverting PKCS#7 to PKCS#12\n\n\nopenssl pkcs12 -export -in server.crt -inkey server.key   -out keystore.p12 -name www\n\n\nConverting PKCS#12 to JKS\n\n\nkeytool -importkeystore -destkeystore keystore -srckeystore keystore.p12 -srcstoretype PKCS12\n               \n\n\nImport Root and Intermediate CA's\n\n\nkeytool -import -trustcacerts -alias root -file root.crt -keystore keystore\n\n\nVerifying\n\n\nTo verify that the keystore is configured correctly:\n\n\nkeytool -list -keystore keystore\n \n\n\nWhich should produce something like:\n\n\n\n\nKeystore type: JKS\nKeystore provider: SUN\n\n\nYour keystore contains 1 entry\n\n\n*.papertrail.co.za, Oct 29, 2015, PrivateKeyEntry, \n\n\n\n\nThe last line has a syntax of \n{CN} {Expiry} {Key Type}\n  \n\n\n{CN}\n should match the URL you would be accessing PaperTrail by\n\n\n{Key Type}\n must be PrivateKeyEntry  \n\n\nConfiguring Client Authentication (Mutual SSL)\n\n\n\n\nConfigure server side SSL as above\n\n\nCreate a new a JKS file called \ntruststore\n containing the trusted CA's\n\n\nCheck Require Client Certificates (\nhttp.ssl.client.require\n)\n\n\n\n\nConfiguring client certificates requires that \nall\n clients supply a trusted certificate\n\n\nThe Common Name (\nCN\n) of the certificate will be used to map the a certificate to a user via the login field", 
            "title": "Ssl"
        }, 
        {
            "location": "/Configuration/ssl/#configuring-https-server-side-only", 
            "text": "To configure PaperTrail to use HTTPS:   Create a Java key store (JKS) with a name of  keystore  and place it in the  conf  directory  Specify the keystore password via  http.ssl.password  Check Properties -  HTTPS -  Enable ( http.ssl ) to true  Set the HTTPS port ( http.ssl.port ) to 443 or 8443  Check Force SSL ( http.ssl.force ) to always redirect from HTTP to HTTPS", 
            "title": "Configuring HTTPS (Server Side Only)"
        }, 
        {
            "location": "/Configuration/ssl/#converting-pkcs7-to-pkcs12", 
            "text": "openssl pkcs12 -export -in server.crt -inkey server.key   -out keystore.p12 -name www", 
            "title": "Converting PKCS#7 to PKCS#12"
        }, 
        {
            "location": "/Configuration/ssl/#converting-pkcs12-to-jks", 
            "text": "keytool -importkeystore -destkeystore keystore -srckeystore keystore.p12 -srcstoretype PKCS12", 
            "title": "Converting PKCS#12 to JKS"
        }, 
        {
            "location": "/Configuration/ssl/#import-root-and-intermediate-cas", 
            "text": "keytool -import -trustcacerts -alias root -file root.crt -keystore keystore", 
            "title": "Import Root and Intermediate CA's"
        }, 
        {
            "location": "/Configuration/ssl/#verifying", 
            "text": "To verify that the keystore is configured correctly:  keytool -list -keystore keystore    Which should produce something like:   Keystore type: JKS\nKeystore provider: SUN  Your keystore contains 1 entry  *.papertrail.co.za, Oct 29, 2015, PrivateKeyEntry,    The last line has a syntax of  {CN} {Expiry} {Key Type}     {CN}  should match the URL you would be accessing PaperTrail by  {Key Type}  must be PrivateKeyEntry", 
            "title": "Verifying"
        }, 
        {
            "location": "/Configuration/ssl/#configuring-client-authentication-mutual-ssl", 
            "text": "Configure server side SSL as above  Create a new a JKS file called  truststore  containing the trusted CA's  Check Require Client Certificates ( http.ssl.client.require )   Configuring client certificates requires that  all  clients supply a trusted certificate  The Common Name ( CN ) of the certificate will be used to map the a certificate to a user via the login field", 
            "title": "Configuring Client Authentication (Mutual SSL)"
        }, 
        {
            "location": "/Installation/Replication/", 
            "text": "Replication\n\n\nClean Install\n\n\n\n\nInstall PaperTrail on master.\n\n\nStartup master.\n\n\nShutdown master and create db dump.\n\n\n\n\n    db.replication.enable=true db.replication.external.id=master db.replication.group.id=master file.replication.upstream=http://slave:8080\n\n\n\n\n\n\nEnable replication on the master and start PaperTrail.\n\n\nRestore master dump on slave and copy over repository.\n\n\nEnable replication on slave and start PaperTrail.\n\n\n\n\ndb.replication.enable=true db.replication.external.id=slave db.replication.group.id=slave db.replication.master=replication1 file.replication.upstream=http://master:8080\n\n\n\n\nUpgrade\n\n\n\n\nShutdown PaperTrail on master and slave.\n\n\nUpgrade PaperTrail on master and startup.\n\n\nUpgrade PaperTrail on slave and startup.\n\n\n\n\nFilestore Replication\n\n\nWhen setting up file store replication to a secondary PaperTrail installation, follow the below points:\n\n\n\n\nWhen entering the URL to the secondary PT, include \"/store\" at the end of the PT URL e.g. http://\n:\n/store\n\n\nAlways tick the \"Async\" option. Not only is this option helpful for slow connections, but it also manages imports if the secondary PT is not available.", 
            "title": "Replication"
        }, 
        {
            "location": "/Installation/Replication/#replication", 
            "text": "", 
            "title": "Replication"
        }, 
        {
            "location": "/Installation/Replication/#clean-install", 
            "text": "Install PaperTrail on master.  Startup master.  Shutdown master and create db dump.       db.replication.enable=true db.replication.external.id=master db.replication.group.id=master file.replication.upstream=http://slave:8080   Enable replication on the master and start PaperTrail.  Restore master dump on slave and copy over repository.  Enable replication on slave and start PaperTrail.   db.replication.enable=true db.replication.external.id=slave db.replication.group.id=slave db.replication.master=replication1 file.replication.upstream=http://master:8080", 
            "title": "Clean Install"
        }, 
        {
            "location": "/Installation/Replication/#upgrade", 
            "text": "Shutdown PaperTrail on master and slave.  Upgrade PaperTrail on master and startup.  Upgrade PaperTrail on slave and startup.", 
            "title": "Upgrade"
        }, 
        {
            "location": "/Installation/Replication/#filestore-replication", 
            "text": "When setting up file store replication to a secondary PaperTrail installation, follow the below points:   When entering the URL to the secondary PT, include \"/store\" at the end of the PT URL e.g. http:// : /store  Always tick the \"Async\" option. Not only is this option helpful for slow connections, but it also manages imports if the secondary PT is not available.", 
            "title": "Filestore Replication"
        }, 
        {
            "location": "/Installation/Sizing/", 
            "text": "PaperTrail Server Requirements\n\n\n\n\n2 - 4GB RAM\n\n\n2 Modern CPU Cores\n\n\n20GB + free disk space\n\n\n\n\nDatabase\n\n\nThe database should be kept entirely in RAM on fast disks (SSD, RAID 1\nwith cache etc)\\\n\\\n As a rough guideline is 1GB of RAM per 1 million docs.\\\n A centralized database can be used, however\u00a0it can introduce latency.\n\n\nIndex Directory\n\n\nThe index directory is where Lucene stores all indexes for searching, as\na rule of thumb is its around 1 - 2 GB per million docs, more if full\ntext searching is enabled.\u00a0\\\n\\\n The index directory needs to be on fast disks (RAID 0, SSD) and does\nnot need to backed up as it can be easily and quickly (with full text\ndisabled) rebuilt.\n\n\nFile Repository\n\n\nThe file repository has lots of small file based IO, each file is stored\nby name as checksum, so once written a file is never updated only\ndeleted.\\\n It can safely be backed up and then archived.\\\n\\\n RAID 6+ is sufficient.\u00a0\\\n\\\n Files can also be stored on a object storage platform like Amazon S3,\nCaringo CAStore reducing the need for backups.\\\n\\\n Replication can also be configured between 2 PaperTrail instances using\nfile stores.\\", 
            "title": "Sizing"
        }, 
        {
            "location": "/Installation/Sizing/#papertrail-server-requirements", 
            "text": "2 - 4GB RAM  2 Modern CPU Cores  20GB + free disk space", 
            "title": "PaperTrail Server Requirements"
        }, 
        {
            "location": "/Installation/Sizing/#database", 
            "text": "The database should be kept entirely in RAM on fast disks (SSD, RAID 1\nwith cache etc)\\\n\\\n As a rough guideline is 1GB of RAM per 1 million docs.\\\n A centralized database can be used, however\u00a0it can introduce latency.", 
            "title": "Database"
        }, 
        {
            "location": "/Installation/Sizing/#index-directory", 
            "text": "The index directory is where Lucene stores all indexes for searching, as\na rule of thumb is its around 1 - 2 GB per million docs, more if full\ntext searching is enabled.\u00a0\\\n\\\n The index directory needs to be on fast disks (RAID 0, SSD) and does\nnot need to backed up as it can be easily and quickly (with full text\ndisabled) rebuilt.", 
            "title": "Index Directory"
        }, 
        {
            "location": "/Installation/Sizing/#file-repository", 
            "text": "The file repository has lots of small file based IO, each file is stored\nby name as checksum, so once written a file is never updated only\ndeleted.\\\n It can safely be backed up and then archived.\\\n\\\n RAID 6+ is sufficient.\u00a0\\\n\\\n Files can also be stored on a object storage platform like Amazon S3,\nCaringo CAStore reducing the need for backups.\\\n\\\n Replication can also be configured between 2 PaperTrail instances using\nfile stores.\\", 
            "title": "File Repository"
        }, 
        {
            "location": "/Installation/Windows/", 
            "text": "Windows Installations\n\n\n\n\nOn some versions of Windows 2012 you may need to install \nVisual C++\n\n\n\n\nSQL Server Windows Authentication\n\n\n\n\nCopy \nntmlauth.dll\n file to C:\\Windows \n\n\nFor remote installations, make sure that the Windows user granted DB\naccess is the same as the user that is being logged on to the application\nmachine.", 
            "title": "Windows"
        }, 
        {
            "location": "/Installation/Windows/#windows-installations", 
            "text": "On some versions of Windows 2012 you may need to install  Visual C++", 
            "title": "Windows Installations"
        }, 
        {
            "location": "/Installation/Windows/#sql-server-windows-authentication", 
            "text": "Copy  ntmlauth.dll  file to C:\\Windows   For remote installations, make sure that the Windows user granted DB\naccess is the same as the user that is being logged on to the application\nmachine.", 
            "title": "SQL Server Windows Authentication"
        }, 
        {
            "location": "/Installation/db-tuning/", 
            "text": "Database Performance Tuning\n\n\n\n\nUse READ COMMITTED default tx isolation level.\n\n\nUse a transaction logging mode that allows point in time recovery\n    (PITR) if possible\n\n\n\n\nRecommended PostgreSQL Settings\n\n\nmax_connections = 300 shared_buffers =\u00a01GB\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0# increase based on db and RAM size \ntemp_buffers = 1GB\u00a0\u00a0# increase based on db and RAM size \nmax_prepared_transactions = 0 \nwork_mem = 4MB \nmaintenance_work_mem = 512MB\neffective_io_concurrency = 4\u00a0\u00a0 \u00a0 \nwal_level = archive\u00a0\u00a0 \u00a0# allows PITR and restore \nfsync = on\u00a0\u00a0 # setting it to off can boost performance at the risk of full db corruption\nsynchronous_commit = on \u00a0# can be safely set to off full_page_writes = on\n\n\n\n\nRecommended MySQL Settings\n\n\ncharacter-set-server=utf8\ndefault-character-set=utf8\ndefault-storage-engine=INNODB\nmax_connections=800\n\n# 0 = log and flush once per second, set sync_binlog=2 # 2 = log on commit and flush once per second, set sync_binlog=2 \ninnodb_flush_log_at_trx_commit=1\u00a0 \nsync_binlog=1  \n\n# increase based on db size and RAM \ninnodb_buffer_pool_size=1G \ntx_isolation=READ-COMMITTED\nbinlog-format=ROW  \ntmp_table_size=64M \ninnodb_log_file_size=500M \nmax_allowed_packet=4M  \ninnodb_thread_concurrency=10 # make buffer pool instances roughly equal the size of the pool in GB's e.g. for an 8GB pool use: #innodb_buffer_pool_instances=8 \n\n# disable query cache \nquery_cache_size=0 \nquery_cache_type=0 \nthread_cache_size=10", 
            "title": "Db tuning"
        }, 
        {
            "location": "/Installation/db-tuning/#database-performance-tuning", 
            "text": "Use READ COMMITTED default tx isolation level.  Use a transaction logging mode that allows point in time recovery\n    (PITR) if possible", 
            "title": "Database Performance Tuning"
        }, 
        {
            "location": "/Installation/db-tuning/#recommended-postgresql-settings", 
            "text": "max_connections = 300 shared_buffers =\u00a01GB\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0# increase based on db and RAM size \ntemp_buffers = 1GB\u00a0\u00a0# increase based on db and RAM size \nmax_prepared_transactions = 0 \nwork_mem = 4MB \nmaintenance_work_mem = 512MB\neffective_io_concurrency = 4\u00a0\u00a0 \u00a0 \nwal_level = archive\u00a0\u00a0 \u00a0# allows PITR and restore \nfsync = on\u00a0\u00a0 # setting it to off can boost performance at the risk of full db corruption\nsynchronous_commit = on \u00a0# can be safely set to off full_page_writes = on", 
            "title": "Recommended PostgreSQL Settings"
        }, 
        {
            "location": "/Installation/db-tuning/#recommended-mysql-settings", 
            "text": "character-set-server=utf8\ndefault-character-set=utf8\ndefault-storage-engine=INNODB\nmax_connections=800\n\n# 0 = log and flush once per second, set sync_binlog=2 # 2 = log on commit and flush once per second, set sync_binlog=2 \ninnodb_flush_log_at_trx_commit=1\u00a0 \nsync_binlog=1  \n\n# increase based on db size and RAM \ninnodb_buffer_pool_size=1G \ntx_isolation=READ-COMMITTED\nbinlog-format=ROW  \ntmp_table_size=64M \ninnodb_log_file_size=500M \nmax_allowed_packet=4M  \ninnodb_thread_concurrency=10 # make buffer pool instances roughly equal the size of the pool in GB's e.g. for an 8GB pool use: #innodb_buffer_pool_instances=8 \n\n# disable query cache \nquery_cache_size=0 \nquery_cache_type=0 \nthread_cache_size=10", 
            "title": "Recommended MySQL Settings"
        }, 
        {
            "location": "/Installation/end-user-installation/", 
            "text": "Installation and Configuration\n\n\nSystem Requirements\n\n\nThe minimum requirements that are advised for Workstations are as follows:\n\n 2-4 GB RAM\n\n Dual Core i3/i5 CPU\n\n Internet Explorer 11/Edge OR\n\n Chrome (latest stable release) OR\n* Firefox (latest stable release)\n\n\nAdvanced Plugin\n\n\n\n\nClick on Help / Cog -\n Check Installation and then follow the instructions that will guide you through the installation process\n\n\n\n\nSee \nWindows\n\n\nFor silent installation use following command:\n\n\nPaperTrailSetup.exe /S\n\n\n\n\nDesktop Agent\n\n\nDownload and run the installer from \nhttp://downloads.papertrail.co.za\n\n\nSee \nWindows\n and \nLinux\n\n\nOffice Addin\n\n\nDownload and run the installer from \nhttp://downloads.papertrail.co.za\n\n\nSee \nWindows\n\n\nWeb Scan\n\n\nWeb scan is distributed as an addon to the Advanced Plugin:\n\n\n\n\nInstall the Advanced Plugin\n\n\nDownload and Install the Web Scan Addon from \nDownloads\n\n\nConfigure scan profiles under System -\n Scanning", 
            "title": "End user installation"
        }, 
        {
            "location": "/Installation/end-user-installation/#installation-and-configuration", 
            "text": "", 
            "title": "Installation and Configuration"
        }, 
        {
            "location": "/Installation/end-user-installation/#system-requirements", 
            "text": "The minimum requirements that are advised for Workstations are as follows:  2-4 GB RAM  Dual Core i3/i5 CPU  Internet Explorer 11/Edge OR  Chrome (latest stable release) OR\n* Firefox (latest stable release)", 
            "title": "System Requirements"
        }, 
        {
            "location": "/Installation/end-user-installation/#advanced-plugin", 
            "text": "Click on Help / Cog -  Check Installation and then follow the instructions that will guide you through the installation process   See  Windows  For silent installation use following command:  PaperTrailSetup.exe /S", 
            "title": "Advanced Plugin"
        }, 
        {
            "location": "/Installation/end-user-installation/#desktop-agent", 
            "text": "Download and run the installer from  http://downloads.papertrail.co.za  See  Windows  and  Linux", 
            "title": "Desktop Agent"
        }, 
        {
            "location": "/Installation/end-user-installation/#office-addin", 
            "text": "Download and run the installer from  http://downloads.papertrail.co.za  See  Windows", 
            "title": "Office Addin"
        }, 
        {
            "location": "/Installation/end-user-installation/#web-scan", 
            "text": "Web scan is distributed as an addon to the Advanced Plugin:   Install the Advanced Plugin  Download and Install the Web Scan Addon from  Downloads  Configure scan profiles under System -  Scanning", 
            "title": "Web Scan"
        }, 
        {
            "location": "/Installation/server-installation/", 
            "text": "Installation and Configuration\n\n\nInstallation\n\n\nTo install PaperTrail you will first need to install the prequisties:\n\n\n\n\nJava 8 SDK\n\n\nPostgreSQL or MS SQL on localhost or remote server\n\n\n\n\nLibreOffice\n\n\n\n\n\n\nDownload and run the installer - this can be done silently using the \n-q\n option\n\n\n\n\nAccess the installation wizard at \nhttp://localhost:8080\n \n\n\nWhen complete conduct a \nHealth Check\n  \n\n\n\n\nSee \nWindows\n, \n \nLinux\n, \nMacOSX\n \n\n\nUpgrades\n\n\n\n\nRun a full \nbackup\n\nRename the \nPapertrail\n installation folder according to date of upgrade and current version, i.e. \nPapertrail_2013-03-04_r864\n as it allows for simplified rollbacks\n\n\nRun the installer\n\n(If applicable also reconfigure the service under the correct user account)\n\n\nTurn on \nmaintenance mode\n\n\nStart PaperTrail and Conduct a health check\n\n\nTurn off \nmaintenance mode\n\n\n\n\nMore Links\n\n\nService options\n\n\nBackups\n\n\nReplication\n\n\nLDAP / Active Directory", 
            "title": "Server installation"
        }, 
        {
            "location": "/Installation/server-installation/#installation-and-configuration", 
            "text": "", 
            "title": "Installation and Configuration"
        }, 
        {
            "location": "/Installation/server-installation/#installation", 
            "text": "To install PaperTrail you will first need to install the prequisties:   Java 8 SDK  PostgreSQL or MS SQL on localhost or remote server   LibreOffice    Download and run the installer - this can be done silently using the  -q  option   Access the installation wizard at  http://localhost:8080    When complete conduct a  Health Check      See  Windows , \n  Linux ,  MacOSX", 
            "title": "Installation"
        }, 
        {
            "location": "/Installation/server-installation/#upgrades", 
            "text": "Run a full  backup \nRename the  Papertrail  installation folder according to date of upgrade and current version, i.e.  Papertrail_2013-03-04_r864  as it allows for simplified rollbacks  Run the installer \n(If applicable also reconfigure the service under the correct user account)  Turn on  maintenance mode  Start PaperTrail and Conduct a health check  Turn off  maintenance mode", 
            "title": "Upgrades"
        }, 
        {
            "location": "/Installation/server-installation/#more-links", 
            "text": "Service options  Backups  Replication  LDAP / Active Directory", 
            "title": "More Links"
        }, 
        {
            "location": "/Installation/service/", 
            "text": "Configuring service settings\n\n\nOS\n                               Linux\n  \nConfiguration applied in\n         /opt/Papertrail/run.sh\n\n\nConfiguration Options\n\n\n\n\nOption\n               -Xmx                     -Xms\n  \nDescription\n          Max memory               Min memory\n  \nExample\n              -Xmx2048M                -Xms2048M", 
            "title": "Service"
        }, 
        {
            "location": "/Installation/service/#configuring-service-settings", 
            "text": "OS                                Linux\n   Configuration applied in          /opt/Papertrail/run.sh", 
            "title": "Configuring service settings"
        }, 
        {
            "location": "/Installation/service/#configuration-options", 
            "text": "Option                -Xmx                     -Xms\n   Description           Max memory               Min memory\n   Example               -Xmx2048M                -Xms2048M", 
            "title": "Configuration Options"
        }, 
        {
            "location": "/Installation/solution/", 
            "text": "Deploying Solutions\n\n\n\n\nFirst take a full \nbackup\n if possible.\n\n\nNB: Turn on \nMaintenance Mode\n\n\nNote A SolutionPack.zip is used in the examples below, however each solution will have it's own filename e.g.  Travel.zip, HR.zip\n\n\n\n\n\n\n\n\nVia the CLI\n\n\npt deploy SolutionPack.zip\n\n\nVia the GUI\n\n\n\n\nGo to the Admin \n Services \n Tasks \n Bulk Import \n Deploy Pack\n\n\n\n\nSelect the \nSolutionPack.zip\n\n\n\n\n\n\nThen conduct a \nHealth Check\n\n\n\n\nFinally turn off \nMaintenance Mode", 
            "title": "Solution"
        }, 
        {
            "location": "/Installation/solution/#deploying-solutions", 
            "text": "First take a full  backup  if possible.  NB: Turn on  Maintenance Mode  Note A SolutionPack.zip is used in the examples below, however each solution will have it's own filename e.g.  Travel.zip, HR.zip", 
            "title": "Deploying Solutions"
        }, 
        {
            "location": "/Installation/solution/#via-the-cli", 
            "text": "pt deploy SolutionPack.zip", 
            "title": "Via the CLI"
        }, 
        {
            "location": "/Installation/solution/#via-the-gui", 
            "text": "Go to the Admin   Services   Tasks   Bulk Import   Deploy Pack   Select the  SolutionPack.zip    Then conduct a  Health Check   Finally turn off  Maintenance Mode", 
            "title": "Via the GUI"
        }, 
        {
            "location": "/Integration/Database/", 
            "text": "Data Sources\n\n\nA DataSource is a generic abstraction over access and querying databases, it can be linked directly to List, and called via the frontend via the \n/data/{datasource name}/\n. The type of datasource can also be switched (provided the name is retained) to allow different implementations during production / staging etc..\n\n\n\n\nDatabase connections are pooled based on connection string and username\n\n\nColumn headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d function\n\n\nAll native SQL commands and functions can be used in the statement\n\n\nSeparate columns in SELECT statements by commas\n\n\nIf column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name\n\n\n\n\n\n\nIt is recommended to use system properties to specify the URL, Username and Password so that they can be externalized and reused across multiple rules. e.g. \n${lob.db.url}\n\n\n\n\nParamaters are passed via \n${param1}\n expressions e.g.\n\n\n SELECT * FROM Invoices WHERE Invoice_No = '${invoice_no}\n\n\n\n\nUsing \nUPDATE\n, \nDELETE\n, \nEXEC\n or \nINSERT\n SQL keywords will use \nPreparedStatement.executeUpdate()\n while all other Keywords will use \nPreparedStatement.executeQuery\n\n\nDirect Access\n\n\nYou can also use direct JDBC or the SQLUtils library to access external databases via a runScript rule - Ensure that you follow the pattern below\n\n\nimport com.egis.datasource.JdbcDataSourceCache\nimport com.egis.kernel.Kernel\nimport com.egis.utils.SQLUtils\nimport javax.sql.DataSource\n\nString url = System.getProperty(\nlob.db.url\n);\nString username = System.getProperty(\nlob.db.username\n);\nString password  = System.getProperty(\nlob.db.password\n);\nDataSource ds = Kernel.get(JdbcDataSourceCache.class).get(url, username, password)\n\nSQLUtils.executeStatement(ds, \nEXEC sp.StoreProc(?,?,?)\n, \nparam1\n, \nparam2\n, \nparam3\n)\n\n\n\n\n\n\nNote that a \nConnection\n or \nDataSource\n is not created directly but delegated to \nJdbcDataSourceCache\n so that connection pooling can occur", 
            "title": "Database"
        }, 
        {
            "location": "/Integration/Database/#data-sources", 
            "text": "A DataSource is a generic abstraction over access and querying databases, it can be linked directly to List, and called via the frontend via the  /data/{datasource name}/ . The type of datasource can also be switched (provided the name is retained) to allow different implementations during production / staging etc..   Database connections are pooled based on connection string and username  Column headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d function  All native SQL commands and functions can be used in the statement  Separate columns in SELECT statements by commas  If column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name    It is recommended to use system properties to specify the URL, Username and Password so that they can be externalized and reused across multiple rules. e.g.  ${lob.db.url}   Paramaters are passed via  ${param1}  expressions e.g.   SELECT * FROM Invoices WHERE Invoice_No = '${invoice_no}  Using  UPDATE ,  DELETE ,  EXEC  or  INSERT  SQL keywords will use  PreparedStatement.executeUpdate()  while all other Keywords will use  PreparedStatement.executeQuery", 
            "title": "Data Sources"
        }, 
        {
            "location": "/Integration/Database/#direct-access", 
            "text": "You can also use direct JDBC or the SQLUtils library to access external databases via a runScript rule - Ensure that you follow the pattern below  import com.egis.datasource.JdbcDataSourceCache\nimport com.egis.kernel.Kernel\nimport com.egis.utils.SQLUtils\nimport javax.sql.DataSource\n\nString url = System.getProperty( lob.db.url );\nString username = System.getProperty( lob.db.username );\nString password  = System.getProperty( lob.db.password );\nDataSource ds = Kernel.get(JdbcDataSourceCache.class).get(url, username, password)\n\nSQLUtils.executeStatement(ds,  EXEC sp.StoreProc(?,?,?) ,  param1 ,  param2 ,  param3 )   Note that a  Connection  or  DataSource  is not created directly but delegated to  JdbcDataSourceCache  so that connection pooling can occur", 
            "title": "Direct Access"
        }, 
        {
            "location": "/Integration/data-sources/", 
            "text": "Data Sources\n\n\nData sources allow for data to be looked up in a centralized fashion -\nthese data sources are always referenced by name so they can differ in\nproduction and dev environments - both in parameters and type.\n\n\nSystem properties can also be used for the URL, username and password\nfields:\\\n e.g.\\\n\n\n${external.db.username} ${external.db.password} jdbc:mysql://${external.db.host}/\n{.ini}\\\n The properties can then be added to a .properties file in the\nPapertrail/conf installation folder\\\n \u00a0\n\n\nJDBC\n\n\nConnect to any remote database accessible via a JDBC URL examples of\nwhich are:\n\n\njdbc:mysql://host:3306/{db}\n{.sql}\n\n\njdbc:sqlserver://host:1443;databaseName={db}\n{.sql}\n\n\njdbc:postgresql://host:5432/{db}\n{.sql}\n\n\nParameters can be specified using \n\\${param}\n syntax (they are\nescaped to prevent SQL Injection):\n e.g.\n\n\nSELECT index1 as name, index2 as value FROM external_table WHERE index3 LIKE '${filter}'\n{.sql}\n\n\nNote the \naliasing\n to \nname\n and \nvalue\n which is required to\ncorrectly render in lookup fields/lists.\n\n\nAlthough any parameter can be used \n\\${filter}\n is reserved for user\nentered input.\n\n\nLocal DB\n\n\nA subtype of JDBC - connects to same database as PaperTrail can be used\nto query papertrail core tables, import and sync tables, or any other\ntable added to this db.\\\n \u00a0\n\n\nNode Query\n\n\nReturns the result of a PQL query - Commonly used for config nodes.\n \u00a0\n\n\nScripted\n\n\nAllows groovy script to be executed to return any arbritrary list of\ndata.", 
            "title": "Data sources"
        }, 
        {
            "location": "/Integration/data-sources/#data-sources", 
            "text": "Data sources allow for data to be looked up in a centralized fashion -\nthese data sources are always referenced by name so they can differ in\nproduction and dev environments - both in parameters and type.  System properties can also be used for the URL, username and password\nfields:\\\n e.g.\\  ${external.db.username} ${external.db.password} jdbc:mysql://${external.db.host}/ {.ini}\\\n The properties can then be added to a .properties file in the\nPapertrail/conf installation folder\\", 
            "title": "Data Sources"
        }, 
        {
            "location": "/Integration/data-sources/#jdbc", 
            "text": "Connect to any remote database accessible via a JDBC URL examples of\nwhich are:  jdbc:mysql://host:3306/{db} {.sql}  jdbc:sqlserver://host:1443;databaseName={db} {.sql}  jdbc:postgresql://host:5432/{db} {.sql}  Parameters can be specified using  \\${param}  syntax (they are\nescaped to prevent SQL Injection):\n e.g.  SELECT index1 as name, index2 as value FROM external_table WHERE index3 LIKE '${filter}' {.sql}  Note the  aliasing  to  name  and  value  which is required to\ncorrectly render in lookup fields/lists.  Although any parameter can be used  \\${filter}  is reserved for user\nentered input.", 
            "title": "JDBC"
        }, 
        {
            "location": "/Integration/data-sources/#local-db", 
            "text": "A subtype of JDBC - connects to same database as PaperTrail can be used\nto query papertrail core tables, import and sync tables, or any other\ntable added to this db.\\", 
            "title": "Local DB"
        }, 
        {
            "location": "/Integration/data-sources/#node-query", 
            "text": "Returns the result of a PQL query - Commonly used for config nodes.", 
            "title": "Node Query"
        }, 
        {
            "location": "/Integration/data-sources/#scripted", 
            "text": "Allows groovy script to be executed to return any arbritrary list of\ndata.", 
            "title": "Scripted"
        }, 
        {
            "location": "/Integration/folder-watch/", 
            "text": "Normal\n\n\nAny file dropped into the Watched Folder will be imported into the specified node.\u00a0\n\n\nCSV\n\n\nPaperTrail will scan the watched folder for any CSV file. The CSV will then be processed and matching files will be imported with their indexes.  \n\n\nSample.csv\n  \n\n\nfilename,index1,index2  \nSample1.txt,value1,value2  \nSample2.txt,value3,value4\n\n\n\nSample1.txt\n  \n\n\nJust some content in Sample1\n\n\n\nSample2.txt\n  \n\n\nJust some content in Sample2\n\n\n\nIn this example \nSample1.txt\n and \nSample2.txt\n would get imported with the index values (value1,value1) and (value3,value4) respectively\u00a0\n\n\nImport and Sync\n\n\nImport ant sync works by creating a temporary staging table to contain metadata coming from external systems - This metadata is dropped off in a XML or CSV file. A mapping file is used to map and reformat the data in these files, the mapping file takes the format of a CSV file imported into PaperTrail with the following columns:  \n\n\n\n\n\n\n\n\n\n\n\nColumn\n\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\n\n\nCSV Only - The name of the CSV column\n\n\n\n\n\n\n\n\n\nxpath\u00a0\u00a0\u00a0\u00a0\n\n\n\nXML Only - The XPATH to use\u00a0\n\n\n\n\n\n\n\n\n\nindex\n\n\n\nThe PaperTrail node index name\n\n\n\n\n\n\n\n\n\nexpression\n\n\n\nOptional - A Groovy standard expression used to filter or reformat the data\u00a0  \ne.g  \n\nPREFIX-${value}\n - Add a prefix to the value  \n\n${value.find('\\d+')}\n - Extract only digits using a regular expression\n\n\n\n\n\n\n\n\n\nformat\n\n\n\nOptional - The date format of the value in the CSV/XML - PaperTrail will parse the date using this format and then reformat it using the configured system wide format for consistency.\n\n\n\n\n\n\n\n\n\n\n\n\nMapping.csv\n\n\nname,index,expression,format  \nindex 1,filename,,  \nindex 2,index2,,  \nindex 3,index3,${value}-smith,  \ndate 3,date3,,dd/MM/yyyy\n\n\n\nData.csv\n  \n\n\nindex 1,index 2,date 3,index 3  \nfile1,oncreate,01/01/2015,john\n\n\n\nXML Mapping.csv\n\n\nxpath,index,format,expression  \n/Data/index1/@value,filename,  \n/Data/index2/text(),index2,  \n/Data/index3/text(),index3,,${value}-smith  \n/Data/date3/text(),date3,MM/dd/yyyy,\n\n\n\nData.xml\n\n\n?xml version=\"1.0\"?\n\n\nData\n\n    \nindex1 value=\"file1\"/\n\n    \nindex2\nonupdate\n/index2\n\n    \nindex3\njohn\n/index3\n\n    \ndate3\n01/01/2015\n/date3\n\n\n/Data\n\n\n\n\nStructured\n\n\nStructured imports import raw textual data and overlay it onto a PDF Template.\u00a0\n\nA Datamap file is used to map blocks of text to fields in the PDF.\u00a0\n\nThe raw data can optionally be processed through a executable (exe) or a groovy script to format it, so that the datamap can extract the content correctly.\u00a0\n\n\nUpdate\n\n\nDeprecated in favour of Import and Sync CSV or XML\n\n\nAttach To Form\n\n\nThis will spawn the specified form and attach the document dropped in the watched folder to the form.\u00a0\n\n\nDocument Archive\n\n\nThis will import a complete document with all versions, indexes, notes, etc. Document Archives are created using Bulk Export or an Auto Export rule.", 
            "title": "Folder watch"
        }, 
        {
            "location": "/Integration/folder-watch/#normal", 
            "text": "Any file dropped into the Watched Folder will be imported into the specified node.", 
            "title": "Normal"
        }, 
        {
            "location": "/Integration/folder-watch/#csv", 
            "text": "PaperTrail will scan the watched folder for any CSV file. The CSV will then be processed and matching files will be imported with their indexes.    Sample.csv     filename,index1,index2  \nSample1.txt,value1,value2  \nSample2.txt,value3,value4  Sample1.txt     Just some content in Sample1  Sample2.txt     Just some content in Sample2  In this example  Sample1.txt  and  Sample2.txt  would get imported with the index values (value1,value1) and (value3,value4) respectively", 
            "title": "CSV"
        }, 
        {
            "location": "/Integration/folder-watch/#import-and-sync", 
            "text": "Import ant sync works by creating a temporary staging table to contain metadata coming from external systems - This metadata is dropped off in a XML or CSV file. A mapping file is used to map and reformat the data in these files, the mapping file takes the format of a CSV file imported into PaperTrail with the following columns:       Column  Description      name  CSV Only - The name of the CSV column    xpath\u00a0\u00a0\u00a0\u00a0  XML Only - The XPATH to use\u00a0    index  The PaperTrail node index name    expression  Optional - A Groovy standard expression used to filter or reformat the data\u00a0  \ne.g   PREFIX-${value}  - Add a prefix to the value   ${value.find('\\d+')}  - Extract only digits using a regular expression    format  Optional - The date format of the value in the CSV/XML - PaperTrail will parse the date using this format and then reformat it using the configured system wide format for consistency.     Mapping.csv  name,index,expression,format  \nindex 1,filename,,  \nindex 2,index2,,  \nindex 3,index3,${value}-smith,  \ndate 3,date3,,dd/MM/yyyy  Data.csv     index 1,index 2,date 3,index 3  \nfile1,oncreate,01/01/2015,john  XML Mapping.csv  xpath,index,format,expression  \n/Data/index1/@value,filename,  \n/Data/index2/text(),index2,  \n/Data/index3/text(),index3,,${value}-smith  \n/Data/date3/text(),date3,MM/dd/yyyy,  Data.xml  ?xml version=\"1.0\"?  Data \n     index1 value=\"file1\"/ \n     index2 onupdate /index2 \n     index3 john /index3 \n     date3 01/01/2015 /date3  /Data", 
            "title": "Import and Sync"
        }, 
        {
            "location": "/Integration/folder-watch/#structured", 
            "text": "Structured imports import raw textual data and overlay it onto a PDF Template.\u00a0 \nA Datamap file is used to map blocks of text to fields in the PDF.\u00a0 \nThe raw data can optionally be processed through a executable (exe) or a groovy script to format it, so that the datamap can extract the content correctly.", 
            "title": "Structured"
        }, 
        {
            "location": "/Integration/folder-watch/#update", 
            "text": "Deprecated in favour of Import and Sync CSV or XML", 
            "title": "Update"
        }, 
        {
            "location": "/Integration/folder-watch/#attach-to-form", 
            "text": "This will spawn the specified form and attach the document dropped in the watched folder to the form.", 
            "title": "Attach To Form"
        }, 
        {
            "location": "/Integration/folder-watch/#document-archive", 
            "text": "This will import a complete document with all versions, indexes, notes, etc. Document Archives are created using Bulk Export or an Auto Export rule.", 
            "title": "Document Archive"
        }, 
        {
            "location": "/Integration/ldap-ad/", 
            "text": "LDAP Configuration\n\n\nOpenLDAP\u00a0\n\n\nConfigure User format = \nuid=${user},o=Directory\n\n\n\n\n\n**Note:** Active directory will return less results and attributes when using port 3268 vs 389\n\n\n\n\n\nMultiple LDAP Servers\n\n\nConfigured by addition a set of properties per domain:\n\n\nldap.extra.**_domain1-corp.local_**.host=  \nldap.extra.domain1-corp.local.user=  \nldap.extra.domain1-corp.local.pass=  \nldap.extra._**domain2-corp.local**_.host=  \nldap.extra.domain2-corp.local.user=  \nldap.extra.domain2-corp.local.pass=\n\n\nSynchronizing With LDAP / Active Directory\n\n\nCheck \nLDAP -\n Auto Create\n \nusers\n to create new users from LDAP when they login\n\nCheck \nLDAP -\n Auto Sync Groups\n \u00a0to synchronize group membership, this will sync on user create and on the interval specified under \nAuthentication -\n Group Sync Interval\n\n\nYou can also specify a datasource under \nAuthentication -\n Group Sync Provider\n e.g. ds:groups \n\n\nSELECT memberOf as groups FROM '@ldap/objectClass=user\nSAMAccountName=${filter}\n\n\nTroubleshooting\n\n\n\n\nGet the LDAP queries that PaperTrail is executing by increasing the log level: \u00a0\ncom.egis.utils.ldap\u00a0in\u00a0\n8.8.4 or \ncom.egis.security.ldap\n\u00a0in 8.8.4+\n\n\n\n\nDEBUG\n to see the results of queries\n\n\nTRACE\n to see the actual query being run and authentication requests\n\n\n\n\nUse an off the shelf tool to check what options work when connecting:\n\n\n\n\nGUI:  \n\n\nhttp://jxplorer.org/\n\n\nhttp://www.ldapsoft.com/ldapbrowser/ldapadmintool.html\n  \n\n\nCLI:  \n\n\nldapsearch -h 172.16.237.131 -D \"administrator@corp.egis-software.com\" -w password -b \"cn=users,dc=corp,dc=egis-software,dc=com\" -s sub \"(\n(objectClass=user)(mail=*))\" '*'\n  \n\n\nUse tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the protocol level.  \n\n\n\n\nAdjust the LDAP query string in \nServices -\n Properties -\n LDAP\n as appropriate", 
            "title": "Ldap ad"
        }, 
        {
            "location": "/Integration/ldap-ad/#ldap-configuration", 
            "text": "OpenLDAP\u00a0  Configure User format =  uid=${user},o=Directory   **Note:** Active directory will return less results and attributes when using port 3268 vs 389", 
            "title": "LDAP Configuration"
        }, 
        {
            "location": "/Integration/ldap-ad/#synchronizing-with-ldap-active-directory", 
            "text": "Check  LDAP -  Auto Create   users  to create new users from LDAP when they login \nCheck  LDAP -  Auto Sync Groups  \u00a0to synchronize group membership, this will sync on user create and on the interval specified under  Authentication -  Group Sync Interval  You can also specify a datasource under  Authentication -  Group Sync Provider  e.g. ds:groups   SELECT memberOf as groups FROM '@ldap/objectClass=user SAMAccountName=${filter}", 
            "title": "Synchronizing With LDAP / Active Directory"
        }, 
        {
            "location": "/Integration/ldap-ad/#troubleshooting", 
            "text": "Get the LDAP queries that PaperTrail is executing by increasing the log level: \u00a0 com.egis.utils.ldap\u00a0in\u00a0 8.8.4 or  com.egis.security.ldap \u00a0in 8.8.4+   DEBUG  to see the results of queries  TRACE  to see the actual query being run and authentication requests   Use an off the shelf tool to check what options work when connecting:   GUI:    http://jxplorer.org/  http://www.ldapsoft.com/ldapbrowser/ldapadmintool.html     CLI:    ldapsearch -h 172.16.237.131 -D \"administrator@corp.egis-software.com\" -w password -b \"cn=users,dc=corp,dc=egis-software,dc=com\" -s sub \"( (objectClass=user)(mail=*))\" '*'     Use tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the protocol level.     Adjust the LDAP query string in  Services -  Properties -  LDAP  as appropriate", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/Reference/Document Properties/", 
            "text": "Document Properties\n\n\nDocument properties are available to use in:\n\n\n\n\nNode rule filters\n\n\nWorkflow filters\n\n\nStandard Expressions e.g. the body field in a sendEmail rule\n\n\n\n\n\n\n\n\n\n\nDocument Property\n\n\nGroovy Description\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndocId\n\n\nString\n\n\nThe document unique identifier. Formatted as a PaperTrail document ID.\n\n\n\n\n\n\ncreatedDate\n\n\nDate\n\n\nThe date that the document was created.\n\n\n\n\n\n\nfilename\n\n\nString\n\n\nThe filename of the document including the extension.\n\n\n\n\n\n\nlastModified\n\n\nDate\n\n\nThe date that the document was last modified. Can be empty.\n\n\n\n\n\n\ncreatedBy\n\n\nString\n\n\nThe name of the user who created the document.\n\n\n\n\n\n\ndispatchedBy\n\n\nString\n\n\nFor asynchronous rules, the user whose action triggered the event. Refer also to sessionUser.\n\n\n\n\n\n\next\n\n\nString\n\n\nA document extension suffix supported by PaperTrail. Does not contain the leading dot.\n\n\n\n\n\n\nip\n\n\nString\n\n\nThe IP address of the user who performed the action that triggered the event.\n\n\n\n\n\n\nname\n\n\nString\n\n\nThe filename of the document excluding the extension.\n\n\n\n\n\n\nsize\n\n\nLong\n\n\nThe size in bytes. Use this for a numeric comparison, for example: size \n 100000.\n\n\n\n\n\n\nsessionUser\n\n\nString\n\n\nFor synchronous rules, the current user. For asynchronous rules, System. Refer also to dispatchedBy.\n\n\n\n\n\n\nstatus\n\n\nString\n\n\nThe status of the document. Possible values are Filed, Current, Diarized, and Out.\n\n\n\n\n\n\nsizeFormatted\n\n\nString\n\n\nFormatted as bytes. For example, 1 KB, 5 MB, 1 GB\ufffcinstead of an integer such as 14328490234..\n\n\n\n\n\n\nvisibility\n\n\nString\n\n\nSets who is permitted to see the document. Valid values are Public, Private and Confidential..\n\n\n\n\n\n\ntitle\n\n\nString\n\n\nTitle.\n\n\n\n\n\n\nsubject\n\n\nString\n\n\nSubject.\n\n\n\n\n\n\nversion\n\n\nString\n\n\nA document version number, for example, 2.1. Can be empty.\n\n\n\n\n\n\n???\n\n\nString\n\n\nAn index that is added under Node Management \n Node \n Index.\n\n\n\n\n\n\n\n\nWritable Properties\n\n\nSome document properties are also editable, but most are read only.\n\n\n\n\nfilename\n\n\nvisibility\n\n\ntitle\n\n\nsubject\n\n\n{custom_index}\n\n\n\n\nto set a writeable property you can use a script:  \n\n\ndoc.metadata().set(\"title\", \"a new title\")\n\n\nOr a updateIndex rule  \n\n\ntitle=new title\n  \n\n\nor using the HTTP API:  \n\n\ncurl -x POST http://host/public/indexes/\ndocId\n/?title= a new title\n  \n\n\nDocument properties can also be updated via other mechanism for updating indexes including:\n\n\n\n\nImport and Sync\n\n\n.TXT files\n\n\n.XML indexes\n\n\n\n\nSpecial properties\n\n\nDue to the large number of places, indexes/properties can be updated. It being the single most common point of integration between systems, there are a few special properties that trigger actions. They are prefixed with \n_\n and not to be confused with normal properties that relate to metadata only.  \n\n\n\n\n\n\n\n\nDocument Property\n\n\nGroovy Description\n\n\n\n\n\n\n\n\n\n\n_audit\n\n\nCreates a new audit history event on the document\n\n\n\n\n\n\n_status\n\n\n_status=Filed will remove all current users of a document _status=Archive will archive the document\n\n\n\n\n\n\n_event\n\n\nDispatches a new Document event\n\n\n\n\n\n\nuser\n\n\nAllocates an user to the document\n\n\n\n\n\n\nowner\n\n\nAssigns ownership to the user\n\n\n\n\n\n\nnode\n\n\nMoves the document to the specified node\n\n\n\n\n\n\nvisibility\n\n\nChanges the visibility of the document\n\n\n\n\n\n\n\n\nArithmetic Operations\n\n\nMost properties and all custom index values are in String format. In order to use arithmetic in filters etc, you need to first convert them to a Number type. e.g.\n\n\ncustomNumberIndex.asInt() \n 10000\n  \n\n\nSee \nGroovy GDK String.asType()\n\n\nRounding\n\n\nIndexName=${(Double.valueOf(IndexName) * 1.14).round(2)}\n\n\nDates\n\n\nFor information about how to format dates, refer to \u00a0\nSimpleDateFormat", 
            "title": "Document Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#document-properties", 
            "text": "Document properties are available to use in:   Node rule filters  Workflow filters  Standard Expressions e.g. the body field in a sendEmail rule      Document Property  Groovy Description  Description      docId  String  The document unique identifier. Formatted as a PaperTrail document ID.    createdDate  Date  The date that the document was created.    filename  String  The filename of the document including the extension.    lastModified  Date  The date that the document was last modified. Can be empty.    createdBy  String  The name of the user who created the document.    dispatchedBy  String  For asynchronous rules, the user whose action triggered the event. Refer also to sessionUser.    ext  String  A document extension suffix supported by PaperTrail. Does not contain the leading dot.    ip  String  The IP address of the user who performed the action that triggered the event.    name  String  The filename of the document excluding the extension.    size  Long  The size in bytes. Use this for a numeric comparison, for example: size   100000.    sessionUser  String  For synchronous rules, the current user. For asynchronous rules, System. Refer also to dispatchedBy.    status  String  The status of the document. Possible values are Filed, Current, Diarized, and Out.    sizeFormatted  String  Formatted as bytes. For example, 1 KB, 5 MB, 1 GB\ufffcinstead of an integer such as 14328490234..    visibility  String  Sets who is permitted to see the document. Valid values are Public, Private and Confidential..    title  String  Title.    subject  String  Subject.    version  String  A document version number, for example, 2.1. Can be empty.    ???  String  An index that is added under Node Management   Node   Index.", 
            "title": "Document Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#writable-properties", 
            "text": "Some document properties are also editable, but most are read only.   filename  visibility  title  subject  {custom_index}   to set a writeable property you can use a script:    doc.metadata().set(\"title\", \"a new title\")  Or a updateIndex rule    title=new title     or using the HTTP API:    curl -x POST http://host/public/indexes/ docId /?title= a new title     Document properties can also be updated via other mechanism for updating indexes including:   Import and Sync  .TXT files  .XML indexes", 
            "title": "Writable Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#special-properties", 
            "text": "Due to the large number of places, indexes/properties can be updated. It being the single most common point of integration between systems, there are a few special properties that trigger actions. They are prefixed with  _  and not to be confused with normal properties that relate to metadata only.       Document Property  Groovy Description      _audit  Creates a new audit history event on the document    _status  _status=Filed will remove all current users of a document _status=Archive will archive the document    _event  Dispatches a new Document event    user  Allocates an user to the document    owner  Assigns ownership to the user    node  Moves the document to the specified node    visibility  Changes the visibility of the document", 
            "title": "Special properties"
        }, 
        {
            "location": "/Reference/Document Properties/#arithmetic-operations", 
            "text": "Most properties and all custom index values are in String format. In order to use arithmetic in filters etc, you need to first convert them to a Number type. e.g.  customNumberIndex.asInt()   10000     See  Groovy GDK String.asType()", 
            "title": "Arithmetic Operations"
        }, 
        {
            "location": "/Reference/Document Properties/#rounding", 
            "text": "IndexName=${(Double.valueOf(IndexName) * 1.14).round(2)}", 
            "title": "Rounding"
        }, 
        {
            "location": "/Reference/Document Properties/#dates", 
            "text": "For information about how to format dates, refer to \u00a0 SimpleDateFormat", 
            "title": "Dates"
        }, 
        {
            "location": "/Reference/Linking/", 
            "text": "Manipulating the linking critera\n\n\nLinking Documents On Numbers Only\n\n\nSpecific node links can be added to only search the digit portion of the index value using IF ELSE logic, i.e.\n\n\n    \nDestination Node\n/recursive=true\nDestination Index\n=${if (\nSource Index\n == null) \"\" else \nSource Index\n.find(\"\\\\d+\")}\n\n\n\nDestination Node: \n\n\nrecursive=true: when searching over multiple child nodes\n\n\nDestination Index: Index field you want to link to\n\n\nSource Index: Index field on node you're linking from\n\n\n${if (\n == null): If source index has no Value\n\n\n\"\" else \n.find(\"\\d+\")}: Find matching Numeric Value\n\n\n\n\nLinking on Numeric with custom field Order_No\n\n\neg. Order_No = 12345\n\n\n   \nDestination Node\n/recursive=true\nOrder_No=${if (Order_No == null) \"\" else Order_No.find(\"\\\\d+\")}\n\n\n\nLinking on Alphanumeric with custom field Order_No\n\n\neg. Order_No = PO12345\n\n\n  \"\" else Order_No.find(\"\\\\w+\")}\n\n\n\nLinking on Alphanumeric, Space, Numeric with custom field Order_No\n\n\neg. Order_No = PO 12345\n\n\n \"\" else Order_No.find(\"\\\\w+\\\\s+\\\\d+\")}\n\n\n\nRegex Examples eg.\n\n\n\\w+\n    : All alphanumeric values\n\n\n\\W\n     : A non-word character: [^\\w]\n\n\n\\d+\n    : All numeric values\n\n\n\\D\n     : A non-digit: [^0-9]\n\n\n\\s\n     : A whitespace character", 
            "title": "Linking"
        }, 
        {
            "location": "/Reference/Linking/#manipulating-the-linking-critera", 
            "text": "", 
            "title": "Manipulating the linking critera"
        }, 
        {
            "location": "/Reference/Linking/#linking-documents-on-numbers-only", 
            "text": "", 
            "title": "Linking Documents On Numbers Only"
        }, 
        {
            "location": "/Reference/Linking/#specific-node-links-can-be-added-to-only-search-the-digit-portion-of-the-index-value-using-if-else-logic-ie", 
            "text": "Destination Node /recursive=true Destination Index =${if ( Source Index  == null) \"\" else  Source Index .find(\"\\\\d+\")}", 
            "title": "Specific node links can be added to only search the digit portion of the index value using IF ELSE logic, i.e."
        }, 
        {
            "location": "/Reference/Linking/#destination-node", 
            "text": "", 
            "title": "Destination Node: "
        }, 
        {
            "location": "/Reference/Linking/#recursivetrue-when-searching-over-multiple-child-nodes", 
            "text": "", 
            "title": "recursive=true: when searching over multiple child nodes"
        }, 
        {
            "location": "/Reference/Linking/#destination-index-index-field-you-want-to-link-to", 
            "text": "", 
            "title": "Destination Index: Index field you want to link to"
        }, 
        {
            "location": "/Reference/Linking/#source-index-index-field-on-node-youre-linking-from", 
            "text": "", 
            "title": "Source Index: Index field on node you're linking from"
        }, 
        {
            "location": "/Reference/Linking/#if-null-if-source-index-has-no-value", 
            "text": "", 
            "title": "${if ( == null): If source index has no Value"
        }, 
        {
            "location": "/Reference/Linking/#else-find92d-find-matching-numeric-value", 
            "text": "", 
            "title": "\"\" else .find(\"\\d+\")}: Find matching Numeric Value"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-numeric-with-custom-field-order_no", 
            "text": "eg. Order_No = 12345      Destination Node /recursive=true Order_No=${if (Order_No == null) \"\" else Order_No.find(\"\\\\d+\")}", 
            "title": "Linking on Numeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-alphanumeric-with-custom-field-order_no", 
            "text": "eg. Order_No = PO12345    \"\" else Order_No.find(\"\\\\w+\")}", 
            "title": "Linking on Alphanumeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-alphanumeric-space-numeric-with-custom-field-order_no", 
            "text": "eg. Order_No = PO 12345   \"\" else Order_No.find(\"\\\\w+\\\\s+\\\\d+\")}", 
            "title": "Linking on Alphanumeric, Space, Numeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#regex-examples-eg", 
            "text": "", 
            "title": "Regex Examples eg."
        }, 
        {
            "location": "/Reference/Linking/#92w-all-alphanumeric-values", 
            "text": "", 
            "title": "\\w+    : All alphanumeric values"
        }, 
        {
            "location": "/Reference/Linking/#92w-a-non-word-character-w", 
            "text": "", 
            "title": "\\W     : A non-word character: [^\\w]"
        }, 
        {
            "location": "/Reference/Linking/#92d-all-numeric-values", 
            "text": "", 
            "title": "\\d+    : All numeric values"
        }, 
        {
            "location": "/Reference/Linking/#92d-a-non-digit-0-9", 
            "text": "", 
            "title": "\\D     : A non-digit: [^0-9]"
        }, 
        {
            "location": "/Reference/Linking/#92s-a-whitespace-character", 
            "text": "", 
            "title": "\\s     : A whitespace character"
        }, 
        {
            "location": "/Reference/health/", 
            "text": "Health checks should be conduced after evyer new installation, upgrade, custom deployment or major config change\n\n\nConducting Health Checks\n\n\n\n\nMonitor the log files under  (\nlogs\n) for any startup or migration errors\n\n\nCheck system health using \n/health\n and ensuring everything is \nGood\n\n\nLog into all applications used (\n/web/webapps\n, \n/web/admin\n,\n/web/portal\n, \n/web/capture\n etc..) and ensure they load and function correctly", 
            "title": "Health"
        }, 
        {
            "location": "/Reference/health/#conducting-health-checks", 
            "text": "Monitor the log files under  ( logs ) for any startup or migration errors  Check system health using  /health  and ensuring everything is  Good  Log into all applications used ( /web/webapps ,  /web/admin , /web/portal ,  /web/capture  etc..) and ensure they load and function correctly", 
            "title": "Conducting Health Checks"
        }, 
        {
            "location": "/Reference/licensing/", 
            "text": "Licensing Details\n\n\nFull\n\n\nFull\n - Full functionality including import via Desktop Agent and Office Add-In.\n\n\nFull v2\n - The same permissions as Full, but defaults to using the new UI\n\n\nCustom\n - Full but with a different starting page e.g. a custom tool or static form.\n\n\nSub Licenses\n\n\nSub licenses are not added directly. \nEach full license provides the ability to create 2 or more sub type users. \ne.g. 1 full user license allows 5 share users to be created.\n\n\nShare (5)\n - Cannot login, can only access PaperTrail from email links Sent via Share, Share Node and eSign actions.\n\n\nView (2)\n - View only functions, no import capabilities.\n\n\nDesktop (2)\n - Import only via Desktop Agent or PaperTrail Office Add-In, no login via front-end.\n\n\nPortal (External)\n\n\nPortal licenses are designed to allow external companies and users to login to a very minimal view to view documents that are logically owned by them e.g. Viewing invoices made out to you.\n\n\nPortal Users have the same permissons as \nView\n and are automatically redirected to the Classic Portal view:  http://\n:8080/web/portal/portal.html.\n\n\nScan\n\n\nSame as Full but also allows the use of the Web Scan client.\n\n\nDeprecated\n\n\nMobile\n Removed in 8.8.0, all users except desktop can use mobile.", 
            "title": "Licensing"
        }, 
        {
            "location": "/Reference/licensing/#licensing-details", 
            "text": "", 
            "title": "Licensing Details"
        }, 
        {
            "location": "/Reference/licensing/#full", 
            "text": "Full  - Full functionality including import via Desktop Agent and Office Add-In.  Full v2  - The same permissions as Full, but defaults to using the new UI  Custom  - Full but with a different starting page e.g. a custom tool or static form.", 
            "title": "Full"
        }, 
        {
            "location": "/Reference/licensing/#sub-licenses", 
            "text": "Sub licenses are not added directly. \nEach full license provides the ability to create 2 or more sub type users. \ne.g. 1 full user license allows 5 share users to be created.  Share (5)  - Cannot login, can only access PaperTrail from email links Sent via Share, Share Node and eSign actions.  View (2)  - View only functions, no import capabilities.  Desktop (2)  - Import only via Desktop Agent or PaperTrail Office Add-In, no login via front-end.", 
            "title": "Sub Licenses"
        }, 
        {
            "location": "/Reference/licensing/#portal-external", 
            "text": "Portal licenses are designed to allow external companies and users to login to a very minimal view to view documents that are logically owned by them e.g. Viewing invoices made out to you.  Portal Users have the same permissons as  View  and are automatically redirected to the Classic Portal view:  http:// :8080/web/portal/portal.html.", 
            "title": "Portal (External)"
        }, 
        {
            "location": "/Reference/licensing/#scan", 
            "text": "Same as Full but also allows the use of the Web Scan client.", 
            "title": "Scan"
        }, 
        {
            "location": "/Reference/licensing/#deprecated", 
            "text": "Mobile  Removed in 8.8.0, all users except desktop can use mobile.", 
            "title": "Deprecated"
        }, 
        {
            "location": "/Reference/linking_syntax/", 
            "text": "PaperTrail Document Linking Syntax\n\n\n\\\n Retrieving a document by docId\n\n\n\n\n\\\n \nGET: /public/file/100/test.doc\n{.sql}\\\n e.g.\\\n http://host:8080/public/file/100/test.doc\\\n\\\n \u00a0\n\n\nRetrieving a document by path\n\n\n\\\n \nGET: /public/file/Division/cabinet/test.doc/dummy.doc\n{.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc.\\\n\\\n N.B. A dummy filename must be appended to the path e.g. dummy.doc.\\\n\\\n \u00a0\n\n\nRetrieving an attachment\n\n\n\\\n \nGET: /public/file/100/test.doc?path=attachments/att01.doc\n{.sql}\\\n e.g.\\\n\n\nhttp://host:8080/public/file/Division/cabinet/test.doc?path=attachments/att01.doc\\\n\\\n \u00a0\n\n\nRetrieving a PDF for a document\n\n\n\\\n \nGET: /public/file/100/test.pdf?path=pdf\n{.sql}\\\n e.g.\\\n http://host:8080/public/file/100/test.pdf?path=pdf\\\n\\\n \u00a0\n\n\nRetrieving a version of a document\n\n\n\\\n \nGET: /public/file/100/test.doc?path=versions/0.2/source\n{.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc?\npath=versions/0.2/source\\\n\\\n \u00a0\n\n\nRetrieving a document via a query\n\n\n\\\n \nGET: /public/file/invoiceNo=AB123/test.doc\n{.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc?\npath=versions/0.2/source\\\n \u00a0\n\n\n\\\n Query Syntax\n\n\n\n\nDivision/Cabinet/*\n:   - Returns all documents directly under Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet?recursive=true\n:   - Returns all document under Division/Cabinet including documents in\n    sub nodes.\\\n     \u00a0\nDivision/Cabinet/test.doc\n:   - Returns the document where the filename is test.doc in\n    Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/filename=test.doc\n:   - Equivalent to the above query Division/Cabinet/filename=*.doc\n:   - Returns all documents that end in .doc\\\n     \u00a0\nDivision/Cabinet Division/Cabinet/filename*=test\n:   - Returns all documents that begin with test in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/test.doc?index1=value1\n:   - Returns the document where the filename is test.doc and\n    index1=value1 in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/index=value\n:   - Returns all documents where index1=value1 in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/index1=value1 \n index2=value2\n:   - Returns all documents where index1=value1 and index2=value2 in\n    Division/Cabinet.\\\n    \\\n     \u00a0\nindex1=value2\n:   - Returns all documents where index1=value1 in all nodes and folders\n    Equals.\n\n\nEquals = Not Equals != Contains *=* Starts With *= Ends With =* Between \n=\n Bigger Than (Number) \n= Smaller Than (Number) \n= After (Date) \n= Before (Date) \n= Is Empty !=!", 
            "title": "Linking syntax"
        }, 
        {
            "location": "/Reference/linking_syntax/#papertrail-document-linking-syntax", 
            "text": "\\\n Retrieving a document by docId   \\\n  GET: /public/file/100/test.doc {.sql}\\\n e.g.\\\n http://host:8080/public/file/100/test.doc\\\n\\", 
            "title": "PaperTrail Document Linking Syntax"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-document-by-path", 
            "text": "\\\n  GET: /public/file/Division/cabinet/test.doc/dummy.doc {.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc.\\\n\\\n N.B. A dummy filename must be appended to the path e.g. dummy.doc.\\\n\\", 
            "title": "Retrieving a document by path"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-an-attachment", 
            "text": "\\\n  GET: /public/file/100/test.doc?path=attachments/att01.doc {.sql}\\\n e.g.\\  http://host:8080/public/file/Division/cabinet/test.doc?path=attachments/att01.doc\\\n\\", 
            "title": "Retrieving an attachment"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-pdf-for-a-document", 
            "text": "\\\n  GET: /public/file/100/test.pdf?path=pdf {.sql}\\\n e.g.\\\n http://host:8080/public/file/100/test.pdf?path=pdf\\\n\\", 
            "title": "Retrieving a PDF for a document"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-version-of-a-document", 
            "text": "\\\n  GET: /public/file/100/test.doc?path=versions/0.2/source {.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc?\npath=versions/0.2/source\\\n\\", 
            "title": "Retrieving a version of a document"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-document-via-a-query", 
            "text": "\\\n  GET: /public/file/invoiceNo=AB123/test.doc {.sql}\\\n e.g.\\\n http://host:8080/public/file/Division/cabinet/test.doc?\npath=versions/0.2/source\\\n \u00a0  \\\n Query Syntax   Division/Cabinet/*\n:   - Returns all documents directly under Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet?recursive=true\n:   - Returns all document under Division/Cabinet including documents in\n    sub nodes.\\\n     \u00a0\nDivision/Cabinet/test.doc\n:   - Returns the document where the filename is test.doc in\n    Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/filename=test.doc\n:   - Equivalent to the above query Division/Cabinet/filename=*.doc\n:   - Returns all documents that end in .doc\\\n     \u00a0\nDivision/Cabinet Division/Cabinet/filename*=test\n:   - Returns all documents that begin with test in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/test.doc?index1=value1\n:   - Returns the document where the filename is test.doc and\n    index1=value1 in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/index=value\n:   - Returns all documents where index1=value1 in Division/Cabinet.\\\n     \u00a0\nDivision/Cabinet/index1=value1   index2=value2\n:   - Returns all documents where index1=value1 and index2=value2 in\n    Division/Cabinet.\\\n    \\\n     \u00a0\nindex1=value2\n:   - Returns all documents where index1=value1 in all nodes and folders\n    Equals.  Equals = Not Equals != Contains *=* Starts With *= Ends With =* Between  =  Bigger Than (Number)  = Smaller Than (Number)  = After (Date)  = Before (Date)  = Is Empty !=!", 
            "title": "Retrieving a document via a query"
        }, 
        {
            "location": "/Reference/maintenance/", 
            "text": "Maintenance Mode\n\n\n\n\nSetting maintenance mode is essential when conducting upgrades as it will ensure that no new documents/emails are imported after the upgrade is completed, as when a rollback is necessary, the imported documents will no longer be available in watched mailbox. \n\n\n\n\nTurning On Maintenance Mode:\n\n\n\n\nConfigure papertrail to start in maintenance mode by adding the following line to the \nconf/papertrail.properties\n\n\n\n\nmode=Maintenance\n\n\n\n\n\n\nRestart PaperTrail\n\n\n\n\nTurning Off Maintenance\n\n\n\n\nRemove or comment out the \nmode\n property in \nconf/papertrail.properties\n\n\nRestart PaperTrail", 
            "title": "Maintenance"
        }, 
        {
            "location": "/Reference/maintenance/#maintenance-mode", 
            "text": "Setting maintenance mode is essential when conducting upgrades as it will ensure that no new documents/emails are imported after the upgrade is completed, as when a rollback is necessary, the imported documents will no longer be available in watched mailbox.", 
            "title": "Maintenance Mode"
        }, 
        {
            "location": "/Reference/maintenance/#turning-on-maintenance-mode", 
            "text": "Configure papertrail to start in maintenance mode by adding the following line to the  conf/papertrail.properties   mode=Maintenance   Restart PaperTrail", 
            "title": "Turning On Maintenance Mode:"
        }, 
        {
            "location": "/Reference/maintenance/#turning-off-maintenance", 
            "text": "Remove or comment out the  mode  property in  conf/papertrail.properties  Restart PaperTrail", 
            "title": "Turning Off Maintenance"
        }, 
        {
            "location": "/Reference/pql/", 
            "text": "PQL\n\n\nPQL is an SQL-like language that can be used for querying and filtering data in PaperTrail. It can be used in the following places:  \n\n\n\n\n\n\nAnywhere where a query expression is used e.g. Advanced Search Reports, Queues, Scheduled Rules, Document linking etc.\n\n\n\n\n\n\nAs an alternative to groovy based expressions on node rule filters\ne.g. instead of:\n\nfilename == 'filename \n a == 'b'\n\nUse:\n\n\n\n\n\n\nWHERE filename = 'filename' AND a = 'b'\n\n\n\n\nPQL filters are fully case-insensitive and null safe so instead of: \nindex1 != null \n index1.toLowerCase() == 'abc'\n\nUse:\n\nWHERE index1 = 'abc'\n\n\nSyntax\n\n\nThe \nSELECT\n clause MUST contain exactly one of the following:\n\n\n\n\n\n\nA comma-separated list of one or more column names (node or document index names).  \n\n\n\n\nYou can use aliases to rename returned columns, e.g. column AS alias.  \n\n\nIf an explicit column list is provided: Only the columns listed will be returned and only in the order supplied.  \n\n\nNote : All standard indexes and any custom indexes will be returned in the default order  \n\n\nNote : Only custom indexes will be returned \n\n\n\n\n\n\n\n\nOne or more calls to aggregate functions.\n\n\n\n\nAggregate functions produce a single row output from multiple rows in a group.\n\n\n\n\n\n\n\n\nColumn Expressions\n\n\nGroovy expressions can be used to format data returned e.g. \n\n\nSELECT '${name[0]}' as Initial FROM Clients\n\n\n\n\nMultiple columns can also be referenced:\n\n\nSELECT '${LastName}, ${FirstName}' as FullName FROM Clients\n\n\n\n\nAs well as arithmetic on Number and Double indexes:\n\n\nSELECT '${total + vat}' as GrandTotal FROM 'Sales'\n\n\n\n\nFROM Clause\n\n\nThe FROM clause identifies which Virtual Table (Node) the query will be run against, as described in the previous section.\n\n\nThe FROM clause MUST contain the full path of a node, and MUST be single quoted if there are any spaces .e.g\n\n\nFROM parent/division\n\n\nFROM 'parent/sub folder/folder'\n\n\nWHERE\n\n\nThis clause identifies the constraints that rows MUST satisfy to be considered a result for the query.\n\n\nAll column names MUST be valid \u201cqueryName\u201d or their aliased values for properties that are defined as \u201cqueryable\u201d in the Object-Type(s) whose Virtual Tables are listed in the FROM clause.\n\n\nProperties are defined to not support a \u201cnull\u201d value, therefore the \n MUST be interpreted as testing the not set or set state of the specified property.\n\n\nComparisons permitted in the WHERE clause.\n\n\nPQL supports the following predicates:\n\n\n\n\n= (equals)  \n\n\n> (bigger than, after)  \n\n\n (smaller than, before)  \n\n\n\n\n\n\nNote: Bigger than / Less than and end equal to (\n=, \n=) are not supported\n\n\n\n\nDate values can be relative e.g.:\n\n\nSELECT docId FROM queryTests2 WHERE date1 \n '+7d'\n\n\n\n\n\n\ncontains\n\n\nnot contains\n\n\nstartsWith\n\n\nnot startsWith\n\n\nendWith\n\n\n\n\nnot endsWith\nBETWEEN and NOT BETWEEN predicates to compare on ranges\ne.g. column BETWEEN a AND b, is equivalent to column \n= a AND column \n= b \n\n\n\n\n\n\nIN  \n\n\n\n\nLIKE   \n\n\nIS NULL  \n\n\nIS NOT NULL  \n\n\nall_empty  \n\n\ne.g. a filter that matches when all 4 indexes are populated\nWHERE not all_empty (invoice_no,total,date,approved)\n\n\n\n\n\n\nnot all_empty  \n\n\nbefore, after   \n\n\n\n\nWHERE createdDate BEFORE '2015-01-01'\n\n\n\n\nWHERE Expressions\n\n\nExpressions can also be on both the left and and right side of WHERE clauses. e.g.\n\n\nSELECT name FROM Customers WHERE '${name[0]}' = 'A'\n\n\n\n\nOR\n\n\nSELECT number1 FROM queryTests2 WHERE 99 \n ${number1 + pqldouble1}\n\n\n\n\nORDER BY\n\n\n\n\nThis clause MUST use a single column to order by.\n\n\nAll column names referenced in this clause MUST be valid \u201cqueryName\u201d or alias (either for an aggregate function result or a column).\n\n\nOnly columns in the SELECT clause MAY be in the ORDER BY clause.\n\n\n\n\nGROUP BY\n\n\nThis clause specifies one or many columns to group by.\n\n\nSupported functions:\n\n\n\n\nCOUNT(column\n, \nCOUNT(*)\n - returns a number of entries in a group. COUNT(column) skips null values.\n\n\nAVG(column)\n - returns an average value of a column in a group.\n\n\nMIN(column)\n, \nMAX(column)\n - return a minimal or maximal value of a certain column in a group.\n\n\nSUM(column)\n - returns a sum of a column in a group.\n\n\n\n\nColumn references can also include groovy expressions e.g. \n\n\nSELECT sum(${time/60}) FROM Time  GROUP BY createdBy\n\n\n\n\nHAVING\n\n\nHaving is used to filter on values that have been grouped e.g.\n\n\nSELECT text1, SUM(number1) FROM queryTests2 GROUP BY text1 HAVING SUM(number1) \n 10\n\n\n\n\nOR\n\n\nSELECT text1, SUM(\\${number1 * 10}) AS totals FROM queryTests2 GROUP BY text1 HAVING totals \n 1000\n\n\n\n\nEscaping\n\n\nRepositories MUST support the escaping of characters using a backslash \n\\\n in the query statement.  The backslash character \n\\\n will be used to escape characters within quoted strings in the query as follows:\n\n\n\n\n\\\u2019 will represent a single-quote(\u2018) character\n\n\n\\ \\ will represent a backslash \n\\\n character\n\n\nWithin a LIKE string, \n\\%\n and \n\\_\n will represent the literal characters % and _, respectively.\n\n\nAll other instances of a \\ are errors.\n\n\n\n\nVirtual Data Sources\n\n\nFROM '@{VirtualDataSource}\n\n\n@WorkflowHistory\n\n\nThe workflow history virtual data source will return details about the unassigned and human tasks of a one or more documents e.g. \n\n\nSELECT * FROM '@WorkflowHistory' WHERE docId = 1\n\n\n\n\nWill return the following special columns:\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nallocation\n\n\nThe final user allocated\n\n\n\n\n\n\ncreatedBy\n\n\nWho the allocation was created by. This is not the creator of the document.\n\n\n\n\n\n\nposition\n\n\nThe workflow label of the task\n\n\n\n\n\n\nduration\n\n\nThe duration of the task e.g. 12 hours\n\n\n\n\n\n\nbusinessDuration\n\n\nThe duration of the task while in business hours e.g. 2 hours\n\n\n\n\n\n\nstart\n\n\nThe start date of the task\n\n\n\n\n\n\nend\n\n\nThe end date of the task\n\n\n\n\n\n\ndurationMillis\n\n\nThe duration of the task in milliseconds\n\n\n\n\n\n\n\n\nAny standard and custom indexes can also be merged into the results by adding them into the column list.\nAny standard search criteria can also be used\n\n\n@Activity\n\n\nReturns: \n\n\n\n\nDocument creations \n\n\nNew Notes \n\n\nAudits of configurable type = defaulting to Check In, Forward, Delete \n\n\n\n\nSELECT * FROM @Activity WHERE Node = 'Finance' AND user = 'X' \n\n\n\n\nequivalent to: \n\n\nSELECT * FROM @Activity/Finance WHERE user = 'X' \n\n\n\n\ndate\n is used for searching on the activity date (not the date of the document)\n\n\nSELECT * FROM @Activity WHERE date = '-7d' \n\n\n\n\n@QueueHistory", 
            "title": "Pql"
        }, 
        {
            "location": "/Reference/pql/#pql", 
            "text": "PQL is an SQL-like language that can be used for querying and filtering data in PaperTrail. It can be used in the following places:      Anywhere where a query expression is used e.g. Advanced Search Reports, Queues, Scheduled Rules, Document linking etc.    As an alternative to groovy based expressions on node rule filters\ne.g. instead of: filename == 'filename   a == 'b' \nUse:    WHERE filename = 'filename' AND a = 'b'  PQL filters are fully case-insensitive and null safe so instead of:  index1 != null   index1.toLowerCase() == 'abc' \nUse: WHERE index1 = 'abc'", 
            "title": "PQL"
        }, 
        {
            "location": "/Reference/pql/#syntax", 
            "text": "The  SELECT  clause MUST contain exactly one of the following:    A comma-separated list of one or more column names (node or document index names).     You can use aliases to rename returned columns, e.g. column AS alias.    If an explicit column list is provided: Only the columns listed will be returned and only in the order supplied.    Note : All standard indexes and any custom indexes will be returned in the default order    Note : Only custom indexes will be returned      One or more calls to aggregate functions.   Aggregate functions produce a single row output from multiple rows in a group.", 
            "title": "Syntax"
        }, 
        {
            "location": "/Reference/pql/#column-expressions", 
            "text": "Groovy expressions can be used to format data returned e.g.   SELECT '${name[0]}' as Initial FROM Clients  Multiple columns can also be referenced:  SELECT '${LastName}, ${FirstName}' as FullName FROM Clients  As well as arithmetic on Number and Double indexes:  SELECT '${total + vat}' as GrandTotal FROM 'Sales'", 
            "title": "Column Expressions"
        }, 
        {
            "location": "/Reference/pql/#from-clause", 
            "text": "The FROM clause identifies which Virtual Table (Node) the query will be run against, as described in the previous section.  The FROM clause MUST contain the full path of a node, and MUST be single quoted if there are any spaces .e.g  FROM parent/division  FROM 'parent/sub folder/folder'", 
            "title": "FROM Clause"
        }, 
        {
            "location": "/Reference/pql/#where", 
            "text": "This clause identifies the constraints that rows MUST satisfy to be considered a result for the query.  All column names MUST be valid \u201cqueryName\u201d or their aliased values for properties that are defined as \u201cqueryable\u201d in the Object-Type(s) whose Virtual Tables are listed in the FROM clause.  Properties are defined to not support a \u201cnull\u201d value, therefore the   MUST be interpreted as testing the not set or set state of the specified property.  Comparisons permitted in the WHERE clause.  PQL supports the following predicates:   = (equals)    > (bigger than, after)     (smaller than, before)      Note: Bigger than / Less than and end equal to ( =,  =) are not supported   Date values can be relative e.g.:  SELECT docId FROM queryTests2 WHERE date1   '+7d'   contains  not contains  startsWith  not startsWith  endWith   not endsWith\nBETWEEN and NOT BETWEEN predicates to compare on ranges\ne.g. column BETWEEN a AND b, is equivalent to column  = a AND column  = b     IN     LIKE     IS NULL    IS NOT NULL    all_empty    e.g. a filter that matches when all 4 indexes are populated\nWHERE not all_empty (invoice_no,total,date,approved)    not all_empty    before, after      WHERE createdDate BEFORE '2015-01-01'", 
            "title": "WHERE"
        }, 
        {
            "location": "/Reference/pql/#where-expressions", 
            "text": "Expressions can also be on both the left and and right side of WHERE clauses. e.g.  SELECT name FROM Customers WHERE '${name[0]}' = 'A'  OR  SELECT number1 FROM queryTests2 WHERE 99   ${number1 + pqldouble1}", 
            "title": "WHERE Expressions"
        }, 
        {
            "location": "/Reference/pql/#order-by", 
            "text": "This clause MUST use a single column to order by.  All column names referenced in this clause MUST be valid \u201cqueryName\u201d or alias (either for an aggregate function result or a column).  Only columns in the SELECT clause MAY be in the ORDER BY clause.", 
            "title": "ORDER BY"
        }, 
        {
            "location": "/Reference/pql/#group-by", 
            "text": "This clause specifies one or many columns to group by.  Supported functions:   COUNT(column ,  COUNT(*)  - returns a number of entries in a group. COUNT(column) skips null values.  AVG(column)  - returns an average value of a column in a group.  MIN(column) ,  MAX(column)  - return a minimal or maximal value of a certain column in a group.  SUM(column)  - returns a sum of a column in a group.   Column references can also include groovy expressions e.g.   SELECT sum(${time/60}) FROM Time  GROUP BY createdBy", 
            "title": "GROUP BY"
        }, 
        {
            "location": "/Reference/pql/#having", 
            "text": "Having is used to filter on values that have been grouped e.g.  SELECT text1, SUM(number1) FROM queryTests2 GROUP BY text1 HAVING SUM(number1)   10  OR  SELECT text1, SUM(\\${number1 * 10}) AS totals FROM queryTests2 GROUP BY text1 HAVING totals   1000", 
            "title": "HAVING"
        }, 
        {
            "location": "/Reference/pql/#escaping", 
            "text": "Repositories MUST support the escaping of characters using a backslash  \\  in the query statement.  The backslash character  \\  will be used to escape characters within quoted strings in the query as follows:   \\\u2019 will represent a single-quote(\u2018) character  \\ \\ will represent a backslash  \\  character  Within a LIKE string,  \\%  and  \\_  will represent the literal characters % and _, respectively.  All other instances of a \\ are errors.", 
            "title": "Escaping"
        }, 
        {
            "location": "/Reference/pql/#virtual-data-sources", 
            "text": "FROM '@{VirtualDataSource}", 
            "title": "Virtual Data Sources"
        }, 
        {
            "location": "/Reference/pql/#workflowhistory", 
            "text": "The workflow history virtual data source will return details about the unassigned and human tasks of a one or more documents e.g.   SELECT * FROM '@WorkflowHistory' WHERE docId = 1  Will return the following special columns:     Column Name  Description      allocation  The final user allocated    createdBy  Who the allocation was created by. This is not the creator of the document.    position  The workflow label of the task    duration  The duration of the task e.g. 12 hours    businessDuration  The duration of the task while in business hours e.g. 2 hours    start  The start date of the task    end  The end date of the task    durationMillis  The duration of the task in milliseconds     Any standard and custom indexes can also be merged into the results by adding them into the column list.\nAny standard search criteria can also be used", 
            "title": "@WorkflowHistory"
        }, 
        {
            "location": "/Reference/pql/#activity", 
            "text": "Returns:    Document creations   New Notes   Audits of configurable type = defaulting to Check In, Forward, Delete    SELECT * FROM @Activity WHERE Node = 'Finance' AND user = 'X'   equivalent to:   SELECT * FROM @Activity/Finance WHERE user = 'X'   date  is used for searching on the activity date (not the date of the document)  SELECT * FROM @Activity WHERE date = '-7d'", 
            "title": "@Activity"
        }, 
        {
            "location": "/Reference/pql/#queuehistory", 
            "text": "", 
            "title": "@QueueHistory"
        }, 
        {
            "location": "/Reference/regex/", 
            "text": "============\n\n\nParagraphs are separated by a blank line.\n\n\n2nd paragraph. \nItalic\n, \nbold\n, and \nmonospace\n. Itemized lists\nlook like:\n\n\n\n\nthis one\n\n\nthat one\n\n\nthe other one\n\n\n\n\nNote that --- not considering the asterisk --- the actual text\ncontent starts at 4-columns in.\n\n\n\n\nBlock quotes are\nwritten like so.\n\n\nThey can span multiple paragraphs,\nif you like.\n\n\n\n\ncode block\n\n\n\n\nInline code `codez\n\n\nUse 3 dashes for an em-dash. Use 2 dashes for ranges (ex., \"it's all\nin chapters 12--14\"). Three dots ... will be converted to an ellipsis.\nUnicode is supported.", 
            "title": "Regex"
        }, 
        {
            "location": "/Troubleshooting/Performance/", 
            "text": "Check underlying system\n\n\n\n\nIs there enough memory? \u00a0Their should always be at least 1 - 2GB\n    free memory in production to avoid using swap space\n\n\nIs CPU Usage high? Then check the\u00a0\nCPU Usage guide\n\n\nCheck network performance via ICMP ping and Browser developer tools\n    network tab - Response times of \\\n 250ms are good \\\n 1s are\n    acceptable\n\n\n\n\nCheck the following resources for identifying lower level\n    bottlenecks\n\n\n\n\n\n\nhttp://www.brendangregg.com/usemethod.html\n\n\n\n\nhttp://www.brendangregg.com/linuxperf.html\n\n\nhttp://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html", 
            "title": "Performance"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/", 
            "text": "Troubleshooting high cpu usage\n\n\nBefore doing anything else\n\n\nBefore restarting PaperTrail always try and get a snapshot:\n\n\nhttp://localhost:8080/snapshot\n\n\nand/or a thread dump  \n\n\nhttp://localhost:8080/snapshot/threads\n\n\nIf the web interface is unresponsive use the command line to retrieve a\nthread dump.\n\n\nTaking a Memory Dump\n\n\nOn Linux: \n/etc/init.d/papertrail heap\n\nOn Windows \n \u00a0Run \njps\n to get the PID of the service and then \njstack\u00a0-dump:format=b,file=C:\\heap.bin \u00a0\nPID\n  \n\n\nCommon Causes of high CPU usage\n\n\nIf a single CPU core is at 100% \u00a0the culprit would normally be \u00a0 single\nthread that reoccurs in every single thread dump.\n\n\nIf all CPU cores are at 100% or near 100%, the cause is either:\n\n\na) memory exhaustion - very little free memory,\u00a0 \njstat\n \u00a0would return\nvery high garbage collection times (GC)\n\nb) an endless loop\n\nc) too many worker threads and/or too few cores\n \u00a0\n\n\nAnalyzing a Thread Dump\n\n\nAnalyzing a thread dump involves looking through all the threads on the\nrunning system to identify a) a pattern\u00a0\n\n\nAny thread in a \nTIMED_WAITING\n or \nWAITING\n state can be safely ignored\nas these threads are sleeping waiting for something else to occur.\n\n\nJetty threads in\nthe\u00a0\njava.net.SocketInputStream.socketRead RUNNING\nstate can also be\nignored as they are waiting for a client to make a TCP/IP connection", 
            "title": "Cpu usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#troubleshooting-high-cpu-usage", 
            "text": "", 
            "title": "Troubleshooting high cpu usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#before-doing-anything-else", 
            "text": "Before restarting PaperTrail always try and get a snapshot:  http://localhost:8080/snapshot  and/or a thread dump    http://localhost:8080/snapshot/threads  If the web interface is unresponsive use the command line to retrieve a\nthread dump.", 
            "title": "Before doing anything else"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#taking-a-memory-dump", 
            "text": "On Linux:  /etc/init.d/papertrail heap \nOn Windows   \u00a0Run  jps  to get the PID of the service and then  jstack\u00a0-dump:format=b,file=C:\\heap.bin \u00a0 PID", 
            "title": "Taking a Memory Dump"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#common-causes-of-high-cpu-usage", 
            "text": "If a single CPU core is at 100% \u00a0the culprit would normally be \u00a0 single\nthread that reoccurs in every single thread dump.  If all CPU cores are at 100% or near 100%, the cause is either:  a) memory exhaustion - very little free memory,\u00a0  jstat  \u00a0would return\nvery high garbage collection times (GC) \nb) an endless loop \nc) too many worker threads and/or too few cores", 
            "title": "Common Causes of high CPU usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#analyzing-a-thread-dump", 
            "text": "Analyzing a thread dump involves looking through all the threads on the\nrunning system to identify a) a pattern\u00a0  Any thread in a  TIMED_WAITING  or  WAITING  state can be safely ignored\nas these threads are sleeping waiting for something else to occur.  Jetty threads in\nthe\u00a0 java.net.SocketInputStream.socketRead RUNNING state can also be\nignored as they are waiting for a client to make a TCP/IP connection", 
            "title": "Analyzing a Thread Dump"
        }, 
        {
            "location": "/Troubleshooting/exceptions/", 
            "text": "java.io.IOException: Cannot run program \"pg\\_dump\": CreateProcess\nerror=2\n\n\u00a0The system cannot find the file specified\nAdd the Postgresql/bin directory to the System PATH environment\nvariable\n\n\njava.io.IOException: Cannot run program \"mysql\\_dump\"\n\n \u00a0The system cannot find the file specified\u00a0\nAdd the MySQL/bin directory to the System PATH environment variable\\\n \u00a0\n\nJDBCExceptionReporter [:] Cannot get a connection, pool error Timeout\nwaiting for idle object Database connection pool is exhausted,\n\n \u00a0- Check for database connection leak warning messages in the log files\nbeforehand\n\n \u00a0- Check database lookup configurations\n\n\nfailed \nSocketConnector@0.0.0.0\n:80:\n[java.net](http://java.net/).BindException: Permission denied\n\n\nTo run PaperTrail on port 80 you need to be root, change\nhttp.port=8080\\", 
            "title": "Exceptions"
        }
    ]
}