{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to PaperTrail Support Portal", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-papertrail-support-portal", 
            "text": "", 
            "title": "Welcome to PaperTrail Support Portal"
        }, 
        {
            "location": "/Configuration/Advanced Login/", 
            "text": "Advanced Login\n\n\nReset User\u2019s Password\n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then \nUser\n from the Navigation Menu.  \n\n\nSelect the user whose password you need to reset, and click \nReset Password\n. The password will be set to a blank password, which the user must then reset on his or her next login.\n\n\n\n\nRemember Me\n\n\n\n\nUnder \nProperties -\n Front End\n, uncheck \nEnable Remember Me\n to force users to enter their password every time.  \n\n\nWhen enabled, users will have the option to remember their password for up to the number of days specified under \nRemember Me Age\n.\n\n\n\n\nOne Time Passwords (OTP)\n\n\nOne time passwords are an additional security method. The login process is in 2 stages. First, a user logs in with a username and password. Next, PaperTrail sends an SMS message that contains a PIN to the user\u2019s mobile phone. The user enters the PIN to complete the login operation.  \n\n\nOne time passwords are a global. If a user does not have a mobile phone, then that user cannot log in with username and a password. However, the user can access PaperTrail with other SSO methods.\n\n\n\n\nMake sure that SMS Notifications are configured.  \n\n\nFrom \nServices \n Properties \n One Time Password\n, select \nRequire OTP SMS\n.", 
            "title": "Advanced Login"
        }, 
        {
            "location": "/Configuration/Advanced Login/#advanced-login", 
            "text": "", 
            "title": "Advanced Login"
        }, 
        {
            "location": "/Configuration/Advanced Login/#reset-users-password", 
            "text": "From within the  Administration interface , select  User Management  and then  User  from the Navigation Menu.    Select the user whose password you need to reset, and click  Reset Password . The password will be set to a blank password, which the user must then reset on his or her next login.", 
            "title": "Reset User\u2019s Password"
        }, 
        {
            "location": "/Configuration/Advanced Login/#remember-me", 
            "text": "Under  Properties -  Front End , uncheck  Enable Remember Me  to force users to enter their password every time.    When enabled, users will have the option to remember their password for up to the number of days specified under  Remember Me Age .", 
            "title": "Remember Me"
        }, 
        {
            "location": "/Configuration/Advanced Login/#one-time-passwords-otp", 
            "text": "One time passwords are an additional security method. The login process is in 2 stages. First, a user logs in with a username and password. Next, PaperTrail sends an SMS message that contains a PIN to the user\u2019s mobile phone. The user enters the PIN to complete the login operation.    One time passwords are a global. If a user does not have a mobile phone, then that user cannot log in with username and a password. However, the user can access PaperTrail with other SSO methods.   Make sure that SMS Notifications are configured.    From  Services   Properties   One Time Password , select  Require OTP SMS .", 
            "title": "One Time Passwords (OTP)"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/", 
            "text": "Advanced Permissions\n\n\nOnce you\u2019ve added a user, you need to specify what features that user can access. PaperTrail offers an extensible permissions system that makes it easy both to assign basic permissions to a large number of users.\n\n\nPaperTrail simplifies assigning permissions to users through two constructs: groups and roles. A group is a collection of users, while a role is a collection of permissions.\n\n\n\n\nNote: While it is possible to assign permissions to individual users, we recommend as a rule that administrators assign permissions to groups and roles, and then associate these groups and roles with users, as maintaining individual permissions becomes more complex as one\u2019s user base increases.\n\n\n\n\nWhen defining a permission for a group, role, or user, an administrator can specify one of three dispositions for that permission:\n\n-  \nPermit\n : Grants the permission to the specified entity.\n\n-  \nDeny\n: Forbids the specified entity from performing the defined action.\n\n-  \nImportant\n: overrides a Deny permissions.  \n\n\nPermissions Context\n\n\nHere is an overview of the different contexts in which permissions apply\n\n\n\n\n\n\n\n\nPermissions\n\n\nContext\n\n\n\n\n\n\n\n\n\n\nAll\n\n\nAlways Applies\n\n\n\n\n\n\nCreator\n\n\nApplies to the user who created a document. Note: In order to import a document in a node \nPermission=Import Context=All\n is required even though the Creator permissions will apply after import.\n\n\n\n\n\n\nOwner\n\n\nApplies to the user or group currently set as owner of the document.\n\n\n\n\n\n\nUser\n\n\nApplies to all the currently allocated users.\n\n\n\n\n\n\nPast User\n\n\nApplies to all previous users of a document.\n\n\n\n\n\n\nRecord\n\n\nApplies only to documents that have been declared a record.\n\n\n\n\n\n\n\n\nNote: In order to a see a folder in the node tree, \nPermission=SEE Context=ALL\n permissions are required as only the All context applies to nodes\n\n\nPermission Assignment\n\n\nRole Creation\n\n\nA set of permissions can be assigned to a role, and that role is assigned to one or more users.  \n\n\nRoles should be used when permissions need to be doled out to individuals not based on their membership in a particular group or team, but based on their responsibilities within a company. \n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then \nRole\n from the \nNavigation Menu\n.  \n\n\nSelect \nAdd\n from the \nCommand Bar\n.  \n\n\nOn the \nAdd Role\n dialog, enter a unique name for the \nrole\n in the \nName\n field. This name cannot be the same name as an existing \nuser, group, route, or role\n.   \n\n\nSelect the \npermissions\n to assign to this role from the available listbox, and then select the right arrow to add these permissions to the selected listbox.  \n\n\nSelect \nAdd\n to add the new \nrole\n to the system.  \n\n\n\n\nDocument visibility level\n\n\nTo create a new document visibility level :  \n\n\n\n\nUnder \nGeneral \u2192 Visibility\n  \n\n\nClick \nAdd\n.  \n\n\nLevel\n: Enter a unique numeric value e.g. 4.  \n\n\nDescription\n: Enter a \ndescription\n for the visibility level e.g. Very High.  \n\n\n\n\nGlobal Permissions\n\n\nTo apply Global Permissions, follow the below steps :  \n\n\n\n\nUnder \nUser Management -\n Global Permissions\n \u2013 Add any permissions required.\n\n\nCreating administrator level permissions.\n\n\nGlobal Administrators are defined as users with Admin on the Global Level.\n\n\nAdministrators are anyone with an Admin permission.\n\n\n\n\nAdministrator Permissions\n\n\nTo apply Administrator Permissions, follow the below steps :  \n\n\n\n\nGlobal Administrators are defined as users with Admin on the Global Level.  \n\n\nAdministrators are anyone with an Admin permission.  \n\n\n\n\nDenying Permissions to User\n\n\nDenying users out of a group permissions on a node :  \n\n\n\n\nGive the \ngroup permissions\n on the node with \nType = Permit\n.  \n\n\nDeny the \nuser permissions\n by using \nType = Deny\n.  \n\n\n\n\nCreator's permissions\n\n\n\n\nApply \npermissions\n in the \nCREATOR\n context\n\n\n\n\nOwner's permissions\n\n\n\n\nApply \npermissions\n in the \nOWNER\n  context\n\n\n\n\nUser's / Collaborator's  permissions\n\n\n\n\nApply \npermissions\n in the \nUSER\n  context \n\n\n\n\nRestrict Specific Node access\n\n\nTo deny administrators access to specific node, follow the below steps :  \n\n\n\n\nGive a user (e.g. HR Manager) \nIMPORTANT Permission Admin\n on the node \n\n\nIMPORTANT: This step must be completed first and verified or there is risk of being locked out of the node\n\n\n\n\n\n\nApply \nDENY Permission Admin\n to Everyone.  \n\n\nOnce applied only the user specified in step 1 will be able to add or remove permissions.  \n\n\nApply any other \nDENY permission\n required e.g. (Deny Role All to Everyone)  \n\n\nApply \nIMPORTANT permissions\n to give  access e.g. (IMPORTANT READ to HR Group)  \n\n\n\n\nApplying Index Level Permissions\n\n\nPermissions in PaperTrail are highly granular, and can even be applied to individual indexes.\n\n\n\n\nWithin the \nNodes interface\n, select a node.   \n\n\nIn the \nObject Browser\n, select an existing index for that node  \n\n\nFrom the \nCommand Bar\n on top of the Object Browser, select \nPermissions\n.  \n\n\nOnly two permissions can be set on a node, \nRead Metadata\n and \nWrite Metadata\n.  \n\n\nSelect one of these permissions from the \nPermission drop-down\n.  \n\n\nSelect whether this permission to either \nPermit, Deny, or Important\n.  \n\n\nSpecify the \nUser or Group\n to whom this permission applies. As you type a value in this box, PaperTrail will display an auto-completion list of matching users and groups.  \n\n\nSelect the \nAdd button\n to add the \nspecified permission\n to the index.  \n\n\nRepeat this process to add as many permissions to this index as needed. When you are done adding permissions, select the \nClose\n button.  \n\n\n\n\nSite-Wide Administrator\n\n\n\n\nWARNING: This permission grant gives a user \u201csuperuser\u201d access to your PaperTrail installation; it should only be granted rarely, and only to trusted individuals within your organization. Before granting site-wide administrator permissions, consider granting a more limited set of permissions for a specific purpose, such as \nList Admin or Node Admin.\n\n\n\n\nTo make another user a site-wide administrator, an existing administrator can grant an existing user the ALL role.   \n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then \nGlobal Permissions\n from the Navigation Menu.  \n\n\nClick \nAdd\n on the Command Bar.  \n\n\nLeave the \nPermission\n field blank.  \n\n\nFrom the \nRole drop-down\n, select All.  \n\n\nLeaving all other fields as is, select the \nAdd button\n. The specified user will now have access to all administrative features of the site.  \n\n\n\n\nLicense Type\n\n\nTo change the license,\n\n\n\n\nUpdate \nServices -\n Properties -\n General -\nLicense Code\n.", 
            "title": "Advanced Permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#advanced-permissions", 
            "text": "Once you\u2019ve added a user, you need to specify what features that user can access. PaperTrail offers an extensible permissions system that makes it easy both to assign basic permissions to a large number of users.  PaperTrail simplifies assigning permissions to users through two constructs: groups and roles. A group is a collection of users, while a role is a collection of permissions.   Note: While it is possible to assign permissions to individual users, we recommend as a rule that administrators assign permissions to groups and roles, and then associate these groups and roles with users, as maintaining individual permissions becomes more complex as one\u2019s user base increases.   When defining a permission for a group, role, or user, an administrator can specify one of three dispositions for that permission: \n-   Permit  : Grants the permission to the specified entity. \n-   Deny : Forbids the specified entity from performing the defined action. \n-   Important : overrides a Deny permissions.", 
            "title": "Advanced Permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#permissions-context", 
            "text": "Here is an overview of the different contexts in which permissions apply     Permissions  Context      All  Always Applies    Creator  Applies to the user who created a document. Note: In order to import a document in a node  Permission=Import Context=All  is required even though the Creator permissions will apply after import.    Owner  Applies to the user or group currently set as owner of the document.    User  Applies to all the currently allocated users.    Past User  Applies to all previous users of a document.    Record  Applies only to documents that have been declared a record.     Note: In order to a see a folder in the node tree,  Permission=SEE Context=ALL  permissions are required as only the All context applies to nodes", 
            "title": "Permissions Context"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#permission-assignment", 
            "text": "", 
            "title": "Permission Assignment"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#role-creation", 
            "text": "A set of permissions can be assigned to a role, and that role is assigned to one or more users.    Roles should be used when permissions need to be doled out to individuals not based on their membership in a particular group or team, but based on their responsibilities within a company.    From within the  Administration interface , select  User Management  and then  Role  from the  Navigation Menu .    Select  Add  from the  Command Bar .    On the  Add Role  dialog, enter a unique name for the  role  in the  Name  field. This name cannot be the same name as an existing  user, group, route, or role .     Select the  permissions  to assign to this role from the available listbox, and then select the right arrow to add these permissions to the selected listbox.    Select  Add  to add the new  role  to the system.", 
            "title": "Role Creation"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#document-visibility-level", 
            "text": "To create a new document visibility level :     Under  General \u2192 Visibility     Click  Add .    Level : Enter a unique numeric value e.g. 4.    Description : Enter a  description  for the visibility level e.g. Very High.", 
            "title": "Document visibility level"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#global-permissions", 
            "text": "To apply Global Permissions, follow the below steps :     Under  User Management -  Global Permissions  \u2013 Add any permissions required.  Creating administrator level permissions.  Global Administrators are defined as users with Admin on the Global Level.  Administrators are anyone with an Admin permission.", 
            "title": "Global Permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#administrator-permissions", 
            "text": "To apply Administrator Permissions, follow the below steps :     Global Administrators are defined as users with Admin on the Global Level.    Administrators are anyone with an Admin permission.", 
            "title": "Administrator Permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#denying-permissions-to-user", 
            "text": "Denying users out of a group permissions on a node :     Give the  group permissions  on the node with  Type = Permit .    Deny the  user permissions  by using  Type = Deny .", 
            "title": "Denying Permissions to User"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#creators-permissions", 
            "text": "Apply  permissions  in the  CREATOR  context", 
            "title": "Creator's permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#owners-permissions", 
            "text": "Apply  permissions  in the  OWNER   context", 
            "title": "Owner's permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#users-collaborators-permissions", 
            "text": "Apply  permissions  in the  USER   context", 
            "title": "User's / Collaborator's  permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#restrict-specific-node-access", 
            "text": "To deny administrators access to specific node, follow the below steps :     Give a user (e.g. HR Manager)  IMPORTANT Permission Admin  on the node   IMPORTANT: This step must be completed first and verified or there is risk of being locked out of the node    Apply  DENY Permission Admin  to Everyone.    Once applied only the user specified in step 1 will be able to add or remove permissions.    Apply any other  DENY permission  required e.g. (Deny Role All to Everyone)    Apply  IMPORTANT permissions  to give  access e.g. (IMPORTANT READ to HR Group)", 
            "title": "Restrict Specific Node access"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#applying-index-level-permissions", 
            "text": "Permissions in PaperTrail are highly granular, and can even be applied to individual indexes.   Within the  Nodes interface , select a node.     In the  Object Browser , select an existing index for that node    From the  Command Bar  on top of the Object Browser, select  Permissions .    Only two permissions can be set on a node,  Read Metadata  and  Write Metadata .    Select one of these permissions from the  Permission drop-down .    Select whether this permission to either  Permit, Deny, or Important .    Specify the  User or Group  to whom this permission applies. As you type a value in this box, PaperTrail will display an auto-completion list of matching users and groups.    Select the  Add button  to add the  specified permission  to the index.    Repeat this process to add as many permissions to this index as needed. When you are done adding permissions, select the  Close  button.", 
            "title": "Applying Index Level Permissions"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#site-wide-administrator", 
            "text": "WARNING: This permission grant gives a user \u201csuperuser\u201d access to your PaperTrail installation; it should only be granted rarely, and only to trusted individuals within your organization. Before granting site-wide administrator permissions, consider granting a more limited set of permissions for a specific purpose, such as \nList Admin or Node Admin.   To make another user a site-wide administrator, an existing administrator can grant an existing user the ALL role.      From within the  Administration interface , select  User Management  and then  Global Permissions  from the Navigation Menu.    Click  Add  on the Command Bar.    Leave the  Permission  field blank.    From the  Role drop-down , select All.    Leaving all other fields as is, select the  Add button . The specified user will now have access to all administrative features of the site.", 
            "title": "Site-Wide Administrator"
        }, 
        {
            "location": "/Configuration/Advanced Permissions/#license-type", 
            "text": "To change the license,   Update  Services -  Properties -  General - License Code .", 
            "title": "License Type"
        }, 
        {
            "location": "/Configuration/Backups/", 
            "text": "Backups\n\n\nWhat needs to be backed up?\n\n\n\n\nDatabase and transaction logs\n\n\nFile Repository (Everything under PT_Repo)\n\n\nSSL Certificate : conf/keystore (If configured)\n\n\nEncryption Keys : e.g. conf/keys.* If File store encryption is\n    configured\n\n\nIndexes : Only for very large installations where an index rebuild\n    is too time-consuming\n\n\n\n\nHow to backup?\n\n\nTo backup in PostgreSQL \n\n\ncd \nC:\\Program Files\n\ncd PostgreSQL\\9.2\\bin\npg_dump \u2013U postgres \u2013h localhost {postgresdb} \n \u201dC:\\{location}\\{location}{backupname}.sql\u201d\npsql -U postgres -h localhost {pt8} \n C:\\{location}\\{location}{backupname}.restore.sql\n\n\n\n\nTo backup in MySQL \n\n\ncd MySQL\\MySQL Server 5.1\\bin\nC:\\ProgramFiles\\MySQL\\MySQL Server 5.1\\bin\nmysql -u {username} -p {password} {MYSQL db} \n \ne:\\database.sql\n\n\n\n\n\nBackups in MSSQL can be done from the management console.\n\n\nSchedule Database Backups using PaperTrail\n\n\nPapertrail can automatically backup databases on schedule configured\nunder\u00a0Services\u00a0\u00a0\u2192\u00a0Properties\u00a0\u00a0\u2192\u00a0Backup \u2192\u00a0DB Schedule\n(db.backup.schedule).\n\n\nPaperTrail will run the pgdump, mysql_dump or SQL Server Backup\nDatabase command \u00a0and store the result in the file repository.\u00a0\n\n\nNote: Backups can only be made of local database\n\n\nConfiguring cloud backups\n\n\nCloud backups lets you back up the PaperTrail file repository (and optionally the PaperTrail database) in near real time to the \nAmazon S3 cloud\n.\n\n\nIf you set up the Amazon S3 account, use the information from that\naccount to configure cloud backups. For Egis managed backups, Egis will\nsupply the information to you.\n\n\n\n\nFrom Services \u00a0\u2192\u00a0\u00a0Tasks\u00a0\u2192\u00a0 Wizards, select Configure cloud backups.\nEnter the values of the Amazon S3 account in these fields:\\\n\n\nBucket\n The Amazon S3 bucket to use, for example:\nacme.papertrail\\\n\n\nAccess key\n An access key that has read and write permissions to\nthe bucket.\\\n\n\nSecret key\n\n\n\n\nConfiguring periodic Windows file share backups\n\n\nPaperTrail creates an incremental backup ZIP file and copies the ZIP\nfile to the specified shared folder.  \n\n\nSpecify these options under the Backup Settings page of the\ninstallation wizard or after installation via Services\u00a0\u2192\u00a0 Tasks\u00a0\u2192\u00a0\nWizards \u00a0\u2192\u00a0\n\n\nConfigure Windows Share backups\n\n\n\n\nHost \u2013 the hostname of the Windows or SMB/CIFS based fileserver\\\n\n\nBackup Dir \u2013 The share and path location (e.g.,\nBackups/Papertrail Relative to the file share, not relative the root\ndirector)\n\n\nUsername and Password if applicable\n\n\n\n\nAd-Hoc Backup\n\n\nTypically, do an ad-hoc backup before you upgrade PaperTrail or before\nyou migrate to a different server.\n\n An ad-hoc backup will export all the files in the repository to a local\nor windows file share location. Multiple ZIP files will be created; a\nlog file for each ZIP file will also be created containing the names of\nthe files in the corresponding ZIP file.  \n\n\nAn ad-hoc backup can be re-run using the same destination path, the\nlogs files will be read and only new files added will be backed up.\n\n1. Under Services \u2192 Tasks \u2192 Backups \u2192 Backup Repository\n\n2. Destination: Local or windows file share\n(\nsmb://user@pass:host/Share/folder\n)\n\n3.\u00a0Optional: Check verify to verify the backup once complete\n\n4.\u00a0Max File Size: Enter a maximum file size. Once a backup file\nreaches this limit (it may not be exact depending on the size of\nindividual files) a new backup file will start.\n\n\nRestoring from backup\n\n\nSelect Restore from Windows File Share or Cloud from the installation\nwizard.\n\n\n3rd Party backup\n\n\n\n\nBackup the database and applicable transaction logs.\n\n\nBackup the PT_Repo directory (defaults to C:\\Data\\PT_Repo).\n\n\n\n\n\n\nNote: PaperTrail does not update files in the PT_Repo directory so once\nbacked up a file does not need to backed-up again.\n\n\n\n\n3.\u00a0\u00a0 \u00a0For large installations the indexes can also be backed up to\ndecrease restore times\n\n Under Services \u00a0\u2192\u00a0Properties \u00a0\u2192\u00a0Backup \u00a0Specify an Index Backup\nSchedule \n Directory\n\n\nNative restore from backup\n\n\n\n\nRestore database and file repository to original locations\n\n\nInstall PaperTrail\n\n\nCheck new installation and enter existing database details", 
            "title": "Backups"
        }, 
        {
            "location": "/Configuration/Backups/#backups", 
            "text": "", 
            "title": "Backups"
        }, 
        {
            "location": "/Configuration/Backups/#what-needs-to-be-backed-up", 
            "text": "Database and transaction logs  File Repository (Everything under PT_Repo)  SSL Certificate : conf/keystore (If configured)  Encryption Keys : e.g. conf/keys.* If File store encryption is\n    configured  Indexes : Only for very large installations where an index rebuild\n    is too time-consuming", 
            "title": "What needs to be backed up?"
        }, 
        {
            "location": "/Configuration/Backups/#how-to-backup", 
            "text": "To backup in PostgreSQL   cd  C:\\Program Files \ncd PostgreSQL\\9.2\\bin\npg_dump \u2013U postgres \u2013h localhost {postgresdb}   \u201dC:\\{location}\\{location}{backupname}.sql\u201d\npsql -U postgres -h localhost {pt8}   C:\\{location}\\{location}{backupname}.restore.sql  To backup in MySQL   cd MySQL\\MySQL Server 5.1\\bin\nC:\\ProgramFiles\\MySQL\\MySQL Server 5.1\\bin mysql -u {username} -p {password} {MYSQL db}    e:\\database.sql   Backups in MSSQL can be done from the management console.", 
            "title": "How to backup?"
        }, 
        {
            "location": "/Configuration/Backups/#schedule-database-backups-using-papertrail", 
            "text": "Papertrail can automatically backup databases on schedule configured\nunder\u00a0Services\u00a0\u00a0\u2192\u00a0Properties\u00a0\u00a0\u2192\u00a0Backup \u2192\u00a0DB Schedule\n(db.backup.schedule).  PaperTrail will run the pgdump, mysql_dump or SQL Server Backup\nDatabase command \u00a0and store the result in the file repository.\u00a0  Note: Backups can only be made of local database", 
            "title": "Schedule Database Backups using PaperTrail"
        }, 
        {
            "location": "/Configuration/Backups/#configuring-cloud-backups", 
            "text": "Cloud backups lets you back up the PaperTrail file repository (and optionally the PaperTrail database) in near real time to the  Amazon S3 cloud .  If you set up the Amazon S3 account, use the information from that\naccount to configure cloud backups. For Egis managed backups, Egis will\nsupply the information to you.   From Services \u00a0\u2192\u00a0\u00a0Tasks\u00a0\u2192\u00a0 Wizards, select Configure cloud backups.\nEnter the values of the Amazon S3 account in these fields:\\  Bucket  The Amazon S3 bucket to use, for example:\nacme.papertrail\\  Access key  An access key that has read and write permissions to\nthe bucket.\\  Secret key", 
            "title": "Configuring cloud backups"
        }, 
        {
            "location": "/Configuration/Backups/#configuring-periodic-windows-file-share-backups", 
            "text": "PaperTrail creates an incremental backup ZIP file and copies the ZIP\nfile to the specified shared folder.    Specify these options under the Backup Settings page of the\ninstallation wizard or after installation via Services\u00a0\u2192\u00a0 Tasks\u00a0\u2192\u00a0\nWizards \u00a0\u2192", 
            "title": "Configuring periodic Windows file share backups"
        }, 
        {
            "location": "/Configuration/Backups/#configure-windows-share-backups", 
            "text": "Host \u2013 the hostname of the Windows or SMB/CIFS based fileserver\\  Backup Dir \u2013 The share and path location (e.g.,\nBackups/Papertrail Relative to the file share, not relative the root\ndirector)  Username and Password if applicable", 
            "title": "Configure Windows Share backups"
        }, 
        {
            "location": "/Configuration/Backups/#ad-hoc-backup", 
            "text": "Typically, do an ad-hoc backup before you upgrade PaperTrail or before\nyou migrate to a different server. \n An ad-hoc backup will export all the files in the repository to a local\nor windows file share location. Multiple ZIP files will be created; a\nlog file for each ZIP file will also be created containing the names of\nthe files in the corresponding ZIP file.    An ad-hoc backup can be re-run using the same destination path, the\nlogs files will be read and only new files added will be backed up. \n1. Under Services \u2192 Tasks \u2192 Backups \u2192 Backup Repository \n2. Destination: Local or windows file share\n( smb://user@pass:host/Share/folder ) \n3.\u00a0Optional: Check verify to verify the backup once complete \n4.\u00a0Max File Size: Enter a maximum file size. Once a backup file\nreaches this limit (it may not be exact depending on the size of\nindividual files) a new backup file will start.", 
            "title": "Ad-Hoc Backup"
        }, 
        {
            "location": "/Configuration/Backups/#restoring-from-backup", 
            "text": "Select Restore from Windows File Share or Cloud from the installation\nwizard.", 
            "title": "Restoring from backup"
        }, 
        {
            "location": "/Configuration/Backups/#3rd-party-backup", 
            "text": "Backup the database and applicable transaction logs.  Backup the PT_Repo directory (defaults to C:\\Data\\PT_Repo).    Note: PaperTrail does not update files in the PT_Repo directory so once\nbacked up a file does not need to backed-up again.   3.\u00a0\u00a0 \u00a0For large installations the indexes can also be backed up to\ndecrease restore times \n Under Services \u00a0\u2192\u00a0Properties \u00a0\u2192\u00a0Backup \u00a0Specify an Index Backup\nSchedule   Directory", 
            "title": "3rd Party backup"
        }, 
        {
            "location": "/Configuration/Backups/#native-restore-from-backup", 
            "text": "Restore database and file repository to original locations  Install PaperTrail  Check new installation and enter existing database details", 
            "title": "Native restore from backup"
        }, 
        {
            "location": "/Configuration/Barcode/", 
            "text": "Barcode Recognition Setup\n\n\n1) Setup an extractFromBarcode rule on the appropriate node\n\n2) Install the Softek SDK. You can download the latest version from:\n\n\nWindows SDK\nv8.1.2\n\n\nLinux SDK v8.1.2\n\n\nLibraries need to be copied to \n/usr/lib/java\n, \n/usr/lib/\n,\n\nC:\\\\Windows\\\\System32\n or wherever the java.library.path is pointing.\n\n\nFor a list of all versions go to \nBardecode\n, although a different license may need to be loaded via the License property.\n\n\nSupported Barcodes\n\n\n\n\nCodabar also known as Code 2 of 7, Codeabar, Ames Code, NW-7 and Monarch (ReadCodabar)\n\n\nCode 128 Symbol Sets A, B and C (ReadCode128)\n\n\nCode 128 Short Format (ReadShortCode128)\n\n\nCode 2 of 5 Datalogic (ReadCode25ni)\n\n\nCode 2 of 5 Iata1 (ReadCode25ni)\n\n\nCode 2 of 5 Iata2 (ReadCode25ni)\n\n\nCode 2 of 5 Industrial (ReadCode25ni)\n\n\nCode 2 of 5 Interleaved (ReadCode25)\n\n\nCode 2 of 5 Matrix (ReadCode25ni)\n\n\nCode 3 of 9 (ReadCode39)\n\n\nCode 3 of 9 Extended (ReadCode39 and ExtendedCode39)\n\n\nCode 93 (ReadCode93)\n\n\nEAN-8, European Article Number/International Article Number (ReadEAN8)\n\n\nEAN-13 and UPC-A, European Article Number/International Article Number (ReadEAN13)\n\n\nGS1-128, UCC-128, EAN-128 (ReadCode128)\n\n\nGS1-Databar (please see 2-D section below)\n\n\nPatch Code Symbols (ReadPatchCodes)\n\n\nUPC-A, Universal Product Code (ReadEAN13 and ReadUPCA)\n\n\nUPC-E, Universal Product Code (ReadUPCE)\n\n\nQR-Code (ReadQRCode)\n\n\nData Matrix ECC200 sizes 8x8 to 144x144 (ReadDataMatrix)\n\n\nGS1-Databar\n\n\nMicro-PDF-417 (ReadMicroPDF417)\n\n\nPDF-417, Portable Data File (ReadPDF417)\n\n\n\n\nProperties\n\n\n\n\n\n\n\n\nProperties\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAllowDuplicateValues\n\n\nBarcodes containing the same text on the same page\n\n\n\n\n\n\nBarcodesAtTopOfPage\n\n\nSearch from the top of a page downwards\n\n\n\n\n\n\nCode128Lenient\n\n\nRelax some of the requirements for Code 128 barcodes\n\n\n\n\n\n\nCode25Checksum\n\n\nCode 25 barcodes include checksum character\n\n\n\n\n\n\nCode25MinLengthOccurrence\n\n\nControl for false positive readings for Code 25 barcodes\n\n\n\n\n\n\nCode39Checksum\n\n\nCode 39 barcodes include checksum character\n\n\n\n\n\n\nCode39MaxRatioPcnt\n\n\nSet the max ratio between the wide and narrow bars\n\n\n\n\n\n\nCode39NeedStartStop\n\n\nRequire start and stop * characters for a Code 39 barcode\n\n\n\n\n\n\nColorProcessingLevel\n\n\nControl the amount of processing time spent reading barcode values from color images\n\n\n\n\n\n\nColorThreshold\n\n\nContrast setting for color images\n\n\n\n\n\n\nConvertUPCEToEAN13\n\n\nOutput UPC-E barcodes in EAN-13 format\n\n\n\n\n\n\nDatabarOptions\n\n\nSet the advanced options for reading GS1 Databar barcodes\n\n\n\n\n\n\nDataMatrixAutoUTF8\n\n\nAutomatic detection of UTF8 data in Datamatrix barcodes\n\n\n\n\n\n\nDespeckle\n\n\nClean up images containing specks of black and white\n\n\n\n\n\n\nEncoding\n\n\nCharacter encoding for barcode values\n\n\n\n\n\n\nErrorCorrection\n\n\nCorrect errors in barcodes\n\n\n\n\n\n\nExtendedCode39\n\n\nRead Code 39 barcodes in the extended symbol set\n\n\n\n\n\n\nGammaCorrection\n\n\nGamma correction value for color images\n\n\n\n\n\n\nLineJump\n\n\nFrequency of line sampling in an image\n\n\n\n\n\n\nMaxLength\n\n\nMaximum string length of a barcode\n\n\n\n\n\n\nMaxRectOverlap\n\n\nMaximum number of threads\n\n\n\n\n\n\nMaxThreads\n\n\nMaximum overlap for bounding rectangles\n\n\n\n\n\n\nMedianFilter\n\n\nApply a median filter to the image\n\n\n\n\n\n\nMedianFilterBias\n\n\nLighten/darken an image during a median filter\n\n\n\n\n\n\nMinLength\n\n\nMinimum string length of a barcode\n\n\n\n\n\n\nMinOccurrence\n\n\nMinimum number of hits needed to read a barcode\n\n\n\n\n\n\nMinSeparation\n\n\nMinimum distance between similar barcodes\n\n\n\n\n\n\nMinSpaceBarWidth\n\n\nMinimum width of a space in a barcode\n\n\n\n\n\n\nMultipleRead\n\n\nRead more than one barcode\n\n\n\n\n\n\nNoiseReduction\n\n\nClean up images containing un-wanted black marks\n\n\n\n\n\n\nPageNo\n\n\nPage number to scan in an image\n\n\n\n\n\n\nPattern\n\n\nRegular expression to search for\n\n\n\n\n\n\nPDF417AutoUTF8\n\n\nAutomatic identification of UTF8 data in PDF-417 barcodes\n\n\n\n\n\n\nPdf417ChannelMode\n\n\nControl the way macros are handled in PDF417 barcodes\n\n\n\n\n\n\nPdf417MacroEscapeBackslash\n\n\nHandling of back slash characters in PDF417 macros\n\n\n\n\n\n\nPhotometric\n\n\nPhotometric interpretation for a black and white bitmap\n\n\n\n\n\n\nPrefOccurrence\n\n\nPreferred number of hits for a barcode\n\n\n\n\n\n\nQRCodeAutoUTF8\n\n\nAutomatic identification of UTF8 data in QrCode barcodes\n\n\n\n\n\n\nQRCodeBWAutoMedianFilter\n\n\nautomatic use of median filter for QrCode detection\n\n\n\n\n\n\nQuietZoneSize\n\n\nSize of quiet zone around a barcode\n\n\n\n\n\n\nReadCodabar\n\n\nRead Codabar barcodes\n\n\n\n\n\n\nReadCode128\n\n\nRead Code 128 barcodes\n\n\n\n\n\n\nReadCode25\n\n\nRead Code 25 (interlaced) barcodes\n\n\n\n\n\n\nReadCode25ni\n\n\nRead Code 25 (non-interlaced) barcodes\n\n\n\n\n\n\nReadCode39\n\n\nRead Code 39 barcodes\n\n\n\n\n\n\nReadDatabar\n\n\nRead GS1 Databar barcodes\n\n\n\n\n\n\nReadDataMatrix\n\n\nRead Data Matrix barcodes\n\n\n\n\n\n\nReadEAN13\n\n\nRead EAN-13 barcodes\n\n\n\n\n\n\nReadEAN8\n\n\nRead EAN-8 barcodes\n\n\n\n\n\n\nReadMicroPDF417\n\n\nRead micro-PDF-417 barcodes\n\n\n\n\n\n\nReadNumeric\n\n\nOnly read numeric barcodes\n\n\n\n\n\n\nReadPatchCodes\n\n\nRead Patch Codes\n\n\n\n\n\n\nReadPDF417\n\n\nRead PDF-417 barcodes\n\n\n\n\n\n\nReadShortCode128\n\n\nRead short Code 128 barcodes\n\n\n\n\n\n\nReadUPCA\n\n\nRead UPC-A barcodes\n\n\n\n\n\n\nReadUPCE\n\n\nRead UPC-E barcodes\n\n\n\n\n\n\nReportUnreadBarcodes\n\n\nReport barcodes that could not be decoded\n\n\n\n\n\n\nScanDirection\n\n\nOrientation to scan for a barcode\n\n\n\n\n\n\nShortCode128MinLength\n\n\nMinimum length for a barcode of type \"SHORTCODE128\"\n\n\n\n\n\n\nShowCheckDigit\n\n\nDisplay check digits\n\n\n\n\n\n\nSkewedDatamatrix\n\n\nCheck for skewed linear barcodes\n\n\n\n\n\n\nSkewedLinear\n\n\nCheck for skewed datamatrix barcodes\n\n\n\n\n\n\nSkewLineJump\n\n\nFrequency of line sampling for skewed barcodes\n\n\n\n\n\n\nSkewTolerance\n\n\nSearch for barcodes at an angle to horizontal or vertical\n\n\n\n\n\n\nTifSplitMode\n\n\nControls how a TIF file should be split\n\n\n\n\n\n\nTifSplitPath\n\n\nSplit a TIF file into smaller parts based on the location of barcodes in the image\n\n\n\n\n\n\nTimeOut\n\n\nSet a time out for barcode detection\n\n\n\n\n\n\nUseFastScan\n\n\nDo a quick scan prior to a deeper search.\n\n\n\n\n\n\nUseOverSampling\n\n\nAnother method for cleaning up 'noisy' images\n\n\n\n\n\n\nWeightLongerBarcodes\n\n\nBoost the hit count for longer barcodes.", 
            "title": "Barcode"
        }, 
        {
            "location": "/Configuration/Barcode/#barcode-recognition-setup", 
            "text": "1) Setup an extractFromBarcode rule on the appropriate node \n2) Install the Softek SDK. You can download the latest version from:  Windows SDK\nv8.1.2  Linux SDK v8.1.2  Libraries need to be copied to  /usr/lib/java ,  /usr/lib/ , C:\\\\Windows\\\\System32  or wherever the java.library.path is pointing.  For a list of all versions go to  Bardecode , although a different license may need to be loaded via the License property.", 
            "title": "Barcode Recognition Setup"
        }, 
        {
            "location": "/Configuration/Barcode/#supported-barcodes", 
            "text": "Codabar also known as Code 2 of 7, Codeabar, Ames Code, NW-7 and Monarch (ReadCodabar)  Code 128 Symbol Sets A, B and C (ReadCode128)  Code 128 Short Format (ReadShortCode128)  Code 2 of 5 Datalogic (ReadCode25ni)  Code 2 of 5 Iata1 (ReadCode25ni)  Code 2 of 5 Iata2 (ReadCode25ni)  Code 2 of 5 Industrial (ReadCode25ni)  Code 2 of 5 Interleaved (ReadCode25)  Code 2 of 5 Matrix (ReadCode25ni)  Code 3 of 9 (ReadCode39)  Code 3 of 9 Extended (ReadCode39 and ExtendedCode39)  Code 93 (ReadCode93)  EAN-8, European Article Number/International Article Number (ReadEAN8)  EAN-13 and UPC-A, European Article Number/International Article Number (ReadEAN13)  GS1-128, UCC-128, EAN-128 (ReadCode128)  GS1-Databar (please see 2-D section below)  Patch Code Symbols (ReadPatchCodes)  UPC-A, Universal Product Code (ReadEAN13 and ReadUPCA)  UPC-E, Universal Product Code (ReadUPCE)  QR-Code (ReadQRCode)  Data Matrix ECC200 sizes 8x8 to 144x144 (ReadDataMatrix)  GS1-Databar  Micro-PDF-417 (ReadMicroPDF417)  PDF-417, Portable Data File (ReadPDF417)", 
            "title": "Supported Barcodes"
        }, 
        {
            "location": "/Configuration/Barcode/#properties", 
            "text": "Properties  Description      AllowDuplicateValues  Barcodes containing the same text on the same page    BarcodesAtTopOfPage  Search from the top of a page downwards    Code128Lenient  Relax some of the requirements for Code 128 barcodes    Code25Checksum  Code 25 barcodes include checksum character    Code25MinLengthOccurrence  Control for false positive readings for Code 25 barcodes    Code39Checksum  Code 39 barcodes include checksum character    Code39MaxRatioPcnt  Set the max ratio between the wide and narrow bars    Code39NeedStartStop  Require start and stop * characters for a Code 39 barcode    ColorProcessingLevel  Control the amount of processing time spent reading barcode values from color images    ColorThreshold  Contrast setting for color images    ConvertUPCEToEAN13  Output UPC-E barcodes in EAN-13 format    DatabarOptions  Set the advanced options for reading GS1 Databar barcodes    DataMatrixAutoUTF8  Automatic detection of UTF8 data in Datamatrix barcodes    Despeckle  Clean up images containing specks of black and white    Encoding  Character encoding for barcode values    ErrorCorrection  Correct errors in barcodes    ExtendedCode39  Read Code 39 barcodes in the extended symbol set    GammaCorrection  Gamma correction value for color images    LineJump  Frequency of line sampling in an image    MaxLength  Maximum string length of a barcode    MaxRectOverlap  Maximum number of threads    MaxThreads  Maximum overlap for bounding rectangles    MedianFilter  Apply a median filter to the image    MedianFilterBias  Lighten/darken an image during a median filter    MinLength  Minimum string length of a barcode    MinOccurrence  Minimum number of hits needed to read a barcode    MinSeparation  Minimum distance between similar barcodes    MinSpaceBarWidth  Minimum width of a space in a barcode    MultipleRead  Read more than one barcode    NoiseReduction  Clean up images containing un-wanted black marks    PageNo  Page number to scan in an image    Pattern  Regular expression to search for    PDF417AutoUTF8  Automatic identification of UTF8 data in PDF-417 barcodes    Pdf417ChannelMode  Control the way macros are handled in PDF417 barcodes    Pdf417MacroEscapeBackslash  Handling of back slash characters in PDF417 macros    Photometric  Photometric interpretation for a black and white bitmap    PrefOccurrence  Preferred number of hits for a barcode    QRCodeAutoUTF8  Automatic identification of UTF8 data in QrCode barcodes    QRCodeBWAutoMedianFilter  automatic use of median filter for QrCode detection    QuietZoneSize  Size of quiet zone around a barcode    ReadCodabar  Read Codabar barcodes    ReadCode128  Read Code 128 barcodes    ReadCode25  Read Code 25 (interlaced) barcodes    ReadCode25ni  Read Code 25 (non-interlaced) barcodes    ReadCode39  Read Code 39 barcodes    ReadDatabar  Read GS1 Databar barcodes    ReadDataMatrix  Read Data Matrix barcodes    ReadEAN13  Read EAN-13 barcodes    ReadEAN8  Read EAN-8 barcodes    ReadMicroPDF417  Read micro-PDF-417 barcodes    ReadNumeric  Only read numeric barcodes    ReadPatchCodes  Read Patch Codes    ReadPDF417  Read PDF-417 barcodes    ReadShortCode128  Read short Code 128 barcodes    ReadUPCA  Read UPC-A barcodes    ReadUPCE  Read UPC-E barcodes    ReportUnreadBarcodes  Report barcodes that could not be decoded    ScanDirection  Orientation to scan for a barcode    ShortCode128MinLength  Minimum length for a barcode of type \"SHORTCODE128\"    ShowCheckDigit  Display check digits    SkewedDatamatrix  Check for skewed linear barcodes    SkewedLinear  Check for skewed datamatrix barcodes    SkewLineJump  Frequency of line sampling for skewed barcodes    SkewTolerance  Search for barcodes at an angle to horizontal or vertical    TifSplitMode  Controls how a TIF file should be split    TifSplitPath  Split a TIF file into smaller parts based on the location of barcodes in the image    TimeOut  Set a time out for barcode detection    UseFastScan  Do a quick scan prior to a deeper search.    UseOverSampling  Another method for cleaning up 'noisy' images    WeightLongerBarcodes  Boost the hit count for longer barcodes.", 
            "title": "Properties"
        }, 
        {
            "location": "/Configuration/Branding/", 
            "text": "Branding PaperTrail\n\n\n\n\nImages are placed in the System/images node.\n\n\nImages must end in .png (if they are a .jpeg or .gif they can be\n    safely renamed).\n\n\nImages should be the correct size, if the image is bigger or smaller\n    it should be manually resized before importing into System/images.\n\n\nTo prevent the images from being overwritten after upgrades, they\n    should be permanently checked out.\n\n\n\n\nlogin_background.png (320x365)\n\n\nThe honeycomb that sits behind the login and password boxes.\n\n\npapertrail.png (110x26)\n\n\nThe logo that sits in the top left of the main application screen.\n\nThe background should be transparent.\n\n\nlogo.png (320x50)\n\n\nThe logo that sits above the honeycomb.\n\nAdd white space to the left of image to center it above the honeycomb.\n\n\negis.png (75x25)\n\n\nThe egis logo on the bottom right of the screen.", 
            "title": "Branding"
        }, 
        {
            "location": "/Configuration/Branding/#branding-papertrail", 
            "text": "Images are placed in the System/images node.  Images must end in .png (if they are a .jpeg or .gif they can be\n    safely renamed).  Images should be the correct size, if the image is bigger or smaller\n    it should be manually resized before importing into System/images.  To prevent the images from being overwritten after upgrades, they\n    should be permanently checked out.", 
            "title": "Branding PaperTrail"
        }, 
        {
            "location": "/Configuration/Branding/#login95backgroundpng-320x365", 
            "text": "The honeycomb that sits behind the login and password boxes.", 
            "title": "login_background.png (320x365)"
        }, 
        {
            "location": "/Configuration/Branding/#papertrailpng-110x26", 
            "text": "The logo that sits in the top left of the main application screen. \nThe background should be transparent.", 
            "title": "papertrail.png (110x26)"
        }, 
        {
            "location": "/Configuration/Branding/#logopng-320x50", 
            "text": "The logo that sits above the honeycomb. \nAdd white space to the left of image to center it above the honeycomb.", 
            "title": "logo.png (320x50)"
        }, 
        {
            "location": "/Configuration/Branding/#egispng-75x25", 
            "text": "The egis logo on the bottom right of the screen.", 
            "title": "egis.png (75x25)"
        }, 
        {
            "location": "/Configuration/Logging/", 
            "text": "Logging\n\n\nUpdating the log settings\n\n\n\n\nAll log settings are stored in the \nconf/logback.groovy\n file\u00a0\n\n\nThe \nAdmin -> Services -> Logging\n \u00a0page will make changes to this file\nif the After Restart \u00a0option is selected\n\n\n\n\nLog file Retention\n\n\n\n\nTo configure the number of days to keep Papertrail logs, locate and\n    edit the following document:\u00a0\nPaperTrail/conf/logback.groovy\n\ne.g. keeps the logs for a period of 14 days:\n\n\n\n\nappender(\nFILE\n, RollingFileAppender) {         \u00a0\u00a0\u00a0\u00a0\n    file\u00a0=\u00a0\nlogs/server.log\n         \u00a0\u00a0\u00a0\u00a0\n    append\u00a0=\u00a0true         \u00a0\u00a0\u00a0\u00a0\n    rollingPolicy(TimeBasedRollingPolicy) {         \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n        maxHistory\u00a0=\u00a014         \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \n        FileNamePattern\u00a0=\u00a0\nlogs/server-%d{yyyy-MM-dd}.log\n         \u00a0\u00a0\u00a0 \n    }         \n}\n\n\n\n\n\n\nLocate the section\u00a0\nmaxHistory = 14\n\u00a0 modify the 14 with\n    the amount of days to keep logs.\n\n\nRestart PaperTrail for the settings to take effect.\n\n\n\n\nLogging to Syslog Host\n\n\n``java\nimport com.egis.utils.apm.\n; \nimport org.productivity.java.syslog4j.impl.net.tcp.\n; \n\n\nappender(\"SYSLOG\", SyslogAppender) { \u00a0\n  \u00a0 layout(LogglyLayout) { \u00a0\u00a0 \u00a0apiToken = \"XXXXX\" \u00a0 \u00a0 } \u00a0 \u00a0\n  \u00a0 syslogConfig(TCPNetSyslogConfig) { \u00a0 \u00a0 \n  \u00a0     host = \u00a0\"logs-01.loggly.com\"\n        port = 514\n        ident = \"papertrail\"\n  \u00a0\u00a0} \n}\n\n\n\n## Logging to a GELF Host \n\nReplace //gelf in the logback.groovy with:\n\n```groovy\nappender(\nGELF\n, GelfAppender) { \u00a0 \u00a0 \n    host = \n${gelfHost}\n \u00a0 \u00a0\n    filter(ThresholdFilter) { \u00a0 \u00a0 \u00a0 \n \u00a0      level = ${gelfLevel} \u00a0 \n \u00a0 } \u00a0 \u00a0\n \u00a0 port = 12201 \u00a0\n \u00a0 additionalFields = \u00a0'{\nthreadName\n: \nthreadName\n, \nexception\n: \nexception\n, \nloggerName\n: \nloggerName\n, \nip\n:\nip\n,\nuser\n:\nuser\n,\ndoc\n:\ndoc\n}' \n}\n\n\n\n\nThe following properties will automate this\nsetup:\u00a0\ngelf.host\n\u00a0and\u00a0\ngelf.level\n\n\nLogging to individual files per logger\n\n\ne.g. to append file access logs to a standalone \nstorage.log\n file:\n\n\nappender(\nSTORAGE\n, RollingFileAppender) {\n    file = \nlogs/storage.log\n\n    append = true\n    rollingPolicy(TimeBasedRollingPolicy) {\n        maxHistory = 14\n        FileNamePattern = \nlogs/storahe-%d{yyyy-MM-dd}.log\n\n    }\n    encoder(PatternLayoutEncoder) {\n        pattern = \n%d{HH:mm:ss.SSS} %level %logger{0} [%X{user}%X{doc}:%X{ip}] %msg%n\n\n    }\n}\n\n\nlogger('com.egis.storage', INFO)\nlogger(\ncom.egis.storage\n, DEBUG, ['STORAGE'], false)", 
            "title": "Logging"
        }, 
        {
            "location": "/Configuration/Logging/#logging", 
            "text": "", 
            "title": "Logging"
        }, 
        {
            "location": "/Configuration/Logging/#updating-the-log-settings", 
            "text": "All log settings are stored in the  conf/logback.groovy  file\u00a0  The  Admin -> Services -> Logging  \u00a0page will make changes to this file\nif the After Restart \u00a0option is selected", 
            "title": "Updating the log settings"
        }, 
        {
            "location": "/Configuration/Logging/#log-file-retention", 
            "text": "To configure the number of days to keep Papertrail logs, locate and\n    edit the following document:\u00a0 PaperTrail/conf/logback.groovy \ne.g. keeps the logs for a period of 14 days:   appender( FILE , RollingFileAppender) {         \u00a0\u00a0\u00a0\u00a0\n    file\u00a0=\u00a0 logs/server.log          \u00a0\u00a0\u00a0\u00a0\n    append\u00a0=\u00a0true         \u00a0\u00a0\u00a0\u00a0\n    rollingPolicy(TimeBasedRollingPolicy) {         \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n        maxHistory\u00a0=\u00a014         \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \n        FileNamePattern\u00a0=\u00a0 logs/server-%d{yyyy-MM-dd}.log          \u00a0\u00a0\u00a0 \n    }         \n}   Locate the section\u00a0 maxHistory = 14 \u00a0 modify the 14 with\n    the amount of days to keep logs.  Restart PaperTrail for the settings to take effect.", 
            "title": "Log file Retention"
        }, 
        {
            "location": "/Configuration/Logging/#logging-to-syslog-host", 
            "text": "``java\nimport com.egis.utils.apm. ; \nimport org.productivity.java.syslog4j.impl.net.tcp. ;   appender(\"SYSLOG\", SyslogAppender) { \u00a0\n  \u00a0 layout(LogglyLayout) { \u00a0\u00a0 \u00a0apiToken = \"XXXXX\" \u00a0 \u00a0 } \u00a0 \u00a0\n  \u00a0 syslogConfig(TCPNetSyslogConfig) { \u00a0 \u00a0 \n  \u00a0     host = \u00a0\"logs-01.loggly.com\"\n        port = 514\n        ident = \"papertrail\"\n  \u00a0\u00a0} \n}  \n## Logging to a GELF Host \n\nReplace //gelf in the logback.groovy with:\n\n```groovy\nappender( GELF , GelfAppender) { \u00a0 \u00a0 \n    host =  ${gelfHost}  \u00a0 \u00a0\n    filter(ThresholdFilter) { \u00a0 \u00a0 \u00a0 \n \u00a0      level = ${gelfLevel} \u00a0 \n \u00a0 } \u00a0 \u00a0\n \u00a0 port = 12201 \u00a0\n \u00a0 additionalFields = \u00a0'{ threadName :  threadName ,  exception :  exception ,  loggerName :  loggerName ,  ip : ip , user : user , doc : doc }' \n}  The following properties will automate this\nsetup:\u00a0 gelf.host \u00a0and\u00a0 gelf.level", 
            "title": "Logging to Syslog Host"
        }, 
        {
            "location": "/Configuration/Logging/#logging-to-individual-files-per-logger", 
            "text": "e.g. to append file access logs to a standalone  storage.log  file:  appender( STORAGE , RollingFileAppender) {\n    file =  logs/storage.log \n    append = true\n    rollingPolicy(TimeBasedRollingPolicy) {\n        maxHistory = 14\n        FileNamePattern =  logs/storahe-%d{yyyy-MM-dd}.log \n    }\n    encoder(PatternLayoutEncoder) {\n        pattern =  %d{HH:mm:ss.SSS} %level %logger{0} [%X{user}%X{doc}:%X{ip}] %msg%n \n    }\n}\n\n\nlogger('com.egis.storage', INFO)\nlogger( com.egis.storage , DEBUG, ['STORAGE'], false)", 
            "title": "Logging to individual files per logger"
        }, 
        {
            "location": "/Configuration/SSO/", 
            "text": "SSO\n\n\nSAML Single Sign On\n\n\nSAML SSO lets a third-party service (an identify provider) authenticate users. A user is authenticated on an identity provider\u2019s website.   \n\n\nThe identity provider redirects the user to the PaperTrail website and sends PaperTrail a SAML token. PaperTrail validates the SAML token and logs the user in. The user does not enter a username or a password.  \n\n\nFrom \nServices \u2192Properties \u2192SSO (SAML)\n, select these fields:  \n\n\n\n\nPublic Key:\n The name of the identity provider\u2019s public key. The public key is in the conf directory in the installation folder.  \n\n\nPrivate Key:\n If encryption is used for the SAML token, enter the path to the private key.  \n\n\nIdentity Provider URL:\n The URL of the identity provider endpoint.  \n\n\nLogin Mapping:\n The element in the SAML token that maps to the login name in PaperTrail. Usually, the element is NameID.  \n\n\n\n\nTo make all authentication use SAML, change the \nServices\nProperties\nFront End\nMain Page property\n to \n/saml\n.  \n\n\nWindows Based SSO (NTLM)\n\n\nNTLM SSO allows for users to be logged in automatically if they are already logged onto their domain account on their PC.   \n\n\nCheck \nServices -\n Properties -\n SSO\n (Windows Kerberos/NTLM)\n\n\nLinux Based SSO (Kerberos)\n\n\nSometimes PaperTrail is installed on Linux server but needs to login in users automatically via Active Directory \u2013 This is only possible by using native Kerberos\n\n\n\n\nAdd the server (e.g., papertrail-srv) to the \nAD Domain\n (e.g., ad.local)  \n\n\nCreate a \nuser account\n (e.g., papertrail-acc) on the AD Domain  \n\n\nConfigure PaperTrail to \nrun as the user account\n (e.g., papertrail-acc)  \n\n\nCreate a \nSPN for each path\n that PaperTrail will be accessed by. \n\n\n\n\ne.g., for port 80:\nsetspn.exe -A HTTP/papertrail-srv papertrail-acc\nsetspn.exe -A HTTP/papertrail-srv.ad.local papertrail-acc\ne.g., for port 8080:\nsetspn.exe -A HTTP/papertrail-srv:8080 papertrail-acc\nsetspn.exe -A HTTP/papertrail-srv.ad.local:8080 papertrail-acc\n\n\n\n\n\n\nEnable SSO on PaperTrail by editing the \nServices -\n Properties -\n SSO (Kerberos)\n properties.\n\n\n\n\nEnable: ticked\nDomain: ad.local\nKDC: kdc.ad.local (whichever server responds to \nping ad.local\n should be listed here)\nUsername: papertrail-acc\nPrincipal: papertrail-acc\nPassword: {password for papertrail-acc}\n\n\n\n\n\n\nUpdate the \nFront End -\n Index Page\n to: \n/web/webapps/main.html\n.\n\n\nUsers need to be \nlogged onto the domain\n (ad.local) and access \nPaperTrail via the FQDN\n (e.g., papertrail-srv.ad.local)", 
            "title": "SSO"
        }, 
        {
            "location": "/Configuration/SSO/#sso", 
            "text": "", 
            "title": "SSO"
        }, 
        {
            "location": "/Configuration/SSO/#saml-single-sign-on", 
            "text": "SAML SSO lets a third-party service (an identify provider) authenticate users. A user is authenticated on an identity provider\u2019s website.     The identity provider redirects the user to the PaperTrail website and sends PaperTrail a SAML token. PaperTrail validates the SAML token and logs the user in. The user does not enter a username or a password.    From  Services \u2192Properties \u2192SSO (SAML) , select these fields:     Public Key:  The name of the identity provider\u2019s public key. The public key is in the conf directory in the installation folder.    Private Key:  If encryption is used for the SAML token, enter the path to the private key.    Identity Provider URL:  The URL of the identity provider endpoint.    Login Mapping:  The element in the SAML token that maps to the login name in PaperTrail. Usually, the element is NameID.     To make all authentication use SAML, change the  Services Properties Front End Main Page property  to  /saml .", 
            "title": "SAML Single Sign On"
        }, 
        {
            "location": "/Configuration/SSO/#windows-based-sso-ntlm", 
            "text": "NTLM SSO allows for users to be logged in automatically if they are already logged onto their domain account on their PC.     Check  Services -  Properties -  SSO  (Windows Kerberos/NTLM)", 
            "title": "Windows Based SSO (NTLM)"
        }, 
        {
            "location": "/Configuration/SSO/#linux-based-sso-kerberos", 
            "text": "Sometimes PaperTrail is installed on Linux server but needs to login in users automatically via Active Directory \u2013 This is only possible by using native Kerberos   Add the server (e.g., papertrail-srv) to the  AD Domain  (e.g., ad.local)    Create a  user account  (e.g., papertrail-acc) on the AD Domain    Configure PaperTrail to  run as the user account  (e.g., papertrail-acc)    Create a  SPN for each path  that PaperTrail will be accessed by.    e.g., for port 80:\nsetspn.exe -A HTTP/papertrail-srv papertrail-acc\nsetspn.exe -A HTTP/papertrail-srv.ad.local papertrail-acc\ne.g., for port 8080:\nsetspn.exe -A HTTP/papertrail-srv:8080 papertrail-acc\nsetspn.exe -A HTTP/papertrail-srv.ad.local:8080 papertrail-acc   Enable SSO on PaperTrail by editing the  Services -  Properties -  SSO (Kerberos)  properties.   Enable: ticked\nDomain: ad.local\nKDC: kdc.ad.local (whichever server responds to  ping ad.local  should be listed here)\nUsername: papertrail-acc\nPrincipal: papertrail-acc\nPassword: {password for papertrail-acc}   Update the  Front End -  Index Page  to:  /web/webapps/main.html .  Users need to be  logged onto the domain  (ad.local) and access  PaperTrail via the FQDN  (e.g., papertrail-srv.ad.local)", 
            "title": "Linux Based SSO (Kerberos)"
        }, 
        {
            "location": "/Configuration/Template Extraction/", 
            "text": "Template Extraction\n\n\nExtract from Templates\n\n\n\n\nSetup a folder called \n'extraction templates'\n\n\nExtract templates from cloud client who has this setup.\n\n\nBulk Export to obtain the extraction zones.\n\n\nImport the templates in the admin section from Tasks-\nDocuments Archive.\n\n\nAdd extract from template rules to those nodes that need to be setup.\n\n\n\n\nSetting up and Configuring Extract from Template rules\n\n\n\n\nAdd new extraction templates node under System as follow\n\n\n \n\n\nImport or copy documents ( PDF based ) to the extraction templates node, that you will be setting up as a template.  \n\n\nSetup new extractFromTemplates rule on the node where the documents will be importing. \n\n\n \n\n\nSelect the Template Editor for the Template editor to open in a new window.   \n\n\nSelect one of the documents that have been copied to your extraction templates node from the drop down\n\n  \n\n\nAdd a new Static Field ( This field will be used to recognize the document to use with this template ) \n\n   \n\n\nEnsure you add your default value for the documents to be recognized \n\n   \n\n\nAdd the new Zone Fields ( This will be configure for the Indexes ) \nChange the field ID to match your index name. \n\n   \n\n\nPosition the field on the document where you want the information to read from the document. \n\n\n\nOnce completed hit the save and Redeploy button to save your work to start testing.", 
            "title": "Template Extraction"
        }, 
        {
            "location": "/Configuration/Template Extraction/#template-extraction", 
            "text": "", 
            "title": "Template Extraction"
        }, 
        {
            "location": "/Configuration/Template Extraction/#extract-from-templates", 
            "text": "Setup a folder called  'extraction templates'  Extract templates from cloud client who has this setup.  Bulk Export to obtain the extraction zones.  Import the templates in the admin section from Tasks- Documents Archive.  Add extract from template rules to those nodes that need to be setup.", 
            "title": "Extract from Templates"
        }, 
        {
            "location": "/Configuration/Template Extraction/#setting-up-and-configuring-extract-from-template-rules", 
            "text": "Add new extraction templates node under System as follow     Import or copy documents ( PDF based ) to the extraction templates node, that you will be setting up as a template.    Setup new extractFromTemplates rule on the node where the documents will be importing.      Select the Template Editor for the Template editor to open in a new window.     Select one of the documents that have been copied to your extraction templates node from the drop down     Add a new Static Field ( This field will be used to recognize the document to use with this template )       Ensure you add your default value for the documents to be recognized       Add the new Zone Fields ( This will be configure for the Indexes ) \nChange the field ID to match your index name.       Position the field on the document where you want the information to read from the document.   Once completed hit the save and Redeploy button to save your work to start testing.", 
            "title": "Setting up and Configuring Extract from Template rules"
        }, 
        {
            "location": "/Configuration/User Management/", 
            "text": "User Management\n\n\nIn PaperTrail, a user is an individual who has \npermissions to log in to PaperTrail and perform various functions, such as reading and editing documents\n. \n\n\nA contact is an external user who \ndoes not have a PaperTrail login name and password, but who can be e-mailed documents and reports by other PaperTrail users\n.\n\n\nCreate a New User\n\n\n\n\nLet\u2019s start by creating a new user called Sally Smith. Sally will have a username of sallysmith.  \n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then User from the Navigation menu.  \n\n\nOn the Command Bar, select \nAdd\n.  \n\n\nSpecify all of the relevant fields for the new user. The Login field is the username that the user will use to log in. This name must not be currently used by an existing User, Group, Role, or Contact.  \n\n\nIf you need to synchronize this user\u2019s account with their Active Directory account, click the \nActive Directory checkbox\n. The value supplied in the Login field must match the user\u2019s Active Directory login (excluding the domain name).  \n\n\nClick \nAdd\n to generate the new user account.  \n\n\n\n\nReset a User\u2019s Password\n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then \nUser\n from the Navigation Menu.  \n\n\nSelect the user whose password you need to reset, and click \nReset Password\n. The password will be set to a blank password, which the user must then reset on their next login.  \n\n\n\n\nCreate an Internal Contact List\n\n\nThe following steps should be followed to create a contact who can receive e-mail notifications from other users.  \n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then  \nContact\n from the Navigation Menu.  \n\n\nSpecify a name for the user in the \nName\n field. This is the only required field; all other fields are optional.   \n\n\nWhen done specifying information for this user, select the \nAdd\n button.  \n\n\n\n\nExternal LDAP contact list\n\n\n\n\nExternal LDAP contact lists can be queried in order to populate email addresses for \nActions \u2192 Email\n.  \n\n\nConfigure \nActive Directory / LDAP settings\n.  \n\n\n\n\nCreate a Group\n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then Group from the Navigation Menu.  \n\n\nSelect \nAdd\n on the Command Bar.  \n\n\nSpecify a \nname\n for the new Group, such as Sales Team. This must be a \nunique name\n; it cannot be the name of another User, Group, Role, or Contact.  \n\n\nSelect \nAdd\n in the dialog box. The new group will be created.  \n\n\n\n\nAssigning a user to a group\n\n\nTo grant the permissions assigned to this group to a user, we simply add the user to this group.\n\n\n\n\nFrom within the \nAdministration interface\n, select \nUser Management\n and then \nGroup\n from the Navigation Menu.  \n\n\nSelect the group you created in the previous step, and then select \nUsers\n from the Command Bar.  \n\n\nIn the \nUsers dialog\n, begin to enter the name of the user you wish to add to the group. While typing, an autocomplete list of names will appear. Select the desired user to add, and then select the \nAdd button\n.  \n\n\nSelect the \nOK button\n on the \nUsers dialog\n.", 
            "title": "User Management"
        }, 
        {
            "location": "/Configuration/User Management/#user-management", 
            "text": "In PaperTrail, a user is an individual who has  permissions to log in to PaperTrail and perform various functions, such as reading and editing documents .   A contact is an external user who  does not have a PaperTrail login name and password, but who can be e-mailed documents and reports by other PaperTrail users .", 
            "title": "User Management"
        }, 
        {
            "location": "/Configuration/User Management/#create-a-new-user", 
            "text": "Let\u2019s start by creating a new user called Sally Smith. Sally will have a username of sallysmith.    From within the  Administration interface , select  User Management  and then User from the Navigation menu.    On the Command Bar, select  Add .    Specify all of the relevant fields for the new user. The Login field is the username that the user will use to log in. This name must not be currently used by an existing User, Group, Role, or Contact.    If you need to synchronize this user\u2019s account with their Active Directory account, click the  Active Directory checkbox . The value supplied in the Login field must match the user\u2019s Active Directory login (excluding the domain name).    Click  Add  to generate the new user account.", 
            "title": "Create a New User"
        }, 
        {
            "location": "/Configuration/User Management/#reset-a-users-password", 
            "text": "From within the  Administration interface , select  User Management  and then  User  from the Navigation Menu.    Select the user whose password you need to reset, and click  Reset Password . The password will be set to a blank password, which the user must then reset on their next login.", 
            "title": "Reset a User\u2019s Password"
        }, 
        {
            "location": "/Configuration/User Management/#create-an-internal-contact-list", 
            "text": "The following steps should be followed to create a contact who can receive e-mail notifications from other users.     From within the  Administration interface , select  User Management  and then   Contact  from the Navigation Menu.    Specify a name for the user in the  Name  field. This is the only required field; all other fields are optional.     When done specifying information for this user, select the  Add  button.", 
            "title": "Create an Internal Contact List"
        }, 
        {
            "location": "/Configuration/User Management/#external-ldap-contact-list", 
            "text": "External LDAP contact lists can be queried in order to populate email addresses for  Actions \u2192 Email .    Configure  Active Directory / LDAP settings .", 
            "title": "External LDAP contact list"
        }, 
        {
            "location": "/Configuration/User Management/#create-a-group", 
            "text": "From within the  Administration interface , select  User Management  and then Group from the Navigation Menu.    Select  Add  on the Command Bar.    Specify a  name  for the new Group, such as Sales Team. This must be a  unique name ; it cannot be the name of another User, Group, Role, or Contact.    Select  Add  in the dialog box. The new group will be created.", 
            "title": "Create a Group"
        }, 
        {
            "location": "/Configuration/User Management/#assigning-a-user-to-a-group", 
            "text": "To grant the permissions assigned to this group to a user, we simply add the user to this group.   From within the  Administration interface , select  User Management  and then  Group  from the Navigation Menu.    Select the group you created in the previous step, and then select  Users  from the Command Bar.    In the  Users dialog , begin to enter the name of the user you wish to add to the group. While typing, an autocomplete list of names will appear. Select the desired user to add, and then select the  Add button .    Select the  OK button  on the  Users dialog .", 
            "title": "Assigning a user to a group"
        }, 
        {
            "location": "/Configuration/WebScan/", 
            "text": "Web Scan\n\n\nWeb Scan Profile Settings\n\n\nseparation\n\n\ntype - \nstring\n\n\nPossible values:\n\n\n\n\n\n\nNone\n - combine all images to single PDF file;\n\n\n\n\n\n\nPage\n - put each image to new PDF file, so each PDF file will contain single page;\n\n\n\n\n\n\nBlank\n - create new PDF when blank image appeared. For instance, there is images sequence:\n\n\n\n\n\n\nimage1, image2, blank image, image3, image4, image5, blank image, image6\n\n\nAs a result of \nBlank\n separation, scan addon will return 3 PDF files: 2 pages (image1, image2), 3 pages (image3, image4, image5) and 1 page (image6).\n\n\n\n\nBarcode\n - create new PDF when image with unique barcode appeared. For instance, there is images sequence:\n\n\n\n\nimage1, image with barcode1, image2, image3, image with barcode3\n\n\nAs a result of \nBlank\n separation, scan addon will return 3 PDF files: 1 page (image1), 3 pages (image with barcode1, image2, image3) and 1 page (image with barcode3).\n\n\nresolution\n\n\ntype - \nobject\n\n\nFields:\n\n\n\n\n\n\nx\n - integer, \nx\n value of resolution. Common possible values: 100 - 600\n\n\n\n\n\n\ny\n - integer, \ny\n value of resolution. Common possible values: 100 - 600\n\n\n\n\n\n\nunits\n - string, measure units for \nx\n and \ny\n. Possible values:  \n\n\n\n\nInches  \n\n\nCentimeters  \n\n\nPoints  \n\n\nPixels  \n\n\n\n\n\n\n\n\nImportant note:\n list of supported values for \nresolution\n may vary depending on scanner model\n\n\ncompressionMode\n\n\ntype - \nstring\n\n\nCommon values:\n\n\n\n\nNone\n - don't use any compression mode;\n\n\nJpeg\n - intended for the compression of color photographs\n\n\nLzw\n - a compression licensed by UNISYS\n\n\nJbig\n - intended for bi-tonal and grayscale document images\n\n\nPng\n - Portable Network Graphic\n\n\nGroup4\n - CCITT Group 4 fax encoding, intended for document images\n\n\n\n\nImportant note:\n list of supported values for \ncompressionMode\n may vary depending on scanner model\n\n\npdfDecoder\n\n\ntype - \nobject\n\n\nFields:\n\n\n\n\nresolution\n - integer, resolution at which to render a PDF page. Minimum - 1, maximum - 3600.\n\n\n\n\nbarcodeSettings\n\n\ntype - \nobject\n\n\nSee \nBarcode Configuration\n for list of supported properties\n\n\nExamples\n\n\nSplit images into PDF files by barcode and use 300x300px scan resolution\n\n\n{\n  \nseparation\n: \nBarcode\n,\n  \nresolution\n: {\n    \nx\n: 300,\n    \ny\n: 300,\n    \nunits\n: \nPixels\n\n  }\n}\n\n\n\n\nCreate single PDF file from scanned images and render it with 80 resolution\n\n\n{\n  \nseparation\n: \nNone\n,\n  \npdfDecoder\n: {\n    \nresolution\n: 80\n  }\n}", 
            "title": "WebScan"
        }, 
        {
            "location": "/Configuration/WebScan/#web-scan", 
            "text": "", 
            "title": "Web Scan"
        }, 
        {
            "location": "/Configuration/WebScan/#web-scan-profile-settings", 
            "text": "", 
            "title": "Web Scan Profile Settings"
        }, 
        {
            "location": "/Configuration/WebScan/#separation", 
            "text": "type -  string  Possible values:    None  - combine all images to single PDF file;    Page  - put each image to new PDF file, so each PDF file will contain single page;    Blank  - create new PDF when blank image appeared. For instance, there is images sequence:    image1, image2, blank image, image3, image4, image5, blank image, image6  As a result of  Blank  separation, scan addon will return 3 PDF files: 2 pages (image1, image2), 3 pages (image3, image4, image5) and 1 page (image6).   Barcode  - create new PDF when image with unique barcode appeared. For instance, there is images sequence:   image1, image with barcode1, image2, image3, image with barcode3  As a result of  Blank  separation, scan addon will return 3 PDF files: 1 page (image1), 3 pages (image with barcode1, image2, image3) and 1 page (image with barcode3).", 
            "title": "separation"
        }, 
        {
            "location": "/Configuration/WebScan/#resolution", 
            "text": "type -  object  Fields:    x  - integer,  x  value of resolution. Common possible values: 100 - 600    y  - integer,  y  value of resolution. Common possible values: 100 - 600    units  - string, measure units for  x  and  y . Possible values:     Inches    Centimeters    Points    Pixels       Important note:  list of supported values for  resolution  may vary depending on scanner model", 
            "title": "resolution"
        }, 
        {
            "location": "/Configuration/WebScan/#compressionmode", 
            "text": "type -  string  Common values:   None  - don't use any compression mode;  Jpeg  - intended for the compression of color photographs  Lzw  - a compression licensed by UNISYS  Jbig  - intended for bi-tonal and grayscale document images  Png  - Portable Network Graphic  Group4  - CCITT Group 4 fax encoding, intended for document images   Important note:  list of supported values for  compressionMode  may vary depending on scanner model", 
            "title": "compressionMode"
        }, 
        {
            "location": "/Configuration/WebScan/#pdfdecoder", 
            "text": "type -  object  Fields:   resolution  - integer, resolution at which to render a PDF page. Minimum - 1, maximum - 3600.", 
            "title": "pdfDecoder"
        }, 
        {
            "location": "/Configuration/WebScan/#barcodesettings", 
            "text": "type -  object  See  Barcode Configuration  for list of supported properties", 
            "title": "barcodeSettings"
        }, 
        {
            "location": "/Configuration/WebScan/#examples", 
            "text": "Split images into PDF files by barcode and use 300x300px scan resolution  {\n   separation :  Barcode ,\n   resolution : {\n     x : 300,\n     y : 300,\n     units :  Pixels \n  }\n}  Create single PDF file from scanned images and render it with 80 resolution  {\n   separation :  None ,\n   pdfDecoder : {\n     resolution : 80\n  }\n}", 
            "title": "Examples"
        }, 
        {
            "location": "/Configuration/Yaml Config/", 
            "text": "YAML Import and Export\n\n\nIn addition to the various CSV and XML based exports available, a generic export/import interface is available via:\n[via?]\nImports can be imported multiple times without creating duplicates, this can be used for updating configuration.\n\n\nExamples\n\n\nTo import one or more entities:\n\n\nPOST: / dao /import/yml\n\n\n\n\nTo export all instances of an entity: \n\n\n/dao/export/yml/{Entity}\n\n\n\n\nTo export a specific entity:\n\n\n/dao/export/yml/{Entity}?id={name}\n\n\n\n\nWhere {Entity} is one of:  \n\n\n\n\nUser - All permissions and group memberships will be retained.  \n\n\nNode - All child nodes, indexes, permissions and rules will be retained.  \n\n\nListIndex - All values will be retained.  \n\n\nDataSource  \n\n\nRuleApplication  \n\n\nForm  \n\n\nTemplate  \n\n\nAll entities will export something - but the output may or may not import back in.  \n\n\n\n\nUsing \nhttpie\n:  \n\n\nhttp --auth admin:test POST \nhttp://localhost:8080/dao/import/yml\n \nAccept:*\n \n ~/test.yml", 
            "title": "Yaml Config"
        }, 
        {
            "location": "/Configuration/Yaml Config/#yaml-import-and-export", 
            "text": "In addition to the various CSV and XML based exports available, a generic export/import interface is available via:\n[via?]\nImports can be imported multiple times without creating duplicates, this can be used for updating configuration.", 
            "title": "YAML Import and Export"
        }, 
        {
            "location": "/Configuration/Yaml Config/#examples", 
            "text": "To import one or more entities:  POST: / dao /import/yml  To export all instances of an entity:   /dao/export/yml/{Entity}  To export a specific entity:  /dao/export/yml/{Entity}?id={name}  Where {Entity} is one of:     User - All permissions and group memberships will be retained.    Node - All child nodes, indexes, permissions and rules will be retained.    ListIndex - All values will be retained.    DataSource    RuleApplication    Form    Template    All entities will export something - but the output may or may not import back in.     Using  httpie :    http --auth admin:test POST  http://localhost:8080/dao/import/yml   Accept:*    ~/test.yml", 
            "title": "Examples"
        }, 
        {
            "location": "/Configuration/indexes/", 
            "text": "Configuring Node Indexes / Fields\n\n\nIndex Types\n\n\n\n\n\n\n\n\nType\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nText\n\n\n\n\n\n\n\n\n\n\nLong Text\n\n\nA comment box that can accept many lines of text.  \nWarning:\n Builtin notes and comments are most likely a better option\n\n\n\n\n\n\n\n\nDate\n\n\nA date in yyyy-mm-dd format\n\n\n2011-12-31\n\n\n\n\n\n\nDate Time\n\n\nA date with a time in yyyy-mm-dd hh:mm format\n\n\n2011-12-31 08:00\n\n\n\n\n\n\nNumber\n\n\n\n\n1\n\n\n\n\n\n\nDouble\n\n\n\n\n1.15\n\n\n\n\n\n\nList\n\n\nSelectable list\n\n\n\n\n\n\n\n\nLong List\n\n\nAutocomplete list - user needs to enter at least 1 letter\n\n\n\n\n\n\n\n\nAuto Number\n\n\nGenerated on create, non editable\n\n\nREF001\n\n\n\n\n\n\nUUID\n\n\nGenerated on create, not editable\n\n\nbe8ca9db-1e8c-4c27-8aad-52f974109f64\n\n\n\n\n\n\nDocument Picker\n\n\n\n\ndocument.docx\n\n\n\n\n\n\nUser Picker\n\n\n\n\nJohn Doe\n\n\n\n\n\n\nDB Lookup\n\n\nDepreceated\n Use a datasource backed list instead\n\n\n\n\n\n\n\n\n\n\nScripting - Front End\n\n\nThe \ncustom\n property can be used to configure a field at runtime, it accepts valid javascript object \n\n\ne.g Create a \nTEXT\n field called ID Type and then add\n\n\n{\n    type: 'formcombo',\n    types: {\n        \nID\n: \nID Meta Model\n,\n        \nPassport\n:\nPassword Meta Model\n,\n    },\n    value: 'Payslip'\n}\n\n\n\n\nThen create a metamodel for each document type:\n\n\n--- !\nMetaModel\n\nname: ID Meta Model\nfields:\n- ID No\n\n--- !\nMetaModel\n\nname: Passport Meta Model\nfields:\n- Passport No\n- Country of Issue\n- Expiry Date\n\n\n\n\nWhen a user selects \nID\n a \nID No\n field will be shown which can include validation for length, etc. If they select \nPassport\n A \nPassport No\n, \nCountry of Issue\n and \nExpiry Date\n fields will be shown\n\n\nScripting - Server Side\n\n\nDefault Value\n is used when a document is created without an index value \n\n\ne.g. \n${new Date():yyyy}\n will automatically populate a year index with the current year.\n\n\nSee \nStandard Expression\n\n\nRegex\n is a Java regular expression that is evaluated server side, if the value does not match the user is shown a validation error.\n\n\nSee \nRegular Expressions\n\n\nFilter\n are evaluated just before an index value is saved, it accepts any Groovy statement\n\n\ne.g.\n\n\nRemove whitespaces:\n\n\nvalue.replaceAll(\n\\\\w*\n, \n)\n\n\n\n\nStrip out all non digits:\n\n\nvalue.replaceAll(\n\\\\D+\n, \n)\n\n\n\n\nUppercase and trim:\n\n\nvalue.toUpperCase().trim()\n\n\n\n\nProperties\n\n\nName\n\u00a0- The name used in the database - Index names cannot be changed after they are created.\u00a0\n\n\nCase Sensitivity\n - All indexes with a common name need to be in the same case, PaperTrail will automatilly change the case if an indexing index in a different node has a different case.\n\n\n\n\nWhile indexes names are case sensitive, their use within queries, scripts and expressions is case \ninsensitive\n\n\n\n\nMandatory\n vs \nRequired\n  - Required indexes have a hard restriction server side, they can never be empty. Mandatory indexes are only restricted on a user interface level. e.g. Does not affect systematic imports via API, Folder Watch, Email Watch etc..\n\n\n\n\nIf a required index is added to a node which already has documents, the index will need to be populated before anything else can be done with those documents)\n\n\n\n\nRead Only\n Indexes can oinly be set on import, thereafter they are non editable", 
            "title": "Indexes"
        }, 
        {
            "location": "/Configuration/indexes/#configuring-node-indexes-fields", 
            "text": "", 
            "title": "Configuring Node Indexes / Fields"
        }, 
        {
            "location": "/Configuration/indexes/#index-types", 
            "text": "Type  Description  Example      Text      Long Text  A comment box that can accept many lines of text.   Warning:  Builtin notes and comments are most likely a better option     Date  A date in yyyy-mm-dd format  2011-12-31    Date Time  A date with a time in yyyy-mm-dd hh:mm format  2011-12-31 08:00    Number   1    Double   1.15    List  Selectable list     Long List  Autocomplete list - user needs to enter at least 1 letter     Auto Number  Generated on create, non editable  REF001    UUID  Generated on create, not editable  be8ca9db-1e8c-4c27-8aad-52f974109f64    Document Picker   document.docx    User Picker   John Doe    DB Lookup  Depreceated  Use a datasource backed list instead", 
            "title": "Index Types"
        }, 
        {
            "location": "/Configuration/indexes/#scripting-front-end", 
            "text": "The  custom  property can be used to configure a field at runtime, it accepts valid javascript object   e.g Create a  TEXT  field called ID Type and then add  {\n    type: 'formcombo',\n    types: {\n         ID :  ID Meta Model ,\n         Passport : Password Meta Model ,\n    },\n    value: 'Payslip'\n}  Then create a metamodel for each document type:  --- ! MetaModel \nname: ID Meta Model\nfields:\n- ID No\n\n--- ! MetaModel \nname: Passport Meta Model\nfields:\n- Passport No\n- Country of Issue\n- Expiry Date  When a user selects  ID  a  ID No  field will be shown which can include validation for length, etc. If they select  Passport  A  Passport No ,  Country of Issue  and  Expiry Date  fields will be shown", 
            "title": "Scripting - Front End"
        }, 
        {
            "location": "/Configuration/indexes/#scripting-server-side", 
            "text": "Default Value  is used when a document is created without an index value   e.g.  ${new Date():yyyy}  will automatically populate a year index with the current year.  See  Standard Expression  Regex  is a Java regular expression that is evaluated server side, if the value does not match the user is shown a validation error.  See  Regular Expressions  Filter  are evaluated just before an index value is saved, it accepts any Groovy statement  e.g.  Remove whitespaces:  value.replaceAll( \\\\w* ,  )  Strip out all non digits:  value.replaceAll( \\\\D+ ,  )  Uppercase and trim:  value.toUpperCase().trim()", 
            "title": "Scripting - Server Side"
        }, 
        {
            "location": "/Configuration/indexes/#properties", 
            "text": "Name \u00a0- The name used in the database - Index names cannot be changed after they are created.\u00a0  Case Sensitivity  - All indexes with a common name need to be in the same case, PaperTrail will automatilly change the case if an indexing index in a different node has a different case.   While indexes names are case sensitive, their use within queries, scripts and expressions is case  insensitive   Mandatory  vs  Required   - Required indexes have a hard restriction server side, they can never be empty. Mandatory indexes are only restricted on a user interface level. e.g. Does not affect systematic imports via API, Folder Watch, Email Watch etc..   If a required index is added to a node which already has documents, the index will need to be populated before anything else can be done with those documents)   Read Only  Indexes can oinly be set on import, thereafter they are non editable", 
            "title": "Properties"
        }, 
        {
            "location": "/Configuration/security/", 
            "text": "Security Settings\n\n\nPaperTrail can be run in 4 distinct\u00a0security modes:\n\n\nLow (Default)\n\n\nSuitable for intra-net based deployments without confidential data\u00a0\n\n\nMedium\n\n\nAccess to the various API's used for replication and clustering is\nrestricted based on Trusted Server entries, some of the endpoints\nrestricted include:\n \u00a0\n\n\n\n\nconversion\n\n\nsignature/upload\n\n\nindex/replication\n\n\nstore\n\n\nreplicate\n\n\n\n\nHigh\n\n\nIncludes all the restrictions of Medium and:\n \u00a0\n\n\n\n\ndisables the /script/console endpoint (used by\n    /web/admin/console.html and pt script\u00a0CLI)\n\n\nprevents updates to the following properties via the web UI, they\n    need to be set via papertrail.properties file:\n\n\n\n\n    ldap.host  \n    waffle.enable  \n    spnego.enable  \n    spnego.kdc  \n    smtp.debug  \n    email.spool  \n    smtp.host  \n    sms.url  \n    web.login.sms.otp  \n    index.store  \n    http.ssl  \n    disabled.audits  \n    disabled.entity.audits  \n    openoffice.path  \n    tiff2pdf.process  \n    pdf2swf.process  \n    security.level  \n\n\n\n\nVery High\n\n\nIncludes all the restrictions of High and further restricts:\n\n\n\n\nLoading jar files via System/jars folder\n\n\nLoading scripts via System/scripts folder\n\n\nLoading UI plugins via System/plugins folder\n\n\nScripted data sources\n\n\nrunScript, dbLookup and commandLineProcess rules\n\n\nCustom options in Meta Model Fields\n\n\nPQL Expressions", 
            "title": "Security"
        }, 
        {
            "location": "/Configuration/security/#security-settings", 
            "text": "PaperTrail can be run in 4 distinct\u00a0security modes:", 
            "title": "Security Settings"
        }, 
        {
            "location": "/Configuration/security/#low-default", 
            "text": "Suitable for intra-net based deployments without confidential data", 
            "title": "Low (Default)"
        }, 
        {
            "location": "/Configuration/security/#medium", 
            "text": "Access to the various API's used for replication and clustering is\nrestricted based on Trusted Server entries, some of the endpoints\nrestricted include:\n \u00a0   conversion  signature/upload  index/replication  store  replicate", 
            "title": "Medium"
        }, 
        {
            "location": "/Configuration/security/#high", 
            "text": "Includes all the restrictions of Medium and:\n \u00a0   disables the /script/console endpoint (used by\n    /web/admin/console.html and pt script\u00a0CLI)  prevents updates to the following properties via the web UI, they\n    need to be set via papertrail.properties file:       ldap.host  \n    waffle.enable  \n    spnego.enable  \n    spnego.kdc  \n    smtp.debug  \n    email.spool  \n    smtp.host  \n    sms.url  \n    web.login.sms.otp  \n    index.store  \n    http.ssl  \n    disabled.audits  \n    disabled.entity.audits  \n    openoffice.path  \n    tiff2pdf.process  \n    pdf2swf.process  \n    security.level", 
            "title": "High"
        }, 
        {
            "location": "/Configuration/security/#very-high", 
            "text": "Includes all the restrictions of High and further restricts:   Loading jar files via System/jars folder  Loading scripts via System/scripts folder  Loading UI plugins via System/plugins folder  Scripted data sources  runScript, dbLookup and commandLineProcess rules  Custom options in Meta Model Fields  PQL Expressions", 
            "title": "Very High"
        }, 
        {
            "location": "/Configuration/ssl/", 
            "text": "Configuring HTTPS (Server Side Only)\n\n\nTo configure PaperTrail to use HTTPS:\n\n\n\n\nCreate a Java key store (JKS) with a name of \nkeystore\n and place it in the \nconf\n directory\n\n\nSpecify the keystore password via \nhttp.ssl.password\n\n\nCheck Properties -\n HTTPS -\n Enable (\nhttp.ssl\n) to true\n\n\nSet the HTTPS port (\nhttp.ssl.port\n) to 443 or 8443\n\n\nCheck Force SSL (\nhttp.ssl.force\n) to always redirect from HTTP to HTTPS\n\n\n\n\nConverting PKCS#7 to PKCS#12\n\n\nopenssl pkcs12 -export -in server.crt -inkey server.key   -out keystore.p12 -name www\n\n\nConverting PKCS#12 to JKS\n\n\nkeytool -importkeystore -destkeystore keystore -srckeystore keystore.p12 -srcstoretype PKCS12\n               \n\n\nImport Root and Intermediate CA's\n\n\nkeytool -import -trustcacerts -alias root -file root.crt -keystore keystore\n\n\nVerifying\n\n\nTo verify that the keystore is configured correctly:\n\n\nkeytool -list -keystore keystore\n \n\n\nWhich should produce something like:\n\n\n\n\nKeystore type: JKS\nKeystore provider: SUN\n\n\nYour keystore contains 1 entry\n\n\n*.papertrail.co.za, Oct 29, 2015, PrivateKeyEntry, \n\n\n\n\nThe last line has a syntax of \n{CN} {Expiry} {Key Type}\n  \n\n\n{CN}\n should match the URL you would be accessing PaperTrail by\n\n\n{Key Type}\n must be PrivateKeyEntry  \n\n\nConfiguring Client Authentication (Mutual SSL)\n\n\n\n\nConfigure server side SSL as above\n\n\nCreate a new a JKS file called \ntruststore\n containing the trusted CA's\n\n\nCheck Require Client Certificates (\nhttp.ssl.client.require\n)\n\n\n\n\nConfiguring client certificates requires that \nall\n clients supply a trusted certificate.\n\n\nThe Common Name (\nCN\n) of the certificate will be used to map the a certificate to a user via the login field.", 
            "title": "Ssl"
        }, 
        {
            "location": "/Configuration/ssl/#configuring-https-server-side-only", 
            "text": "To configure PaperTrail to use HTTPS:   Create a Java key store (JKS) with a name of  keystore  and place it in the  conf  directory  Specify the keystore password via  http.ssl.password  Check Properties -  HTTPS -  Enable ( http.ssl ) to true  Set the HTTPS port ( http.ssl.port ) to 443 or 8443  Check Force SSL ( http.ssl.force ) to always redirect from HTTP to HTTPS", 
            "title": "Configuring HTTPS (Server Side Only)"
        }, 
        {
            "location": "/Configuration/ssl/#converting-pkcs7-to-pkcs12", 
            "text": "openssl pkcs12 -export -in server.crt -inkey server.key   -out keystore.p12 -name www", 
            "title": "Converting PKCS#7 to PKCS#12"
        }, 
        {
            "location": "/Configuration/ssl/#converting-pkcs12-to-jks", 
            "text": "keytool -importkeystore -destkeystore keystore -srckeystore keystore.p12 -srcstoretype PKCS12", 
            "title": "Converting PKCS#12 to JKS"
        }, 
        {
            "location": "/Configuration/ssl/#import-root-and-intermediate-cas", 
            "text": "keytool -import -trustcacerts -alias root -file root.crt -keystore keystore", 
            "title": "Import Root and Intermediate CA's"
        }, 
        {
            "location": "/Configuration/ssl/#verifying", 
            "text": "To verify that the keystore is configured correctly:  keytool -list -keystore keystore    Which should produce something like:   Keystore type: JKS\nKeystore provider: SUN  Your keystore contains 1 entry  *.papertrail.co.za, Oct 29, 2015, PrivateKeyEntry,    The last line has a syntax of  {CN} {Expiry} {Key Type}     {CN}  should match the URL you would be accessing PaperTrail by  {Key Type}  must be PrivateKeyEntry", 
            "title": "Verifying"
        }, 
        {
            "location": "/Configuration/ssl/#configuring-client-authentication-mutual-ssl", 
            "text": "Configure server side SSL as above  Create a new a JKS file called  truststore  containing the trusted CA's  Check Require Client Certificates ( http.ssl.client.require )   Configuring client certificates requires that  all  clients supply a trusted certificate.  The Common Name ( CN ) of the certificate will be used to map the a certificate to a user via the login field.", 
            "title": "Configuring Client Authentication (Mutual SSL)"
        }, 
        {
            "location": "/Installation/Desktop Agent/", 
            "text": "Desktop Agent\n\n\n\n\nClick Next to proceed with installation.\n\n\n\n\nAfter selecting destination directory, click Next. \n\n\n\n\nEnable the Create a Start Menu Folder and click Next.\n\n\n\n\nPlease wait while PaperTrail Desktop Agent is installed.\n\n\n\n\nSelect Additional Tasks and click Next.\n\n\n\n\nClick Finish.\n\n\n\n\nAfter the installation, select a Setup Type and click Next.\n\n\n\n\nYou can enter your PaperTrail server details and click Next.\n\n\n\n\nYou can select your Watched Folders location as displayed and click Next.\n\n\n\n\nSelect a Document Type and click Next.\n\n\n\n\nClick Finish to complete the setup process.\n\n\n\n\nYou can go to the following link to access the desktop agent: \nhttp://localhost:8884\n.", 
            "title": "Desktop Agent"
        }, 
        {
            "location": "/Installation/Desktop Agent/#desktop-agent", 
            "text": "Click Next to proceed with installation.   After selecting destination directory, click Next.    Enable the Create a Start Menu Folder and click Next.   Please wait while PaperTrail Desktop Agent is installed.   Select Additional Tasks and click Next.   Click Finish.   After the installation, select a Setup Type and click Next.   You can enter your PaperTrail server details and click Next.   You can select your Watched Folders location as displayed and click Next.   Select a Document Type and click Next.   Click Finish to complete the setup process.   You can go to the following link to access the desktop agent:  http://localhost:8884 .", 
            "title": "Desktop Agent"
        }, 
        {
            "location": "/Installation/MS Office Add-in/", 
            "text": "PaperTrail MS Office Add-In\n\n\nIn these steps, we will see how to install PaperTrail MS Office Add-In \n\n\n\n\n\n\nEnsure that \nDot NET version 4 (.NET Framework)\n is installed before installing the PaperTrail Add-In.\n\nNOTE: A computer reboot will be required if Dot NET is installed for the first time.\n\n\n\n\n\n\nClose all Microsoft Office applications\n e.g. Word, Outlook, Excel, etc.  \n\n\n\n\n\n\nIf a previous release of the PaperTrail Add-In has been installed on the machine, please \nuninstall the older version\n before installing a later release. (Check the \nAdd and Remove Programs\n, or \nProgram and Features section\n for installed programs.)  \n\n\n\n\n\n\nIf the PaperTrail Add-in was previously installed on the computer, \ndelete the PaperTrail Add-In folder\n after the application has been uninstalled. Default install paths to follow:\n\n\n\n\n\n\nMS Windows 7\n8:\n \n..\\Users\\{user login}\\AppData\\Roaming\\\n\n\nMS Windows XP:\n \n..\\Documents and Settings\\Users\\{user login}\\AppData\\Roaming\\\n\n\nConfiguration\n\n\nTo configure the plugin, \n\n\n\n\nHost\n : Insert the URL, up until the port detail, used to access PaperTrail within your network / domain. \n\n\n\n\nExample: \nhttp://{servername}:8080\n. Replace the {servername} portion with the name or IP of the PaperTrail server.  \n\n\n\n\n\n\nUsername\n : Enter PaperTrail username.  \n\n\n\n\n\n\nPassword\n : Enter PaperTrail password.  \n\n\n\n\n\n\nClick \nSign In\n.  \n\n\n\n\n\n\n\n\nTroubleshooting\n\n\n\n\nNote : If the Plug-in cannot connect/authenticate, check if the user can connect to PaperTrail using a web browser on the user\u2019s machine. Confirm that the user can login to PaperTrail with the same account details being used during the Plug-in authentication section.\n\n\n\n\nIt is possible that the MS Office application can fail to load the PaperTrail Add-In due to different reasons. If the PaperTrail Add-In is not available, check whether the Add-In has been disabled by the MS Office application in use. To access the disabled Add-In section follow these steps:\n\n\nTo enable Add-in in Outlook 2003:\n\n\nClick \nTools -\n Other -\n Advanced Options -\n Add-ins -\n Manage -\n Select Disabled Add-ins\n from the dropdown and tick \nPaperTrail Add-in\n.\n\n\nTo enable Add-in in Outlook 2007:\n\n\nClick \nTools -\n Trust center -\n Add-ins -\n Manage -\n Select Disabled Add-ins\n from the dropdown and tick \nPaperTrail Add-in\n.\n\n\nTo enable Add-in in Outlook 2010:\n\n\nClick \nFile -\n Options -\n Add-Ins -\n Manage -\n Select Disabled Add-ins\n from the dropdown and tick \nPaperTrail Add-in\n.", 
            "title": "MS Office Add in"
        }, 
        {
            "location": "/Installation/MS Office Add-in/#papertrail-ms-office-add-in", 
            "text": "In these steps, we will see how to install PaperTrail MS Office Add-In     Ensure that  Dot NET version 4 (.NET Framework)  is installed before installing the PaperTrail Add-In. \nNOTE: A computer reboot will be required if Dot NET is installed for the first time.    Close all Microsoft Office applications  e.g. Word, Outlook, Excel, etc.      If a previous release of the PaperTrail Add-In has been installed on the machine, please  uninstall the older version  before installing a later release. (Check the  Add and Remove Programs , or  Program and Features section  for installed programs.)      If the PaperTrail Add-in was previously installed on the computer,  delete the PaperTrail Add-In folder  after the application has been uninstalled. Default install paths to follow:    MS Windows 7 8:   ..\\Users\\{user login}\\AppData\\Roaming\\  MS Windows XP:   ..\\Documents and Settings\\Users\\{user login}\\AppData\\Roaming\\", 
            "title": "PaperTrail MS Office Add-In"
        }, 
        {
            "location": "/Installation/MS Office Add-in/#configuration", 
            "text": "To configure the plugin,    Host  : Insert the URL, up until the port detail, used to access PaperTrail within your network / domain.    Example:  http://{servername}:8080 . Replace the {servername} portion with the name or IP of the PaperTrail server.      Username  : Enter PaperTrail username.      Password  : Enter PaperTrail password.      Click  Sign In .", 
            "title": "Configuration"
        }, 
        {
            "location": "/Installation/MS Office Add-in/#troubleshooting", 
            "text": "Note : If the Plug-in cannot connect/authenticate, check if the user can connect to PaperTrail using a web browser on the user\u2019s machine. Confirm that the user can login to PaperTrail with the same account details being used during the Plug-in authentication section.   It is possible that the MS Office application can fail to load the PaperTrail Add-In due to different reasons. If the PaperTrail Add-In is not available, check whether the Add-In has been disabled by the MS Office application in use. To access the disabled Add-In section follow these steps:  To enable Add-in in Outlook 2003:  Click  Tools -  Other -  Advanced Options -  Add-ins -  Manage -  Select Disabled Add-ins  from the dropdown and tick  PaperTrail Add-in .  To enable Add-in in Outlook 2007:  Click  Tools -  Trust center -  Add-ins -  Manage -  Select Disabled Add-ins  from the dropdown and tick  PaperTrail Add-in .  To enable Add-in in Outlook 2010:  Click  File -  Options -  Add-Ins -  Manage -  Select Disabled Add-ins  from the dropdown and tick  PaperTrail Add-in .", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/Installation/Replication/", 
            "text": "Replication\n\n\nClean Install\n\n\n\n\nInstall PaperTrail on master.\n\n\nStartup master.\n\n\nShutdown master and create db dump.\n\n\n\n\n    db.replication.enable=true db.replication.external.id=master db.replication.group.id=master file.replication.upstream=http://slave:8080\n\n\n\n\n\n\nEnable replication on the master and start PaperTrail.\n\n\nRestore master dump on slave and copy over repository.\n\n\nEnable replication on slave and start PaperTrail.\n\n\n\n\ndb.replication.enable=true db.replication.external.id=slave db.replication.group.id=slave db.replication.master=replication1 file.replication.upstream=http://master:8080\n\n\n\n\nUpgrade\n\n\n\n\nShutdown PaperTrail on master and slave.\n\n\nUpgrade PaperTrail on master and startup.\n\n\nUpgrade PaperTrail on slave and startup.\n\n\n\n\nFilestore Replication\n\n\nWhen setting up file store replication to a secondary PaperTrail installation, follow the below points:\n\n\n\n\nWhen entering the URL to the secondary PT, include \"/store\" at the end of the PT URL e.g. http://\n:\n/store\n\n\nAlways tick the \"Async\" option. Not only is this option helpful for slow connections, but it also manages imports if the secondary PT is not available.", 
            "title": "Replication"
        }, 
        {
            "location": "/Installation/Replication/#replication", 
            "text": "", 
            "title": "Replication"
        }, 
        {
            "location": "/Installation/Replication/#clean-install", 
            "text": "Install PaperTrail on master.  Startup master.  Shutdown master and create db dump.       db.replication.enable=true db.replication.external.id=master db.replication.group.id=master file.replication.upstream=http://slave:8080   Enable replication on the master and start PaperTrail.  Restore master dump on slave and copy over repository.  Enable replication on slave and start PaperTrail.   db.replication.enable=true db.replication.external.id=slave db.replication.group.id=slave db.replication.master=replication1 file.replication.upstream=http://master:8080", 
            "title": "Clean Install"
        }, 
        {
            "location": "/Installation/Replication/#upgrade", 
            "text": "Shutdown PaperTrail on master and slave.  Upgrade PaperTrail on master and startup.  Upgrade PaperTrail on slave and startup.", 
            "title": "Upgrade"
        }, 
        {
            "location": "/Installation/Replication/#filestore-replication", 
            "text": "When setting up file store replication to a secondary PaperTrail installation, follow the below points:   When entering the URL to the secondary PT, include \"/store\" at the end of the PT URL e.g. http:// : /store  Always tick the \"Async\" option. Not only is this option helpful for slow connections, but it also manages imports if the secondary PT is not available.", 
            "title": "Filestore Replication"
        }, 
        {
            "location": "/Installation/Sizing/", 
            "text": "PaperTrail Server Requirements\n\n\n\n\n2 - 4GB RAM\n\n\n2 Modern CPU Cores\n\n\n20GB + free disk space\n\n\n\n\nDatabase\n\n\n\n\nThe database should be kept entirely in RAM on fast disks (SSD, RAID 1\nwith cache etc). A rough guideline is to use 1GB of RAM per 1 million docs.  \n\n\nA centralized database can be used, however\u00a0it can introduce latency.  \n\n\n\n\nIndex Directory\n\n\n\n\nThe index directory is where Lucene stores all indexes for searching. As\na rule of thumb is it's around 1 - 2 GB per million docs, more if full\ntext searching is enabled.  \n\n\nThe index directory needs to be on fast disks (RAID 0, SSD) and does\nnot need to backed up as it can be easily and quickly (with full text\ndisabled) rebuilt.  \n\n\n\n\nFile Repository\n\n\n\n\nThe file repository has lots of small file based IO where each file is stored\nby name as checksum. So once a file is written, it is never updated - only\ndeleted.\n\n\nIt can safely be backed up and then archived.\n\n\nRAID 6+ is sufficient.\n\n\nFiles can also be stored on a object storage platform like Amazon S3,\nCaringo CAStore reducing the need for backups.\n\n\nReplication can also be configured between 2 PaperTrail instances using\nfile stores.", 
            "title": "Sizing"
        }, 
        {
            "location": "/Installation/Sizing/#papertrail-server-requirements", 
            "text": "2 - 4GB RAM  2 Modern CPU Cores  20GB + free disk space", 
            "title": "PaperTrail Server Requirements"
        }, 
        {
            "location": "/Installation/Sizing/#database", 
            "text": "The database should be kept entirely in RAM on fast disks (SSD, RAID 1\nwith cache etc). A rough guideline is to use 1GB of RAM per 1 million docs.    A centralized database can be used, however\u00a0it can introduce latency.", 
            "title": "Database"
        }, 
        {
            "location": "/Installation/Sizing/#index-directory", 
            "text": "The index directory is where Lucene stores all indexes for searching. As\na rule of thumb is it's around 1 - 2 GB per million docs, more if full\ntext searching is enabled.    The index directory needs to be on fast disks (RAID 0, SSD) and does\nnot need to backed up as it can be easily and quickly (with full text\ndisabled) rebuilt.", 
            "title": "Index Directory"
        }, 
        {
            "location": "/Installation/Sizing/#file-repository", 
            "text": "The file repository has lots of small file based IO where each file is stored\nby name as checksum. So once a file is written, it is never updated - only\ndeleted.  It can safely be backed up and then archived.  RAID 6+ is sufficient.  Files can also be stored on a object storage platform like Amazon S3,\nCaringo CAStore reducing the need for backups.  Replication can also be configured between 2 PaperTrail instances using\nfile stores.", 
            "title": "File Repository"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/", 
            "text": "Ubuntu Linux\n\n\nJava\n\n\n\n\nInstall Oracle Java 8 SDK:\n\n\n\n\nadd-apt-repository ppa:webupd8team/java --yes   \napt-get update   \necho oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | /usr/bin/debconf-set-selections\napt-get install oracle-java8-installer update-java-alternatives -s java-8-oracle  \n\n\n\n\n\n\n\n\nInstall JCE Unlimited strength policy files for some AES-256 encryption operations (optional).\n\n\n\n\n\n\nThe policy jar files can be downloaded from \nhere\n\n\n\n\n\n\ncp local_policy.jar /usr/lib/jvm/java-8-oracle/jre/lib/security/\ncp US_export_policy.jar /usr/lib/jvm/java-8-oracle/jre/lib/security/ \n\n\n\n\nPostgreSQL\n\n\n\n\nInstall PostGres \n\n\n\n\napt-get install postgresql-9.3\n\n\n\n\n(If postgres is not available, follow the instructions at http://wiki.postgresql.org/wiki/Apt to install the repository and then re-try.)\n\n\n\n\nCreate database and postgres Papertrail user:\n\n\n\n\nPSQL_VERSION=9.3 sudo -u postgres psql -c \n\nCREATE ROLE papertrail PASSWORD 'papertrail' SUPERUSER CREATEDB CREATEROLE INHERIT LOGIN;\n   \nsudo -u postgres psql -c 'create database papertrail with owner papertrail;'  \necho host  papertrail papertrail  127.0.0.1/32 md5 \n /etc/postgresql/$PSQL_VERSION/main/pg_hba.conf /etc/init.d/postgresql restart\n\n\n\n\nConversion\n\n\nInstall the following dependencies:\n\n\n\n\nlibreoffice\n\n\nlibtiff-tools\n\n\nghostscript\n\n\nswftools\n\n\n\n\napt-get install libreoffice libtiff-tools ghostscript\n\n\n\n\nswftools is not a standard package - To install it, use\n\n\nsudo apt-get -y install libjpeg62 libgif4 sudo apt-get -y install libart-2.0-2 wget -P /tmp/http://archive.canonical.com/ubuntu/pool/partner/s/swftools/swftools_0.9.0-0ubuntu2_amd64.deb chmod a+x /tmp/swftools_0.9.0-0ubuntu2_amd64.deb sudo dpkg -i /tmp/swftools_0.9.0-0ubuntu2_amd64.deb\n\n\n\n\nPaperTrail Service\n\n\n1) Install PaperTrail\n\nsh Papertrail_\nversion\n.sh -q\n\n\n2) Update the db settings in the \n/opt/Papertrail/conf/papertrail/properties\n\n\ndb.database=papertrail\ndb.host=localhost\ndb.pass=papertrail\ndb.user=papertrail\ndb.type=postgresql\n\n\n\n\n3) Start papertrail\n\n/etc/init.d/papertrail start", 
            "title": "Ubuntu Linux"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/#ubuntu-linux", 
            "text": "", 
            "title": "Ubuntu Linux"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/#java", 
            "text": "Install Oracle Java 8 SDK:   add-apt-repository ppa:webupd8team/java --yes   \napt-get update   \necho oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | /usr/bin/debconf-set-selections\napt-get install oracle-java8-installer update-java-alternatives -s java-8-oracle      Install JCE Unlimited strength policy files for some AES-256 encryption operations (optional).    The policy jar files can be downloaded from  here    cp local_policy.jar /usr/lib/jvm/java-8-oracle/jre/lib/security/\ncp US_export_policy.jar /usr/lib/jvm/java-8-oracle/jre/lib/security/", 
            "title": "Java"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/#postgresql", 
            "text": "Install PostGres    apt-get install postgresql-9.3  (If postgres is not available, follow the instructions at http://wiki.postgresql.org/wiki/Apt to install the repository and then re-try.)   Create database and postgres Papertrail user:   PSQL_VERSION=9.3 sudo -u postgres psql -c  CREATE ROLE papertrail PASSWORD 'papertrail' SUPERUSER CREATEDB CREATEROLE INHERIT LOGIN;    \nsudo -u postgres psql -c 'create database papertrail with owner papertrail;'  \necho host  papertrail papertrail  127.0.0.1/32 md5   /etc/postgresql/$PSQL_VERSION/main/pg_hba.conf /etc/init.d/postgresql restart", 
            "title": "PostgreSQL"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/#conversion", 
            "text": "Install the following dependencies:   libreoffice  libtiff-tools  ghostscript  swftools   apt-get install libreoffice libtiff-tools ghostscript  swftools is not a standard package - To install it, use  sudo apt-get -y install libjpeg62 libgif4 sudo apt-get -y install libart-2.0-2 wget -P /tmp/http://archive.canonical.com/ubuntu/pool/partner/s/swftools/swftools_0.9.0-0ubuntu2_amd64.deb chmod a+x /tmp/swftools_0.9.0-0ubuntu2_amd64.deb sudo dpkg -i /tmp/swftools_0.9.0-0ubuntu2_amd64.deb", 
            "title": "Conversion"
        }, 
        {
            "location": "/Installation/Ubuntu-Linux/#papertrail-service", 
            "text": "1) Install PaperTrail sh Papertrail_ version .sh -q  2) Update the db settings in the  /opt/Papertrail/conf/papertrail/properties  db.database=papertrail\ndb.host=localhost\ndb.pass=papertrail\ndb.user=papertrail\ndb.type=postgresql  3) Start papertrail /etc/init.d/papertrail start", 
            "title": "PaperTrail Service"
        }, 
        {
            "location": "/Installation/Windows/", 
            "text": "Windows Installations\n\n\n\n\nOn some versions of Windows 2012 you may need to install \nVisual C++\n\n\n\n\nSQL Server Windows Authentication\n\n\n\n\nCopy \nntmlauth.dll\n file to C:\\Windows \n\n\nFor remote installations, make sure that the Windows user that has been granted DB\naccess is the same as the user that is being logged in to the application\nmachine.", 
            "title": "Windows"
        }, 
        {
            "location": "/Installation/Windows/#windows-installations", 
            "text": "On some versions of Windows 2012 you may need to install  Visual C++", 
            "title": "Windows Installations"
        }, 
        {
            "location": "/Installation/Windows/#sql-server-windows-authentication", 
            "text": "Copy  ntmlauth.dll  file to C:\\Windows   For remote installations, make sure that the Windows user that has been granted DB\naccess is the same as the user that is being logged in to the application\nmachine.", 
            "title": "SQL Server Windows Authentication"
        }, 
        {
            "location": "/Installation/end-user-installation/", 
            "text": "Installation and Configuration\n\n\nSystem Requirements\n\n\nThe minimum requirements that are advised for Workstations are as follows:\n\n\n\n\n2-4 GB RAM  \n\n\nDual Core i3/i5 CPU  \n\n\nInternet Explorer 11/Edge OR  \n\n\nChrome (latest stable release) OR  \n\n\nFirefox (latest stable release)  \n\n\n\n\nAdvanced Plugin\n\n\n\n\nClick on Help / Cog -\n Check Installation and then follow the instructions that will guide you through the installation process\n\n\n\n\nSee \nWindows\n\n\nFor silent installation use following command:\n\n\nPaperTrailSetup.exe /S\n\n\n\n\nDesktop Agent\n\n\nDownload and run the installer from \nhttp://downloads.papertrail.co.za\n\n\nSee \nWindows\n and \nLinux\n\n\nOffice Addin\n\n\nDownload and run the installer from \nhttp://downloads.papertrail.co.za\n\n\nSee \nMS Office Add-in\n\n\nWeb Scan\n\n\nWeb scan is distributed as an add-on to the Advanced Plugin:\n\n\n\n\nInstall the Advanced Plugin\n\n\nDownload and Install the Web Scan Add-on from \nDownloads\n\n\nConfigure scan profiles under System -\n Scanning", 
            "title": "End user installation"
        }, 
        {
            "location": "/Installation/end-user-installation/#installation-and-configuration", 
            "text": "", 
            "title": "Installation and Configuration"
        }, 
        {
            "location": "/Installation/end-user-installation/#system-requirements", 
            "text": "The minimum requirements that are advised for Workstations are as follows:   2-4 GB RAM    Dual Core i3/i5 CPU    Internet Explorer 11/Edge OR    Chrome (latest stable release) OR    Firefox (latest stable release)", 
            "title": "System Requirements"
        }, 
        {
            "location": "/Installation/end-user-installation/#advanced-plugin", 
            "text": "Click on Help / Cog -  Check Installation and then follow the instructions that will guide you through the installation process   See  Windows  For silent installation use following command:  PaperTrailSetup.exe /S", 
            "title": "Advanced Plugin"
        }, 
        {
            "location": "/Installation/end-user-installation/#desktop-agent", 
            "text": "Download and run the installer from  http://downloads.papertrail.co.za  See  Windows  and  Linux", 
            "title": "Desktop Agent"
        }, 
        {
            "location": "/Installation/end-user-installation/#office-addin", 
            "text": "Download and run the installer from  http://downloads.papertrail.co.za  See  MS Office Add-in", 
            "title": "Office Addin"
        }, 
        {
            "location": "/Installation/end-user-installation/#web-scan", 
            "text": "Web scan is distributed as an add-on to the Advanced Plugin:   Install the Advanced Plugin  Download and Install the Web Scan Add-on from  Downloads  Configure scan profiles under System -  Scanning", 
            "title": "Web Scan"
        }, 
        {
            "location": "/Installation/macosx/", 
            "text": "PaperTrail Installation for Mac\n\n\n1) Install Postgres, Open Office/Libro office and Java 8 update 45 JDK.\n\n2) Open Postgres and add a new schemer.\n\n3) Install PT with the following command:\n\n/Users/mikegrobbelaar/Desktop/Papertrail_8_7_8_SP1_b5023.sh\n\n4) If Permissions required, use the following command:\n\nsudo chmod 777 /opt/\n to give access to this folder.\n\n5) Once installed, use the below command Permissions required:\n\ncd /opt/Papertrail/\n\n6) Run the following command:\n\nchmod 777 run.sh sudo or ./run.sh\n  \n\n\nStarting PaperTrail for Mac\n\n\n1)  Open up the Terminal via the Launchpad.\n\n2)  Insert the below commands:\n\ncd /opt/Papertrail/ ls ./run.sh", 
            "title": "Macosx"
        }, 
        {
            "location": "/Installation/macosx/#papertrail-installation-for-mac", 
            "text": "1) Install Postgres, Open Office/Libro office and Java 8 update 45 JDK. \n2) Open Postgres and add a new schemer. \n3) Install PT with the following command: /Users/mikegrobbelaar/Desktop/Papertrail_8_7_8_SP1_b5023.sh \n4) If Permissions required, use the following command: sudo chmod 777 /opt/  to give access to this folder. \n5) Once installed, use the below command Permissions required: cd /opt/Papertrail/ \n6) Run the following command: chmod 777 run.sh sudo or ./run.sh", 
            "title": "PaperTrail Installation for Mac"
        }, 
        {
            "location": "/Installation/macosx/#starting-papertrail-for-mac", 
            "text": "1)  Open up the Terminal via the Launchpad. \n2)  Insert the below commands: cd /opt/Papertrail/ ls ./run.sh", 
            "title": "Starting PaperTrail for Mac"
        }, 
        {
            "location": "/Installation/server-installation/", 
            "text": "Installation and Configuration\n\n\nInstallation\n\n\nTo install PaperTrail you will first need to install the prerequisites:\n\n\n\n\nJava 8 SDK\n\n\nPostgreSQL or MS SQL on localhost or remote server\n\n\nLibreOffice\n\n\n\n\nOnce you have the prerequisites : \n\n\n\n\nDownload and run the installer - this can be done silently using the \n-q\n option  \n\n\nAccess the installation wizard at \nhttp://localhost:8080\n  \n\n\nWhen complete, conduct a \nHealth Check\n  \n\n\n\n\nSee \nWindows\n, \n \nLinux\n, \nMacOSX\n \n\n\nUpgrades\n\n\n\n\nRun a full \nbackup\n\nRename the \nPapertrail\n installation folder according to date of upgrade and current version, i.e. \nPapertrail_2013-03-04_r864\n as it allows for simplified rollbacks\n\n\nRun the installer\n\n(If applicable also reconfigure the service under the correct user account)\n\n\nTurn on \nmaintenance mode\n\n\nStart PaperTrail and Conduct a health check\n\n\nTurn off \nmaintenance mode\n\n\n\n\nMore Links\n\n\nService options\n\n\nBackups\n\n\nReplication\n\n\nLDAP / Active Directory", 
            "title": "Server installation"
        }, 
        {
            "location": "/Installation/server-installation/#installation-and-configuration", 
            "text": "", 
            "title": "Installation and Configuration"
        }, 
        {
            "location": "/Installation/server-installation/#installation", 
            "text": "To install PaperTrail you will first need to install the prerequisites:   Java 8 SDK  PostgreSQL or MS SQL on localhost or remote server  LibreOffice   Once you have the prerequisites :    Download and run the installer - this can be done silently using the  -q  option    Access the installation wizard at  http://localhost:8080     When complete, conduct a  Health Check      See  Windows , \n  Linux ,  MacOSX", 
            "title": "Installation"
        }, 
        {
            "location": "/Installation/server-installation/#upgrades", 
            "text": "Run a full  backup \nRename the  Papertrail  installation folder according to date of upgrade and current version, i.e.  Papertrail_2013-03-04_r864  as it allows for simplified rollbacks  Run the installer \n(If applicable also reconfigure the service under the correct user account)  Turn on  maintenance mode  Start PaperTrail and Conduct a health check  Turn off  maintenance mode", 
            "title": "Upgrades"
        }, 
        {
            "location": "/Installation/server-installation/#more-links", 
            "text": "Service options  Backups  Replication  LDAP / Active Directory", 
            "title": "More Links"
        }, 
        {
            "location": "/Installation/service/", 
            "text": "Configuring service settings\n\n\n\n\n\n\n\n\nOS\n\n\nConfiguration Applied in\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\n/opt/Papertrail/run.sh\n\n\n\n\n\n\n\n\nConfiguration Options\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n-Xmx\n\n\nMax memory\n\n\n-Xmx2048M\n\n\n\n\n\n\n-Xms\n\n\nMin memory\n\n\n-Xms2048M", 
            "title": "Service"
        }, 
        {
            "location": "/Installation/service/#configuring-service-settings", 
            "text": "OS  Configuration Applied in      Linux  /opt/Papertrail/run.sh", 
            "title": "Configuring service settings"
        }, 
        {
            "location": "/Installation/service/#configuration-options", 
            "text": "Option  Description  Example      -Xmx  Max memory  -Xmx2048M    -Xms  Min memory  -Xms2048M", 
            "title": "Configuration Options"
        }, 
        {
            "location": "/Installation/solution/", 
            "text": "Deploying Solutions\n\n\n\n\nFirst take a full \nbackup\n if possible.\n\n\nNB: Turn on \nMaintenance Mode\n\n\n\n\nNote : A SolutionPack.zip is used in the examples below, however each solution will have it's own filename e.g.  Travel.zip, HR.zip\n\n\nVia the CLI\n\n\npt deploy SolutionPack.zip\n\n\nVia the GUI\n\n\n\n\nGo to the Admin \n Services \n Tasks \n Bulk Import \n Deploy Pack\n\n\nSelect the \nSolutionPack.zip\n\n\nThen conduct a \nHealth Check\n\n\nFinally turn off \nMaintenance Mode", 
            "title": "Solution"
        }, 
        {
            "location": "/Installation/solution/#deploying-solutions", 
            "text": "First take a full  backup  if possible.  NB: Turn on  Maintenance Mode   Note : A SolutionPack.zip is used in the examples below, however each solution will have it's own filename e.g.  Travel.zip, HR.zip", 
            "title": "Deploying Solutions"
        }, 
        {
            "location": "/Installation/solution/#via-the-cli", 
            "text": "pt deploy SolutionPack.zip", 
            "title": "Via the CLI"
        }, 
        {
            "location": "/Installation/solution/#via-the-gui", 
            "text": "Go to the Admin   Services   Tasks   Bulk Import   Deploy Pack  Select the  SolutionPack.zip  Then conduct a  Health Check  Finally turn off  Maintenance Mode", 
            "title": "Via the GUI"
        }, 
        {
            "location": "/Integration/Database/", 
            "text": "Data Sources\n\n\nA DataSource is a generic abstraction over access and querying databases, it can be linked directly to List, and called via the front-end using \n/data/{datasource name}/\n. \n\n\nThe type of datasource can also be switched (provided the name is retained) to allow different implementations during production / staging etc..\n\n\n\n\nDatabase connections are pooled based on connection string and username.\n\n\nColumn headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d function.\n\n\nAll native SQL commands and functions can be used in the statement.\n\n\nSeparate columns in SELECT statements by commas.\n\n\nIf column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name.\n\n\n\n\n\n\nIt is recommended to use system properties to specify the URL, Username and Password so that they can be externalized and reused across multiple rules. e.g. \n${lob.db.url}\n\n\n\n\nParamaters are passed via \n${param1}\n expressions e.g.\n\n\n SELECT * FROM Invoices WHERE Invoice_No = '${invoice_no}\n\n\n\n\nUsing \nUPDATE\n, \nDELETE\n, \nEXEC\n or \nINSERT\n SQL keywords will use \nPreparedStatement.executeUpdate()\n while all other Keywords will use \nPreparedStatement.executeQuery\n\n\nDirect Access\n\n\nYou can also use direct JDBC or the SQLUtils library to access external databases via a runScript rule - Ensure that you follow the pattern below\n\n\nimport com.egis.datasource.JdbcDataSourceCache\nimport com.egis.kernel.Kernel\nimport com.egis.utils.SQLUtils\nimport javax.sql.DataSource\n\nString url = System.getProperty(\nlob.db.url\n);\nString username = System.getProperty(\nlob.db.username\n);\nString password  = System.getProperty(\nlob.db.password\n);\nDataSource ds = Kernel.get(JdbcDataSourceCache.class).get(url, username, password)\n\nSQLUtils.executeStatement(ds, \nEXEC sp.StoreProc(?,?,?)\n, \nparam1\n, \nparam2\n, \nparam3\n)\n\n\n\n\n\n\nNote that a \nConnection\n or \nDataSource\n is not created directly but delegated to \nJdbcDataSourceCache\n so that connection pooling can occur\n\n\n\n\nDatabase JDBC Configs\n\n\n\n\n\n\n\n\nServer\n\n\nConfiguration\n\n\n\n\n\n\n\n\n\n\nMicrosoft SQL Server\n\n\njdbc:sqlserver://[serverName[\\instanceName][:portNumber]];databaseName=\ndatabaseName\n[;property=value[;property=value]]\n or \njdbc:sqlserver://host;databaseName=test123\n\n\n\n\n\n\nMYSQL\n\n\njdbc:mysql://\ndatabase server\n:\nports\n/\ndatabase names\n\n\n\n\n\n\nPostgreSQL\n\n\njdbc:postgresql://\ndatabase server\n:\nport\n/\ndatabaseName\n\n\n\n\n\n\n\n\nSQL\n\n\nSELECT Statement : To Fetch records from an external database to PaperTrail records.  \n\n\nFormat : \n\n\n   **SELECT \\\nCOLUMNS\\\n\u00a0FROM \\\nTABLENAME\\\n WHERE\n   \\\nDATABASE INDEX\\\n = \\${\\\nPAPERTRAIL INDEX\\\n}**\n\n\n\n\n   SELECT No_ AS Invoice_No, \n     LEFT(CONVERT(date, \nPosting Date\n),10) \n     AS Invoice_Date,\nOrder No_\n \n     AS Internal_Order, \nSell-to Customer No_\n \n     AS Customer_No,\nExternal Document No_\n \n     AS Customer_Order_No, \nShipment Method Code\n \n     AS Delivery_Method \n   FROM \nSAFINTRA JHB$Sales Invoice Header\n \n   WHERE No_ = '${invoice_no}\n\n\n\n\nUPDATE Statement : To Update records from an external database to PaperTrail records.  \n\n\nFormat :\n\n\n**FORMAT**: **UPDATE \\\nTABLE NAME\\\n SET \\\nDATABASE INDEX\\\n =\n'\\\nVALUE\\\n' WHERE \\\nDATABASE INDEX\\\n = \\${\\\nPAPERTRAIL\nINDEX\\\n}**\n\n\n\n\nUPDATE test \nSET Index1 = 'asdf' \nWHERE Invoice_Number = ${Invoice_Number}\n\n\n\n\nRules for SQL statements\n\n\n\n\nColumn headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d\n    function.\n\n\nAll native SQL commands and functions can be used in the statement.\n\n\nSeparate columns in SELECT statements by commas.\n\n\nIf column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name.\n\n\n\n\nEvent\n\n\nWhen to run the SQL Lookup or Update.", 
            "title": "Database"
        }, 
        {
            "location": "/Integration/Database/#data-sources", 
            "text": "A DataSource is a generic abstraction over access and querying databases, it can be linked directly to List, and called via the front-end using  /data/{datasource name}/ .   The type of datasource can also be switched (provided the name is retained) to allow different implementations during production / staging etc..   Database connections are pooled based on connection string and username.  Column headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d function.  All native SQL commands and functions can be used in the statement.  Separate columns in SELECT statements by commas.  If column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name.    It is recommended to use system properties to specify the URL, Username and Password so that they can be externalized and reused across multiple rules. e.g.  ${lob.db.url}   Paramaters are passed via  ${param1}  expressions e.g.   SELECT * FROM Invoices WHERE Invoice_No = '${invoice_no}  Using  UPDATE ,  DELETE ,  EXEC  or  INSERT  SQL keywords will use  PreparedStatement.executeUpdate()  while all other Keywords will use  PreparedStatement.executeQuery", 
            "title": "Data Sources"
        }, 
        {
            "location": "/Integration/Database/#direct-access", 
            "text": "You can also use direct JDBC or the SQLUtils library to access external databases via a runScript rule - Ensure that you follow the pattern below  import com.egis.datasource.JdbcDataSourceCache\nimport com.egis.kernel.Kernel\nimport com.egis.utils.SQLUtils\nimport javax.sql.DataSource\n\nString url = System.getProperty( lob.db.url );\nString username = System.getProperty( lob.db.username );\nString password  = System.getProperty( lob.db.password );\nDataSource ds = Kernel.get(JdbcDataSourceCache.class).get(url, username, password)\n\nSQLUtils.executeStatement(ds,  EXEC sp.StoreProc(?,?,?) ,  param1 ,  param2 ,  param3 )   Note that a  Connection  or  DataSource  is not created directly but delegated to  JdbcDataSourceCache  so that connection pooling can occur", 
            "title": "Direct Access"
        }, 
        {
            "location": "/Integration/Database/#database-jdbc-configs", 
            "text": "Server  Configuration      Microsoft SQL Server  jdbc:sqlserver://[serverName[\\instanceName][:portNumber]];databaseName= databaseName [;property=value[;property=value]]  or  jdbc:sqlserver://host;databaseName=test123    MYSQL  jdbc:mysql:// database server : ports / database names    PostgreSQL  jdbc:postgresql:// database server : port / databaseName", 
            "title": "Database JDBC Configs"
        }, 
        {
            "location": "/Integration/Database/#sql", 
            "text": "SELECT Statement : To Fetch records from an external database to PaperTrail records.    Format :      **SELECT \\ COLUMNS\\ \u00a0FROM \\ TABLENAME\\  WHERE\n   \\ DATABASE INDEX\\  = \\${\\ PAPERTRAIL INDEX\\ }**     SELECT No_ AS Invoice_No, \n     LEFT(CONVERT(date,  Posting Date ),10) \n     AS Invoice_Date, Order No_  \n     AS Internal_Order,  Sell-to Customer No_  \n     AS Customer_No, External Document No_  \n     AS Customer_Order_No,  Shipment Method Code  \n     AS Delivery_Method \n   FROM  SAFINTRA JHB$Sales Invoice Header  \n   WHERE No_ = '${invoice_no}  UPDATE Statement : To Update records from an external database to PaperTrail records.    Format :  **FORMAT**: **UPDATE \\ TABLE NAME\\  SET \\ DATABASE INDEX\\  =\n'\\ VALUE\\ ' WHERE \\ DATABASE INDEX\\  = \\${\\ PAPERTRAIL\nINDEX\\ }**  UPDATE test \nSET Index1 = 'asdf' \nWHERE Invoice_Number = ${Invoice_Number}", 
            "title": "SQL"
        }, 
        {
            "location": "/Integration/Database/#rules-for-sql-statements", 
            "text": "Column headers and index values must match index values in\n    PaperTrail, otherwise give columns aliases by using the \u201cAS\u201d\n    function.  All native SQL commands and functions can be used in the statement.  Separate columns in SELECT statements by commas.  If column names contain spaces, double quotes (\u201c \u201c) should be used\n    to surround the name in order to concatenate the name.", 
            "title": "Rules for SQL statements"
        }, 
        {
            "location": "/Integration/Database/#event", 
            "text": "When to run the SQL Lookup or Update.", 
            "title": "Event"
        }, 
        {
            "location": "/Integration/EasyPDF/", 
            "text": "EasyPDF deployment and configuration\n\n\nSoftware Requirements\n\n\nThe following software will have to be installed on the EasyPDF server : \n\n1.  Windows Server 2008 32/64 bit.\n\n2.  PaperTrail 32 bit (latest release available).\n\n3.  EasyPDF version 6/7 32 bit.\n\n4.  EasyPDF PaperTrail Addon 32 bit (EasyPDF 6 requires Addon r5453\nand\u00a0EasyPDF 7 requires Addon r8738).\n\n5.  Microsoft Office 2010.\n\n6.  Any other native applications that may need to be converted to\nPDF by EasyPDF (i.e. AutoCAD).  \n\n\nNote : UAC should be disabled on the machine before any software is\ninstalled.\n\n\nLocal Installation\n\n\n(Both PaperTrail and EasyPDF running on same host) :\n\n\n\n\nInstall EasyPDF application.\n\n\nInstall PaperTrail release.\n\n\nInstall EasyPDF PaperTrail Addon.\n\n\nSet the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.\n\n\nStart PaperTrail and confirm that installation was successful.\n\n\nAdd the following line to the easypdf.properties file and restart\nPaperTrail thereafter :\n\n\n\n\neasypdf.word.nativeOfficePDF=true\n\n\n\n\n\n\nImport test documents to confirm that all is set up correctly.\n\n\n\n\nRemote Installation\n\n\n(Both PaperTrail and EasyPDF running on separate hosts) :\n\n\nEasyPDF server\n\n\nSame as \nLocal Installation\n\n\nPaperTrail application server\n :\n\n\n1.\u00a0Once PaperTrail is up and running, set the below properties in\nthe papertrail.properties file to enable remote conversions :\n\n\nconversion.filetype.\\*=remote\nconversion.filetype.pdf=pdf\nconversion.remote.host=http://host1:8080\n\n\n\n\n2.\u00a0Import test documents on application server to confirm that all\nis set up correctly.\n\n\nTroubleshooting\n\n\nIf any conversion issue are being experienced, create a .vbs\nfile which can be run to test conversions outside of PaperTrail. The\npaths in the properties are input and output files, and should be\nconfigured accordingly :\n\n\nSet oPrinter = CreateObject(\neasyPDF.Printer.7\n)\nSet oPrintJob = oPrinter.PrintJob\noPrintJob.PrintOut \nC:\\\\test.txt\n, \nC:\\\\output.pdf\n\n\n\n\n\nAnother way to test the conversions is to navigate to\n\nC:\\Users\\Public\\Documents\\BCL Technologies\\easyPDF SDK\n7\\Samples\\Visual C#\\EasyPDFPrinterTest\n and then running\nEasyPDFPrinterTest.exe. This will allow you to select an input document\nto convert and specify the output path of the PDF.\n\n\nFor any more information, the user manual can be accessed \nhere", 
            "title": "EasyPDF"
        }, 
        {
            "location": "/Integration/EasyPDF/#easypdf-deployment-and-configuration", 
            "text": "", 
            "title": "EasyPDF deployment and configuration"
        }, 
        {
            "location": "/Integration/EasyPDF/#software-requirements", 
            "text": "The following software will have to be installed on the EasyPDF server :  \n1.  Windows Server 2008 32/64 bit. \n2.  PaperTrail 32 bit (latest release available). \n3.  EasyPDF version 6/7 32 bit. \n4.  EasyPDF PaperTrail Addon 32 bit (EasyPDF 6 requires Addon r5453\nand\u00a0EasyPDF 7 requires Addon r8738). \n5.  Microsoft Office 2010. \n6.  Any other native applications that may need to be converted to\nPDF by EasyPDF (i.e. AutoCAD).    Note : UAC should be disabled on the machine before any software is\ninstalled.", 
            "title": "Software Requirements"
        }, 
        {
            "location": "/Integration/EasyPDF/#local-installation", 
            "text": "(Both PaperTrail and EasyPDF running on same host) :   Install EasyPDF application.  Install PaperTrail release.  Install EasyPDF PaperTrail Addon.  Set the \u201cBCL easyPDF SDK 7 Loader\u201d and \u201cPapertrail\u201d services to\nrun as the same account which should be granted administrative\npermissions.  Start PaperTrail and confirm that installation was successful.  Add the following line to the easypdf.properties file and restart\nPaperTrail thereafter :   easypdf.word.nativeOfficePDF=true   Import test documents to confirm that all is set up correctly.", 
            "title": "Local Installation"
        }, 
        {
            "location": "/Integration/EasyPDF/#remote-installation", 
            "text": "(Both PaperTrail and EasyPDF running on separate hosts) :  EasyPDF server  Same as  Local Installation  PaperTrail application server  :  1.\u00a0Once PaperTrail is up and running, set the below properties in\nthe papertrail.properties file to enable remote conversions :  conversion.filetype.\\*=remote\nconversion.filetype.pdf=pdf\nconversion.remote.host=http://host1:8080  2.\u00a0Import test documents on application server to confirm that all\nis set up correctly.", 
            "title": "Remote Installation"
        }, 
        {
            "location": "/Integration/EasyPDF/#troubleshooting", 
            "text": "If any conversion issue are being experienced, create a .vbs\nfile which can be run to test conversions outside of PaperTrail. The\npaths in the properties are input and output files, and should be\nconfigured accordingly :  Set oPrinter = CreateObject( easyPDF.Printer.7 )\nSet oPrintJob = oPrinter.PrintJob\noPrintJob.PrintOut  C:\\\\test.txt ,  C:\\\\output.pdf   Another way to test the conversions is to navigate to C:\\Users\\Public\\Documents\\BCL Technologies\\easyPDF SDK\n7\\Samples\\Visual C#\\EasyPDFPrinterTest  and then running\nEasyPDFPrinterTest.exe. This will allow you to select an input document\nto convert and specify the output path of the PDF.  For any more information, the user manual can be accessed  here", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/Integration/Folder Export/", 
            "text": "Document Export\n\n\nCommand Line Process\n\n\nExecute a command line process on a document. To do this, separate the command (script) and the file with: ||.   \n\n\nIf the path is not specified in the PATH environment variable, then specify the path. \nExamples:  \n\n\nautoPrint.vbs||${file}\nC:\\autoPrint.vbs||${file}\n\n\n\n\nNode Replication\n\n\nHTTP Path: The path to the PaperTrail server that will contain the replicated node.  \n\n\nBy default, a server can replicate to any other server. To prevent this behavior, refer to Trusted Servers, page.  \n\n\nTo see information about replication, to replicate documents again, and to clear replication queues, use the Rule.replicate message queue in \nServices\nMessages\n.  \n\n\nAuto Export\n\n\nThe autoExport rule can export documents via 3 different mechanisms:\n\n\nFolder\n\n\nFolder supports multiple folder types:\n\n\n\n\n\n\n\n\nSyntax\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/folder/path\n\n\nLinux Format\n\n\n\n\n\n\nC:\\folder\\path\n\n\nWindows Format\n\n\n\n\n\n\n\\server1\\path\n\n\nWindows Only UNC style path - Note: Mapped drives are not supported\n\n\n\n\n\n\nsmb://server1/path\n\n\nSMB/CIFS format supported on both Linux and Windows - Integrated Authentication is not supported\n\n\n\n\n\n\nftp://server1/path\n\n\nFTP server supported on both Windows + Linux\n\n\n\n\n\n\n\n\nEmail\n\n\nUploads the document via HTTP post to the specified host. If the URL does not contain a path then the following default is used:  \n\n\n/public/file/${_httpNodePath}/${_httpFilename}\n\n\n\n\n${_httpFilename}\n corresponds to  the URL encoded filename of the document  \n\n\n${_httpNodePath}\n corresponds to the URL encoded node path  \n\n\n\n\nThis corresponds to the public API available for importing documents into PaperTrail.\n\n\n\n\nTo specify a different node path you would use:\n\n/public/file/Division/Cabinet/${_httpFilename}\n  \n\n\nTo append indexes you would use:\n\n/public/file/${_httpNodePath}/${_httpFilename}?index1=staticValue1\nindex2=${docId}\n  \n\n\nAnd to append all indexes:\n\n/public/file/${_httpNodePath}/${_httpFilename}?${_httpIndexes}\n  \n\n\n\n\nPaperTrail Server\n\n\n\n\nHTTP Path: The URL of the PaperTrail server to which the documents will be exported. Example: http://headoffice:8080  \n\n\nInclude: We recommend Document Archive or Source.  \n\n\n\n\nExport Format\n\n\n\n\nSource - The original document  \n\n\nPDF - The PDF rendition or the original document  \n\n\nPDF Printout  - A PDF rendition that simulates a print to PDF event  \n\n\nDocument Archive - A ZIP file including all metadata and files  \n\n\nXML - An XML file including all metadata  \n\n\nScripted - Allows the use of script to create FileObject from the a DocumentModel", 
            "title": "Folder Export"
        }, 
        {
            "location": "/Integration/Folder Export/#document-export", 
            "text": "", 
            "title": "Document Export"
        }, 
        {
            "location": "/Integration/Folder Export/#command-line-process", 
            "text": "Execute a command line process on a document. To do this, separate the command (script) and the file with: ||.     If the path is not specified in the PATH environment variable, then specify the path. \nExamples:    autoPrint.vbs||${file}\nC:\\autoPrint.vbs||${file}", 
            "title": "Command Line Process"
        }, 
        {
            "location": "/Integration/Folder Export/#node-replication", 
            "text": "HTTP Path: The path to the PaperTrail server that will contain the replicated node.    By default, a server can replicate to any other server. To prevent this behavior, refer to Trusted Servers, page.    To see information about replication, to replicate documents again, and to clear replication queues, use the Rule.replicate message queue in  Services Messages .", 
            "title": "Node Replication"
        }, 
        {
            "location": "/Integration/Folder Export/#auto-export", 
            "text": "The autoExport rule can export documents via 3 different mechanisms:", 
            "title": "Auto Export"
        }, 
        {
            "location": "/Integration/Folder Export/#folder", 
            "text": "Folder supports multiple folder types:     Syntax  Description      /folder/path  Linux Format    C:\\folder\\path  Windows Format    \\server1\\path  Windows Only UNC style path - Note: Mapped drives are not supported    smb://server1/path  SMB/CIFS format supported on both Linux and Windows - Integrated Authentication is not supported    ftp://server1/path  FTP server supported on both Windows + Linux", 
            "title": "Folder"
        }, 
        {
            "location": "/Integration/Folder Export/#email", 
            "text": "Uploads the document via HTTP post to the specified host. If the URL does not contain a path then the following default is used:    /public/file/${_httpNodePath}/${_httpFilename}   ${_httpFilename}  corresponds to  the URL encoded filename of the document    ${_httpNodePath}  corresponds to the URL encoded node path     This corresponds to the public API available for importing documents into PaperTrail.   To specify a different node path you would use: /public/file/Division/Cabinet/${_httpFilename}     To append indexes you would use: /public/file/${_httpNodePath}/${_httpFilename}?index1=staticValue1 index2=${docId}     And to append all indexes: /public/file/${_httpNodePath}/${_httpFilename}?${_httpIndexes}", 
            "title": "Email"
        }, 
        {
            "location": "/Integration/Folder Export/#papertrail-server", 
            "text": "HTTP Path: The URL of the PaperTrail server to which the documents will be exported. Example: http://headoffice:8080    Include: We recommend Document Archive or Source.", 
            "title": "PaperTrail Server"
        }, 
        {
            "location": "/Integration/Folder Export/#export-format", 
            "text": "Source - The original document    PDF - The PDF rendition or the original document    PDF Printout  - A PDF rendition that simulates a print to PDF event    Document Archive - A ZIP file including all metadata and files    XML - An XML file including all metadata    Scripted - Allows the use of script to create FileObject from the a DocumentModel", 
            "title": "Export Format"
        }, 
        {
            "location": "/Integration/data-sources/", 
            "text": "Data Sources\n\n\nData sources allow for data to be looked up in a centralized fashion. These data sources are always referenced by name so they can differ in production and dev environments - both in parameters and type.\n\n\nSystem properties can also be used for the URL, username and password\nfields:\n\n\n${external.db.username} ${external.db.password} jdbc:mysql://${external.db.host}/`{.ini}\n\n\n\n\nThe properties can then be added to a .properties file in the Papertrail/conf installation folder\n\n\nJDBC\n\n\nConnect to any remote database accessible via a JDBC URL examples of\nwhich are:\n\n\njdbc:mysql://host:3306/{db}{.sql}\n\n\njdbc:sqlserver://host:1443;databaseName={db}{.sql}\n\n\njdbc:postgresql://host:5432/{db}{.sql}\n\n\nParameters can be specified using \n\\${param}\n syntax (they are\nescaped to prevent SQL Injection):\n e.g.\n\n\nSELECT index1 as name, index2 as value FROM external_table WHERE index3 LIKE '${filter}'{.sql}\n\n\nNote the \naliasing\n to \nname\n and \nvalue\n is required to\ncorrectly render in lookup fields/lists.\n\n\nAlthough any parameter can be used, \n\\${filter}\n is reserved for user\nentered input.\n\n\nLocal DB\n\n\nA subtype of JDBC which connects to same database as PaperTrail and can be used\nto query PaperTrail core tables, import and sync tables, or any other\ntable added to this db.\n \u00a0\n\n\nNode Query\n\n\nReturns the result of a PQL query - Commonly used for config nodes.\n \u00a0\n\n\nScripted\n\n\nAllows groovy script to be executed to return any arbritrary list of\ndata.", 
            "title": "Data sources"
        }, 
        {
            "location": "/Integration/data-sources/#data-sources", 
            "text": "Data sources allow for data to be looked up in a centralized fashion. These data sources are always referenced by name so they can differ in production and dev environments - both in parameters and type.  System properties can also be used for the URL, username and password\nfields:  ${external.db.username} ${external.db.password} jdbc:mysql://${external.db.host}/`{.ini}  The properties can then be added to a .properties file in the Papertrail/conf installation folder", 
            "title": "Data Sources"
        }, 
        {
            "location": "/Integration/data-sources/#jdbc", 
            "text": "Connect to any remote database accessible via a JDBC URL examples of\nwhich are:  jdbc:mysql://host:3306/{db}{.sql}  jdbc:sqlserver://host:1443;databaseName={db}{.sql}  jdbc:postgresql://host:5432/{db}{.sql}  Parameters can be specified using  \\${param}  syntax (they are\nescaped to prevent SQL Injection):\n e.g.  SELECT index1 as name, index2 as value FROM external_table WHERE index3 LIKE '${filter}'{.sql}  Note the  aliasing  to  name  and  value  is required to\ncorrectly render in lookup fields/lists.  Although any parameter can be used,  \\${filter}  is reserved for user\nentered input.", 
            "title": "JDBC"
        }, 
        {
            "location": "/Integration/data-sources/#local-db", 
            "text": "A subtype of JDBC which connects to same database as PaperTrail and can be used\nto query PaperTrail core tables, import and sync tables, or any other\ntable added to this db.", 
            "title": "Local DB"
        }, 
        {
            "location": "/Integration/data-sources/#node-query", 
            "text": "Returns the result of a PQL query - Commonly used for config nodes.", 
            "title": "Node Query"
        }, 
        {
            "location": "/Integration/data-sources/#scripted", 
            "text": "Allows groovy script to be executed to return any arbritrary list of\ndata.", 
            "title": "Scripted"
        }, 
        {
            "location": "/Integration/email-watch/", 
            "text": "Email Watch\n\n\nImport emails from a specific email account\n\n\n\n\nAdd a new \nImport Management -\n Email Account\n.  \n\n\nAdd a new \nImport Management -\n Email Import\n.  \n\n\nName\n \u2013 Specify the name of the import - this will be recorded under the history tab.  \n\n\nSelect the \nNode\n to import the document into.  \n\n\nSelect the \nAccount\n created in step 1.  \n\n\nSelect an \nAttachment\n Policy\n\n        *  \nBody Only\n - Import the .html or .txt email body only.\n\n        *  \nAttachments Only\n \u2013 Import attachments only e.g .pdf, .word.\n\n        *  \nSource Only\n - Import the email as a .eml suitable for search an preview.\n\n        *  \nDocument Archive\n \u2013 Used in conjunction with the autoExport rule.\n\n        *  \nThreads\n \u2013 Update the original email with any replies \u2013 The Document.response event can be used to trigger notifications / workflows etc.\n\n\nClick Add.\n\n\n\n\nFilter spam or unwanted messages out\n\n\n\n\nCreate one or more \nEmail Imports\n with a Rule Order of 1.  \n\n\nSpecify unwanted terms under the \nField\n Tab e.g.  \n\n\nCreate all other \nEmail Imports\n with a Rule Order larger than 1.  \n\n\n\n\nImport emails from one email account with multiple aliases\n\n\n\n\nCreate one \nemail account\n.  \n\n\nCreate one or more email import and specify the alias under the \nRules -\n To\n and \nRules -\n CC\n fields.  \n\n\nSelect the \nemail account\n created under step 1.  \n\n\n\n\nMap email fields to document indexes\n\n\n\n\nSelect the \nnode to import the emails to\n.\n\n\nMap the \nfields\n under the \nFields\n tab.\n\n\n\n\nExclude signature images and other attachments from being imported.\n\n\n\n\nUnder the \nrules\n tab, specify a semi-colon separated list of \nunwanted extensions\n under Attachment Exclusion Filter.\ne.g. \n.gif;\n.jpeg;*.png\n\n\n\n\nOR\n\n\n\n\nSpecify only the attachments you want to import under \nAttachment Inclusion Filter\n.\n\n.pdf;\n.doc*\n\n\n\n\nUpdate the original email when a reply is received (threading)\n\n\nTroubleshooting email imports:\n\n\n\n\nEnsure that standard email clients can connect over the POP and IMAP Protocols.\n\n\nCheck \nServices -\n Properties -\n Imports -\n Debug POP/IMAP\n to record the conversion with the POP/IMAP server to if it returns any error messages.", 
            "title": "Email watch"
        }, 
        {
            "location": "/Integration/email-watch/#email-watch", 
            "text": "", 
            "title": "Email Watch"
        }, 
        {
            "location": "/Integration/email-watch/#import-emails-from-a-specific-email-account", 
            "text": "Add a new  Import Management -  Email Account .    Add a new  Import Management -  Email Import .    Name  \u2013 Specify the name of the import - this will be recorded under the history tab.    Select the  Node  to import the document into.    Select the  Account  created in step 1.    Select an  Attachment  Policy \n        *   Body Only  - Import the .html or .txt email body only. \n        *   Attachments Only  \u2013 Import attachments only e.g .pdf, .word. \n        *   Source Only  - Import the email as a .eml suitable for search an preview. \n        *   Document Archive  \u2013 Used in conjunction with the autoExport rule. \n        *   Threads  \u2013 Update the original email with any replies \u2013 The Document.response event can be used to trigger notifications / workflows etc.  Click Add.", 
            "title": "Import emails from a specific email account"
        }, 
        {
            "location": "/Integration/email-watch/#filter-spam-or-unwanted-messages-out", 
            "text": "Create one or more  Email Imports  with a Rule Order of 1.    Specify unwanted terms under the  Field  Tab e.g.    Create all other  Email Imports  with a Rule Order larger than 1.", 
            "title": "Filter spam or unwanted messages out"
        }, 
        {
            "location": "/Integration/email-watch/#import-emails-from-one-email-account-with-multiple-aliases", 
            "text": "Create one  email account .    Create one or more email import and specify the alias under the  Rules -  To  and  Rules -  CC  fields.    Select the  email account  created under step 1.", 
            "title": "Import emails from one email account with multiple aliases"
        }, 
        {
            "location": "/Integration/email-watch/#map-email-fields-to-document-indexes", 
            "text": "Select the  node to import the emails to .  Map the  fields  under the  Fields  tab.", 
            "title": "Map email fields to document indexes"
        }, 
        {
            "location": "/Integration/email-watch/#exclude-signature-images-and-other-attachments-from-being-imported", 
            "text": "Under the  rules  tab, specify a semi-colon separated list of  unwanted extensions  under Attachment Exclusion Filter.\ne.g.  .gif; .jpeg;*.png   OR   Specify only the attachments you want to import under  Attachment Inclusion Filter . .pdf; .doc*   Update the original email when a reply is received (threading)", 
            "title": "Exclude signature images and other attachments from being imported."
        }, 
        {
            "location": "/Integration/email-watch/#troubleshooting-email-imports", 
            "text": "Ensure that standard email clients can connect over the POP and IMAP Protocols.  Check  Services -  Properties -  Imports -  Debug POP/IMAP  to record the conversion with the POP/IMAP server to if it returns any error messages.", 
            "title": "Troubleshooting email imports:"
        }, 
        {
            "location": "/Integration/folder-watch/", 
            "text": "Normal\n\n\nAny file dropped into the Watched Folder will be imported into the specified node.\u00a0\n\n\nCSV\n\n\nPaperTrail will scan the watched folder for any CSV file. The CSV will then be processed and matching files will be imported with their indexes.  \n\n\nFilename : Sample.csv   \n    filename,index1,index2  \n    Sample1.txt,value1,value2  \n    Sample2.txt,value3,value4\n\n\n\n\nFilename : Sample1.txt\nJust some content in Sample 1\n\n\n\n\nFilename : Sample2.txt\nJust some content in Sample 2\n\n\n\n\nIn this example \nSample1.txt\n and \nSample2.txt\n would get imported with the index values (value1,value1) and (value3,value4) respectively\u00a0\n\n\nImport and Sync\n\n\nImport and sync works by creating a temporary staging table to contain meta data coming from external systems - This meta data is dropped off in a XML or CSV file. A mapping file is used to map and reformat the data in these files, the mapping file takes the format of a CSV file imported into PaperTrail with the following columns:  \n\n\n\n\n\n\n\n\nColumn\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nCSV Only - The name of the CSV column\n\n\n\n\n\n\nxpath\n\n\nXML Only - The XPATH to use\n\n\n\n\n\n\nindex\n\n\nThe PaperTrail node index name\n\n\n\n\n\n\nexpression\n\n\nOptional - A Groovy standard expression used to filter or reformat the data  e.g PREFIX-${value} - Add a prefix to the value ${value.find('\\d+')} - Extract only digits using a regular expression.\n\n\n\n\n\n\nformat\n\n\nOptional - The date format of the value in the CSV/XML - PaperTrail will parse the date using this format and then reformat it using the configured system wide format for consistency.\n\n\n\n\n\n\n\n\nFilename : Mapping.csv   \n    name,index,expression,format  \n    index 1,filename,,  \n    index 2,index2,,  \n    index 3,index3,${value}-smith,  \n    date 3,date3,,dd/MM/yyyy\n\n\n\n\nFilename : Data.csv\n    index 1,index 2,date 3,index 3  \n    file1,oncreate,01/01/2015,john\n\n\n\n\nFilename : XML Mapping.csv\n\n    xpath,index,format,expression  \n    /Data/index1/@value,filename,  \n    /Data/index2/text(),index2,  \n    /Data/index3/text(),index3,,${value}-smith  \n    /Data/date3/text(),date3,MM/dd/yyyy\n\n\n\n\nFilename : Data.xml\n \n?xml version=\n1.0\n?\n\n    \nData\n\n        \nindex1 value=\nfile1\n/\n\n        \nindex2\nonupdate\n/index2\n\n        \nindex3\njohn\n/index3\n\n        \ndate3\n01/01/2015\n/date3\n\n    \n/Data\n\n\n\n\n\nStructured\n\n\n\n\nStructured imports import raw textual data and overlay it onto a PDF Template.\u00a0  \n\n\nA Datamap file is used to map blocks of text to fields in the PDF.\u00a0  \n\n\nThe raw data can optionally be processed through an executable (.exe) or a groovy script to format it, so that the datamap can extract the content correctly.\u00a0\n\n\n\n\nUpdate\n\n\nDeprecated in favour of Import and Sync CSV or XML\n\n\nAttach To Form\n\n\nThis will spawn the specified form and attach the document dropped in the watched folder to the form.\u00a0\n\n\nDocument Archive\n\n\n\n\nThis will import a complete document with all versions, indexes, notes, etc.  \n\n\nDocument Archives are created using Bulk Export or an Auto Export rule.", 
            "title": "Folder watch"
        }, 
        {
            "location": "/Integration/folder-watch/#normal", 
            "text": "Any file dropped into the Watched Folder will be imported into the specified node.", 
            "title": "Normal"
        }, 
        {
            "location": "/Integration/folder-watch/#csv", 
            "text": "PaperTrail will scan the watched folder for any CSV file. The CSV will then be processed and matching files will be imported with their indexes.    Filename : Sample.csv   \n    filename,index1,index2  \n    Sample1.txt,value1,value2  \n    Sample2.txt,value3,value4  Filename : Sample1.txt\nJust some content in Sample 1  Filename : Sample2.txt\nJust some content in Sample 2  In this example  Sample1.txt  and  Sample2.txt  would get imported with the index values (value1,value1) and (value3,value4) respectively", 
            "title": "CSV"
        }, 
        {
            "location": "/Integration/folder-watch/#import-and-sync", 
            "text": "Import and sync works by creating a temporary staging table to contain meta data coming from external systems - This meta data is dropped off in a XML or CSV file. A mapping file is used to map and reformat the data in these files, the mapping file takes the format of a CSV file imported into PaperTrail with the following columns:       Column  Description      name  CSV Only - The name of the CSV column    xpath  XML Only - The XPATH to use    index  The PaperTrail node index name    expression  Optional - A Groovy standard expression used to filter or reformat the data  e.g PREFIX-${value} - Add a prefix to the value ${value.find('\\d+')} - Extract only digits using a regular expression.    format  Optional - The date format of the value in the CSV/XML - PaperTrail will parse the date using this format and then reformat it using the configured system wide format for consistency.     Filename : Mapping.csv   \n    name,index,expression,format  \n    index 1,filename,,  \n    index 2,index2,,  \n    index 3,index3,${value}-smith,  \n    date 3,date3,,dd/MM/yyyy  Filename : Data.csv\n    index 1,index 2,date 3,index 3  \n    file1,oncreate,01/01/2015,john  Filename : XML Mapping.csv\n\n    xpath,index,format,expression  \n    /Data/index1/@value,filename,  \n    /Data/index2/text(),index2,  \n    /Data/index3/text(),index3,,${value}-smith  \n    /Data/date3/text(),date3,MM/dd/yyyy  Filename : Data.xml\n  ?xml version= 1.0 ? \n     Data \n         index1 value= file1 / \n         index2 onupdate /index2 \n         index3 john /index3 \n         date3 01/01/2015 /date3 \n     /Data", 
            "title": "Import and Sync"
        }, 
        {
            "location": "/Integration/folder-watch/#structured", 
            "text": "Structured imports import raw textual data and overlay it onto a PDF Template.\u00a0    A Datamap file is used to map blocks of text to fields in the PDF.\u00a0    The raw data can optionally be processed through an executable (.exe) or a groovy script to format it, so that the datamap can extract the content correctly.", 
            "title": "Structured"
        }, 
        {
            "location": "/Integration/folder-watch/#update", 
            "text": "Deprecated in favour of Import and Sync CSV or XML", 
            "title": "Update"
        }, 
        {
            "location": "/Integration/folder-watch/#attach-to-form", 
            "text": "This will spawn the specified form and attach the document dropped in the watched folder to the form.", 
            "title": "Attach To Form"
        }, 
        {
            "location": "/Integration/folder-watch/#document-archive", 
            "text": "This will import a complete document with all versions, indexes, notes, etc.    Document Archives are created using Bulk Export or an Auto Export rule.", 
            "title": "Document Archive"
        }, 
        {
            "location": "/Integration/ldap-ad/", 
            "text": "LDAP Configuration\n\n\nOpenLDAP\n\n\nConfigure User format = uid=${user},o=Directory\n\n\nNote: Active directory will return less results and attributes when using port 3268 vs 389\n\n\nMultiple LDAP Servers\n\n\nConfigured by addition a set of properties per domain:\n\n\nldap.extra.**_domain1-corp.local_**.host=  \nldap.extra.domain1-corp.local.user=  \nldap.extra.domain1-corp.local.pass=  \nldap.extra._**domain2-corp.local**_.host=  \nldap.extra.domain2-corp.local.user=  \nldap.extra.domain2-corp.local.pass=  \n\n\n\n\nSynchronizing With LDAP / Active Directory\n\n\n\n\nCheck LDAP -\n Auto Create users  to create new users from LDAP when they login  \n\n\nCheck LDAP -\n Auto Sync Groups \u00a0to synchronize group membership, this will sync on user create and on the interval specified under Authentication -\n Group Sync Interval\n\n\n\n\nYou can also specify a datasource under \nAuthentication -\n Group Sync Provider\n e.g. ds:groups \n\n\nSELECT memberOf as groups FROM '@ldap/objectClass=user\nSAMAccountName=${filter}\n\n\nTroubleshooting\n\n\n\n\n\n\nGet the LDAP queries that PaperTrail is executing by increasing the log level: \u00a0\ncom.egis.utils.ldap\n\u00a0in\u00a0\n 8.8.4 or \ncom.egis.security.ldap\n\u00a0in 8.8.4+\n\n\n\n\n\n\nDEBUG to see the results of queries  \n\n\n\n\nTRACE to see the actual query being run and authentication requests  \n\n\nUse an off the shelf tool to check what options work when connecting:\n\n\n\n\nGUI:  \n\n\nhttp://jxplorer.org/\n\n\nhttp://www.ldapsoft.com/ldapbrowser/ldapadmintool.html\n  \n\n\nCLI:  \n\n\nldapsearch -h 172.16.237.131 -D \nadministrator@corp.egis-software.com\n -w password -b \ncn=users,dc=corp,dc=egis-software,dc=com\n -s sub \n(\n(objectClass=user)(mail=*))\n '*'\n\n\n\n\nUse tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the protocol level.  \n\n\n\n\nAdjust the LDAP query string in \nServices -\n Properties -\n LDAP\n as appropriate", 
            "title": "Ldap ad"
        }, 
        {
            "location": "/Integration/ldap-ad/#ldap-configuration", 
            "text": "", 
            "title": "LDAP Configuration"
        }, 
        {
            "location": "/Integration/ldap-ad/#openldap", 
            "text": "Configure User format = uid=${user},o=Directory  Note: Active directory will return less results and attributes when using port 3268 vs 389", 
            "title": "OpenLDAP"
        }, 
        {
            "location": "/Integration/ldap-ad/#multiple-ldap-servers", 
            "text": "Configured by addition a set of properties per domain:  ldap.extra.**_domain1-corp.local_**.host=  \nldap.extra.domain1-corp.local.user=  \nldap.extra.domain1-corp.local.pass=  \nldap.extra._**domain2-corp.local**_.host=  \nldap.extra.domain2-corp.local.user=  \nldap.extra.domain2-corp.local.pass=", 
            "title": "Multiple LDAP Servers"
        }, 
        {
            "location": "/Integration/ldap-ad/#synchronizing-with-ldap-active-directory", 
            "text": "Check LDAP -  Auto Create users  to create new users from LDAP when they login    Check LDAP -  Auto Sync Groups \u00a0to synchronize group membership, this will sync on user create and on the interval specified under Authentication -  Group Sync Interval   You can also specify a datasource under  Authentication -  Group Sync Provider  e.g. ds:groups   SELECT memberOf as groups FROM '@ldap/objectClass=user SAMAccountName=${filter}", 
            "title": "Synchronizing With LDAP / Active Directory"
        }, 
        {
            "location": "/Integration/ldap-ad/#troubleshooting", 
            "text": "Get the LDAP queries that PaperTrail is executing by increasing the log level: \u00a0 com.egis.utils.ldap \u00a0in\u00a0  8.8.4 or  com.egis.security.ldap \u00a0in 8.8.4+    DEBUG to see the results of queries     TRACE to see the actual query being run and authentication requests    Use an off the shelf tool to check what options work when connecting:   GUI:    http://jxplorer.org/  http://www.ldapsoft.com/ldapbrowser/ldapadmintool.html     CLI:    ldapsearch -h 172.16.237.131 -D  administrator@corp.egis-software.com  -w password -b  cn=users,dc=corp,dc=egis-software,dc=com  -s sub  ( (objectClass=user)(mail=*))  '*'  Use tcpdump\u00a0or wireshark to capture ldap\u00a0queries and results at the protocol level.     Adjust the LDAP query string in  Services -  Properties -  LDAP  as appropriate", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/Reference/Cold Standby Failover Procedure/", 
            "text": "Cold Standby Failover Procedure\n\n\n\n\nEnsure the master server is actually down and not immediately recoverable.  \n\n\nKill the master server i.e. ensure that the primary server does not continue to operate (service requests) as it could cause missing data or conflicts down the line - If necessary, physically remove network cables.  \n\n\nRun the \nC:\\failover.bat\n script which automates the following actions:\n\n        -  Stop PaperTrail.\n\n        -  Delete the existing properties file: \nC:\\Program Files\\Papertrail\\conf\\papertrail.properties\n.\n\n        - Copy and rename the \nC:\\failover.properties\n to: \nC:\\Program Files\\Papertrail\\conf\\papertrail.properties\n.\n\n        - Start PaperTrail.\n\n        - Repair the indexes.  \n\n\n\n\nFailover Verification Procedure\n\n\n\n\nConfirm new documents can be imported.  \n\n\nConfirm old documents can be viewed.  \n\n\nConfirm documents are searchable by running an index repair.  \n\n\nConfirm all file and email imports functioning (if applicable).  \n\n\nConfirm file store integrity by running file store repair.  \n\n\n\n\nClient / Imports Failover Procedure\n\n\nNote :  \nDO NOT COMPLETE THE FOLLOWING STEPS DURING DR TEST.\n\n\n\n\nMove or change the IP / hostname from the master to the slave so that users can connect to PT as normal.  \n\n\nRename the server for all file and email imports.\ne.g. \nUPDATE import_setting SET serverId = \nid of slave server\n\n\nRestart email and import file services.", 
            "title": "Cold Standby Failover Procedure"
        }, 
        {
            "location": "/Reference/Cold Standby Failover Procedure/#cold-standby-failover-procedure", 
            "text": "Ensure the master server is actually down and not immediately recoverable.    Kill the master server i.e. ensure that the primary server does not continue to operate (service requests) as it could cause missing data or conflicts down the line - If necessary, physically remove network cables.    Run the  C:\\failover.bat  script which automates the following actions: \n        -  Stop PaperTrail. \n        -  Delete the existing properties file:  C:\\Program Files\\Papertrail\\conf\\papertrail.properties . \n        - Copy and rename the  C:\\failover.properties  to:  C:\\Program Files\\Papertrail\\conf\\papertrail.properties . \n        - Start PaperTrail. \n        - Repair the indexes.", 
            "title": "Cold Standby Failover Procedure"
        }, 
        {
            "location": "/Reference/Cold Standby Failover Procedure/#failover-verification-procedure", 
            "text": "Confirm new documents can be imported.    Confirm old documents can be viewed.    Confirm documents are searchable by running an index repair.    Confirm all file and email imports functioning (if applicable).    Confirm file store integrity by running file store repair.", 
            "title": "Failover Verification Procedure"
        }, 
        {
            "location": "/Reference/Cold Standby Failover Procedure/#client-imports-failover-procedure", 
            "text": "Note :   DO NOT COMPLETE THE FOLLOWING STEPS DURING DR TEST.   Move or change the IP / hostname from the master to the slave so that users can connect to PT as normal.    Rename the server for all file and email imports.\ne.g.  UPDATE import_setting SET serverId =  id of slave server  Restart email and import file services.", 
            "title": "Client / Imports Failover Procedure"
        }, 
        {
            "location": "/Reference/Document Properties/", 
            "text": "Document Properties\n\n\nDocument properties are available to use in:\n\n\n\n\nNode rule filters\n\n\nWorkflow filters\n\n\nStandard Expressions e.g. the body field in a sendEmail rule\n\n\n\n\n\n\n\n\n\n\nDocument Property\n\n\nGroovy Description\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndocId\n\n\nString\n\n\nThe document unique identifier. Formatted as a PaperTrail document ID.\n\n\n\n\n\n\ncreatedDate\n\n\nDate\n\n\nThe date that the document was created.\n\n\n\n\n\n\nfilename\n\n\nString\n\n\nThe filename of the document including the extension.\n\n\n\n\n\n\nlastModified\n\n\nDate\n\n\nThe date that the document was last modified. Can be empty.\n\n\n\n\n\n\ncreatedBy\n\n\nString\n\n\nThe name of the user who created the document.\n\n\n\n\n\n\ndispatchedBy\n\n\nString\n\n\nFor asynchronous rules, the user whose action triggered the event. Refer also to sessionUser.\n\n\n\n\n\n\next\n\n\nString\n\n\nA document extension suffix supported by PaperTrail. Does not contain the leading dot.\n\n\n\n\n\n\nip\n\n\nString\n\n\nThe IP address of the user who performed the action that triggered the event.\n\n\n\n\n\n\nname\n\n\nString\n\n\nThe filename of the document excluding the extension.\n\n\n\n\n\n\nsize\n\n\nLong\n\n\nThe size in bytes. Use this for a numeric comparison, for example: size \n 100000.\n\n\n\n\n\n\nsessionUser\n\n\nString\n\n\nFor synchronous rules, the current user. For asynchronous rules, System. Refer also to dispatchedBy.\n\n\n\n\n\n\nstatus\n\n\nString\n\n\nThe status of the document. Possible values are Filed, Current, Diarized, and Out.\n\n\n\n\n\n\nsizeFormatted\n\n\nString\n\n\nFormatted as bytes. For example, 1 KB, 5 MB, 1 GB\ufffcinstead of an integer such as 14328490234..\n\n\n\n\n\n\nvisibility\n\n\nString\n\n\nSets who is permitted to see the document. Valid values are Public, Private and Confidential..\n\n\n\n\n\n\ntitle\n\n\nString\n\n\nTitle.\n\n\n\n\n\n\nsubject\n\n\nString\n\n\nSubject.\n\n\n\n\n\n\nversion\n\n\nString\n\n\nA document version number, for example, 2.1. Can be empty.\n\n\n\n\n\n\n???\n\n\nString\n\n\nAn index that is added under Node Management \n Node \n Index.\n\n\n\n\n\n\n\n\nWritable Properties\n\n\nSome document properties are also editable, but most are read only.\n\n\n\n\nfilename\n\n\nvisibility\n\n\ntitle\n\n\nsubject\n\n\n{custom_index}\n\n\n\n\nto set a writeable property you can use a script:  \n\n\ndoc.metadata().set(\"title\", \"a new title\")\n\n\nOr a updateIndex rule  \n\n\ntitle=new title\n  \n\n\nor using the HTTP API:  \n\n\ncurl -x POST http://host/public/indexes/\ndocId\n/?title= a new title\n  \n\n\nDocument properties can also be updated via other mechanism for updating indexes including:\n\n\n\n\nImport and Sync\n\n\n.TXT files\n\n\n.XML indexes\n\n\n\n\nSpecial properties\n\n\nDue to the large number of places, indexes/properties can be updated. It being the single most common point of integration between systems, there are a few special properties that trigger actions. They are prefixed with \n_\n and not to be confused with normal properties that relate to metadata only.  \n\n\n\n\n\n\n\n\nDocument Property\n\n\nGroovy Description\n\n\n\n\n\n\n\n\n\n\n_audit\n\n\nCreates a new audit history event on the document\n\n\n\n\n\n\n_status\n\n\n_status=Filed will remove all current users of a document _status=Archive will archive the document\n\n\n\n\n\n\n_event\n\n\nDispatches a new Document event\n\n\n\n\n\n\nuser\n\n\nAllocates an user to the document\n\n\n\n\n\n\nowner\n\n\nAssigns ownership to the user\n\n\n\n\n\n\nnode\n\n\nMoves the document to the specified node\n\n\n\n\n\n\nvisibility\n\n\nChanges the visibility of the document\n\n\n\n\n\n\n\n\nArithmetic Operations\n\n\nMost properties and all custom index values are in String format. In order to use arithmetic in filters etc, you need to first convert them to a Number type. e.g.\n\n\ncustomNumberIndex.asInt() \n 10000\n  \n\n\nSee \nGroovy GDK String.asType()\n\n\nRounding\n\n\nIndexName=${(Double.valueOf(IndexName) * 1.14).round(2)}\n\n\nDates\n\n\nFor information about how to format dates, refer to \u00a0\nSimpleDateFormat", 
            "title": "Document Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#document-properties", 
            "text": "Document properties are available to use in:   Node rule filters  Workflow filters  Standard Expressions e.g. the body field in a sendEmail rule      Document Property  Groovy Description  Description      docId  String  The document unique identifier. Formatted as a PaperTrail document ID.    createdDate  Date  The date that the document was created.    filename  String  The filename of the document including the extension.    lastModified  Date  The date that the document was last modified. Can be empty.    createdBy  String  The name of the user who created the document.    dispatchedBy  String  For asynchronous rules, the user whose action triggered the event. Refer also to sessionUser.    ext  String  A document extension suffix supported by PaperTrail. Does not contain the leading dot.    ip  String  The IP address of the user who performed the action that triggered the event.    name  String  The filename of the document excluding the extension.    size  Long  The size in bytes. Use this for a numeric comparison, for example: size   100000.    sessionUser  String  For synchronous rules, the current user. For asynchronous rules, System. Refer also to dispatchedBy.    status  String  The status of the document. Possible values are Filed, Current, Diarized, and Out.    sizeFormatted  String  Formatted as bytes. For example, 1 KB, 5 MB, 1 GB\ufffcinstead of an integer such as 14328490234..    visibility  String  Sets who is permitted to see the document. Valid values are Public, Private and Confidential..    title  String  Title.    subject  String  Subject.    version  String  A document version number, for example, 2.1. Can be empty.    ???  String  An index that is added under Node Management   Node   Index.", 
            "title": "Document Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#writable-properties", 
            "text": "Some document properties are also editable, but most are read only.   filename  visibility  title  subject  {custom_index}   to set a writeable property you can use a script:    doc.metadata().set(\"title\", \"a new title\")  Or a updateIndex rule    title=new title     or using the HTTP API:    curl -x POST http://host/public/indexes/ docId /?title= a new title     Document properties can also be updated via other mechanism for updating indexes including:   Import and Sync  .TXT files  .XML indexes", 
            "title": "Writable Properties"
        }, 
        {
            "location": "/Reference/Document Properties/#special-properties", 
            "text": "Due to the large number of places, indexes/properties can be updated. It being the single most common point of integration between systems, there are a few special properties that trigger actions. They are prefixed with  _  and not to be confused with normal properties that relate to metadata only.       Document Property  Groovy Description      _audit  Creates a new audit history event on the document    _status  _status=Filed will remove all current users of a document _status=Archive will archive the document    _event  Dispatches a new Document event    user  Allocates an user to the document    owner  Assigns ownership to the user    node  Moves the document to the specified node    visibility  Changes the visibility of the document", 
            "title": "Special properties"
        }, 
        {
            "location": "/Reference/Document Properties/#arithmetic-operations", 
            "text": "Most properties and all custom index values are in String format. In order to use arithmetic in filters etc, you need to first convert them to a Number type. e.g.  customNumberIndex.asInt()   10000     See  Groovy GDK String.asType()", 
            "title": "Arithmetic Operations"
        }, 
        {
            "location": "/Reference/Document Properties/#rounding", 
            "text": "IndexName=${(Double.valueOf(IndexName) * 1.14).round(2)}", 
            "title": "Rounding"
        }, 
        {
            "location": "/Reference/Document Properties/#dates", 
            "text": "For information about how to format dates, refer to \u00a0 SimpleDateFormat", 
            "title": "Dates"
        }, 
        {
            "location": "/Reference/Encryption/", 
            "text": "Encryption\n\n\nEncrypting files at rest (AES)\n\n\n\n\nAdd the following to the \npapertrail.properties\n file before starting PaperTrail for the first time \n\n\nstorage.encrypt=true\n\n\n\n\nOR\n\n\n\n\nAdd a new file store under \nServices -\n File Store\n.  \n\n\nSelect Software under the \nEncrypt\n option.  \n\n\nEnter a \nKey size\n e.g. 128, 196, 256.  \n\n\nEnter the \nunique key name\n for this store.  \n\n\nThe \nencryption key will be automatically generated\n on restart and stored obfuscated in the database.  \n\n\n\n\nEncrypting files in transit (SSL)\n\n\n\n\nCreate a \nJava keystore\n.  \n\n\nCopy the keystore to \nconf/keystore\n.\n\n\nUnder \nServices -\n Properties -\n Front End (SSL)\n.\n\n\nCheck \nEnable\n.\n\n\nEnter the \nkeystore password\n.\n\n\nOptional: Check \nForce SSL\n to ensure all traffic from HTTP is redirected to HTTPS.  \n\n\nClick \nSave\n.  \n\n\nRestart \nPaperTrail\n.", 
            "title": "Encryption"
        }, 
        {
            "location": "/Reference/Encryption/#encryption", 
            "text": "", 
            "title": "Encryption"
        }, 
        {
            "location": "/Reference/Encryption/#encrypting-files-at-rest-aes", 
            "text": "Add the following to the  papertrail.properties  file before starting PaperTrail for the first time   storage.encrypt=true   OR   Add a new file store under  Services -  File Store .    Select Software under the  Encrypt  option.    Enter a  Key size  e.g. 128, 196, 256.    Enter the  unique key name  for this store.    The  encryption key will be automatically generated  on restart and stored obfuscated in the database.", 
            "title": "Encrypting files at rest (AES)"
        }, 
        {
            "location": "/Reference/Encryption/#encrypting-files-in-transit-ssl", 
            "text": "Create a  Java keystore .    Copy the keystore to  conf/keystore .  Under  Services -  Properties -  Front End (SSL) .  Check  Enable .  Enter the  keystore password .  Optional: Check  Force SSL  to ensure all traffic from HTTP is redirected to HTTPS.    Click  Save .    Restart  PaperTrail .", 
            "title": "Encrypting files in transit (SSL)"
        }, 
        {
            "location": "/Reference/High Availability & Clustering/", 
            "text": "High Availability\n\n\nReplication (Master \u2013 Master)\n\n\n\n\nUse the \nNew Replication Installation\n option in the wizard on both the master and slave.  \n\n\nCheck \nMaster\n on the primary node.  \n\n\nThe master node is responsible for \ntriggering timeouts\n, running \nscheduled rules\n etc.  \n\n\n\n\nReplicated installation.\n\n\nTo convert a standalone installation to a replicated installation, follow these steps:  \n\n\n\n\nStop PaperTrail and create a \ndatabase backup\n.  \n\n\nConfigure the following properties in \npapertrail.properties\n on the master\n\n\n\n\nindex.upstream=http://slave:8080\nreplication.upstream=http://slave:8080  \nfile.replication.upstream=http://host:8080  \nreplication.master=true  \nreplication.increment=2  \nreplication.offset=1  \ndb.identity.override=true # for sql server replication only  \n\n\n\n\n\n\nConfigure these properties on the slave:  \n\n\n\n\nindex.upstream=http://master:8080  \nreplication.upstream=http:// master:8080\nfile.replication.upstream=http:// master:8080  \nreplication.master=false  \nreplication.increment=2  \nreplication.offset=2  \ndb.identity.override=true # for sql server replication only  \n\n\n\n\n\n\nStart up the master\n\n\nWait a few minutes and start up the slave\n\n\n\n\nClustering\n\n\n\n\nSelect the \nNew Clustering\n installation from the wizard:  \n\n\n\n\nOR\n\n\n\n\nAdd these properties to the \npapertrail.properties\n  \n\n\n\n\nindex.upstream=http://slave:8080   \ncluster.enable=true   \nstorage.upstream=http://slave:8080  \n\n\n\n\n\n\nRestart PaperTrail.\n\n\n\n\n\n\nNote: Clustering requires a low latency (\n1ms), reliable (preferably dual path redundant network) network connection to function correctly.  Replication can be used in WAN environments.", 
            "title": "High Availability & Clustering"
        }, 
        {
            "location": "/Reference/High Availability & Clustering/#high-availability", 
            "text": "", 
            "title": "High Availability"
        }, 
        {
            "location": "/Reference/High Availability & Clustering/#replication-master-master", 
            "text": "Use the  New Replication Installation  option in the wizard on both the master and slave.    Check  Master  on the primary node.    The master node is responsible for  triggering timeouts , running  scheduled rules  etc.", 
            "title": "Replication (Master \u2013 Master)"
        }, 
        {
            "location": "/Reference/High Availability & Clustering/#replicated-installation", 
            "text": "To convert a standalone installation to a replicated installation, follow these steps:     Stop PaperTrail and create a  database backup .    Configure the following properties in  papertrail.properties  on the master   index.upstream=http://slave:8080\nreplication.upstream=http://slave:8080  \nfile.replication.upstream=http://host:8080  \nreplication.master=true  \nreplication.increment=2  \nreplication.offset=1  \ndb.identity.override=true # for sql server replication only     Configure these properties on the slave:     index.upstream=http://master:8080  \nreplication.upstream=http:// master:8080\nfile.replication.upstream=http:// master:8080  \nreplication.master=false  \nreplication.increment=2  \nreplication.offset=2  \ndb.identity.override=true # for sql server replication only     Start up the master  Wait a few minutes and start up the slave", 
            "title": "Replicated installation."
        }, 
        {
            "location": "/Reference/High Availability & Clustering/#clustering", 
            "text": "Select the  New Clustering  installation from the wizard:     OR   Add these properties to the  papertrail.properties      index.upstream=http://slave:8080   \ncluster.enable=true   \nstorage.upstream=http://slave:8080     Restart PaperTrail.    Note: Clustering requires a low latency ( 1ms), reliable (preferably dual path redundant network) network connection to function correctly.  Replication can be used in WAN environments.", 
            "title": "Clustering"
        }, 
        {
            "location": "/Reference/Linking/", 
            "text": "Manipulating the linking critera\n\n\nLinking Documents On Numbers Only\n\n\nSpecific node links can be added to only search the digit portion of the index value using IF ELSE logic, i.e.\n\n\nDestination Node\n/recursive=true\nDestination Index\n=${if (\nSource Index\n == null) \n else \nSource Index\n.find(\n\\\\d+\n)}\n\n\n\n\nwhere \n\n\n\n\nDestination Node: \nRoot node/child node/\n\n\nrecursive=true: when searching over multiple child nodes\n\n\nDestination Index: Index field you want to link to\n\n\nSource Index: Index field on node you're linking from\n\n\n${if (\n == null): If source index has no Value\n\n\n\"\" else \n.find(\"\\d+\")}: Find matching Numeric Value\n\n\n\n\nLinking on Numeric with custom field Order_No\n\n\neg. Order_No = 12345\n\n\nDestination Node\n/recursive=true\nOrder_No=${if (Order_No == null) \"\" else Order_No.find(\"\\\\d+\")}\n\n\nLinking on Alphanumeric with custom field Order_No\n\n\neg. Order_No = PO12345\n\n\n\"\" else Order_No.find(\"\\\\w+\")\n\n\nLinking on Alphanumeric, Space, Numeric with custom field Order_No\n\n\neg. Order_No = PO 12345\n\n\nRegex Examples eg.\n\n\n1)  \n\\w+\n    : All alphanumeric values\n\n\n2)  \n\\W\n     : A non-word character: [^\\w]\n\n\n3)  \n\\d+\n    : All numeric values\n\n\n4)  \n\\D\n     : A non-digit: [^0-9]\n\n\n5)  \n\\s\n     : A whitespace character", 
            "title": "Linking"
        }, 
        {
            "location": "/Reference/Linking/#manipulating-the-linking-critera", 
            "text": "", 
            "title": "Manipulating the linking critera"
        }, 
        {
            "location": "/Reference/Linking/#linking-documents-on-numbers-only", 
            "text": "Specific node links can be added to only search the digit portion of the index value using IF ELSE logic, i.e.  Destination Node /recursive=true Destination Index =${if ( Source Index  == null)   else  Source Index .find( \\\\d+ )}  where    Destination Node:  Root node/child node/  recursive=true: when searching over multiple child nodes  Destination Index: Index field you want to link to  Source Index: Index field on node you're linking from  ${if (  == null): If source index has no Value  \"\" else  .find(\"\\d+\")}: Find matching Numeric Value", 
            "title": "Linking Documents On Numbers Only"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-numeric-with-custom-field-order_no", 
            "text": "eg. Order_No = 12345  Destination Node /recursive=true Order_No=${if (Order_No == null) \"\" else Order_No.find(\"\\\\d+\")}", 
            "title": "Linking on Numeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-alphanumeric-with-custom-field-order_no", 
            "text": "eg. Order_No = PO12345  \"\" else Order_No.find(\"\\\\w+\")", 
            "title": "Linking on Alphanumeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#linking-on-alphanumeric-space-numeric-with-custom-field-order_no", 
            "text": "eg. Order_No = PO 12345", 
            "title": "Linking on Alphanumeric, Space, Numeric with custom field Order_No"
        }, 
        {
            "location": "/Reference/Linking/#regex-examples-eg", 
            "text": "1)   \\w+     : All alphanumeric values  2)   \\W      : A non-word character: [^\\w]  3)   \\d+     : All numeric values  4)   \\D      : A non-digit: [^0-9]  5)   \\s      : A whitespace character", 
            "title": "Regex Examples eg."
        }, 
        {
            "location": "/Reference/Logging/", 
            "text": "Logging\n\n\nUpdating the log settings\n\n\n\n\nAll log settings are stored in the \nconf/logback.groovy\n file.  \n\n\nThe \nAdmin -\n Services -\n Logging\n  page will make changes to this file if the After Restart option is selected.\n\n\n\n\nLoggers\n\n\n\n\n\n\n\n\nLogger\n\n\nDescription\n\n\nVerbosity\n\n\n\n\n\n\n\n\n\n\ncom.egis.index\n\n\nInfo about updates to the search index\n\n\n10+ lines per doc update\n\n\n\n\n\n\ncom.egis.index.query\n\n\nSQL and Search index queries\n\n\n10+ lines per search\n\n\n\n\n\n\ncom.egis.storage\n\n\nFile operations\n\n\n1+ lines per file read/write\n\n\n\n\n\n\ncom.egis.kernel.messaging\n\n\nAll messages \u2013 useful to see what is occurring as a whole\n\n\n10+ lines per transaction and/or event\n\n\n\n\n\n\ncom.egis.web.WebErrorHandlerImpl\n\n\nShow full validation and access denied errors\n\n\nFull stack on validation or access denied exception\n\n\n\n\n\n\ncom.egis.conversion\n\n\nIssues with converting files to PDF and Flash\n\n\nUp to 20+ lines per conversion\n\n\n\n\n\n\ncom.egis.web.ActionResource\n\n\nAll user actions initiated via the UI with params, very verbose\n\n\n1 long log line for every user action\n\n\n\n\n\n\ncom.egis.DocumentLogger\n\n\nAll actions on documents, somewhat verbose\n\n\nUp to 5 - 10 lines per document operation\n\n\n\n\n\n\ncom.egis.requests\n\n\nAll HTTP requests, very verbose\n\n\n1 line per HTTP request\n\n\n\n\n\n\ncom.egis.workflow\n\n\nAll Workflow rules fired up until a stationary rule is reached (Human Task, Unassigned Task)\n\n\n10+ lines depending on amount of rules\n\n\n\n\n\n\ncom.egis.allocation.QueueService\n\n\nqueue fill events\n\n\n\n\n\n\n\n\n\n\nLog file Retention\n\n\n\n\nTo configure the number of days to keep Papertrail logs, locate and edit the following document: \nPaperTrail/conf/logback.groovy\n\n\nThe example below keeps the logs for a period of 14 days:\n\n\n\n\nappender(\nFILE\n, RollingFileAppender) { \nfile = \nlogs/server.log\n     \nappend = true     \nrollingPolicy(TimeBasedRollingPolicy) {  \nmaxHistory = 14  \nFileNamePattern = \nlogs/server-%d{yyyy-MM-dd}.log\n\n}}\n\n\n\n\n\n\nLocate the section \nmaxHistory = 14\n. Please modify the 14 with the amount of days to keep logs.  \n\n\nRestart PaperTrail for the settings to take effect.  \n\n\n\n\nLogging to Syslog Host\n\n\nimport com.egis.utils.apm.*; \nimport org.productivity.java.syslog4j.impl.net.tcp.*; \nappender(\nSYSLOG\n, SyslogAppender) {  \nlayout(LogglyLayout) {        \napiToken = \nXXXXX\n     \n}     \nsyslogConfig(TCPNetSyslogConfig) { \nhost =  \nlogs-01.loggly.com\n\nport = 514\nident = \npapertrail\n     \n} \n}\n\n\n\n\nFiltering logs\n\n\ne.g  To filter out all sql SELECT statemetns with \ndb.debug=true\n: \n\n\nimport ch.qos.logback.core.filter.*\nimport ch.qos.logback.classic.boolex.*\nimport static ch.qos.logback.core.spi.FilterReply.*\n\nappender(\nSTDOUT\n, ConsoleAppender) {\n    filter(EvaluatorFilter) {\n      evaluator(GEventEvaluator) {\n        expression = 'e.message.toLowerCase().startsWith(\nselect\n)'\n      }\n      onMismatch = NEUTRAL\n      onMatch = DENY \n    }\n\n    // encoder(PatternLayoutEncoder)...\n\n}\n\n\n\n\n\n\nLogging to a GELF Host\n\n\nReplace //gelf in the logback.groovy with:\n\n\nappender(\nGELF\n, GelfAppender) { \nhost = \n${gelfHost}\n\nfilter(ThresholdFilter) { \nlevel = ${gelfLevel} \n} \nport = 12201 \nadditionalFields =  '{\nthreadName\n: \nthreadName\n, \nexception\n: \nexception\n, \nloggerName\n: \nloggerName\n, \nip\n:\nip\n,\nuser\n:\nuser\n,\ndoc\n:\ndoc\n}' \n}\n\n\n\n\nThe following properties will automate this setup: \ngelf.host\n and \ngelf.level", 
            "title": "Logging"
        }, 
        {
            "location": "/Reference/Logging/#logging", 
            "text": "", 
            "title": "Logging"
        }, 
        {
            "location": "/Reference/Logging/#updating-the-log-settings", 
            "text": "All log settings are stored in the  conf/logback.groovy  file.    The  Admin -  Services -  Logging   page will make changes to this file if the After Restart option is selected.", 
            "title": "Updating the log settings"
        }, 
        {
            "location": "/Reference/Logging/#loggers", 
            "text": "Logger  Description  Verbosity      com.egis.index  Info about updates to the search index  10+ lines per doc update    com.egis.index.query  SQL and Search index queries  10+ lines per search    com.egis.storage  File operations  1+ lines per file read/write    com.egis.kernel.messaging  All messages \u2013 useful to see what is occurring as a whole  10+ lines per transaction and/or event    com.egis.web.WebErrorHandlerImpl  Show full validation and access denied errors  Full stack on validation or access denied exception    com.egis.conversion  Issues with converting files to PDF and Flash  Up to 20+ lines per conversion    com.egis.web.ActionResource  All user actions initiated via the UI with params, very verbose  1 long log line for every user action    com.egis.DocumentLogger  All actions on documents, somewhat verbose  Up to 5 - 10 lines per document operation    com.egis.requests  All HTTP requests, very verbose  1 line per HTTP request    com.egis.workflow  All Workflow rules fired up until a stationary rule is reached (Human Task, Unassigned Task)  10+ lines depending on amount of rules    com.egis.allocation.QueueService  queue fill events", 
            "title": "Loggers"
        }, 
        {
            "location": "/Reference/Logging/#log-file-retention", 
            "text": "To configure the number of days to keep Papertrail logs, locate and edit the following document:  PaperTrail/conf/logback.groovy  The example below keeps the logs for a period of 14 days:   appender( FILE , RollingFileAppender) { \nfile =  logs/server.log      \nappend = true     \nrollingPolicy(TimeBasedRollingPolicy) {  \nmaxHistory = 14  \nFileNamePattern =  logs/server-%d{yyyy-MM-dd}.log \n}}   Locate the section  maxHistory = 14 . Please modify the 14 with the amount of days to keep logs.    Restart PaperTrail for the settings to take effect.", 
            "title": "Log file Retention"
        }, 
        {
            "location": "/Reference/Logging/#logging-to-syslog-host", 
            "text": "import com.egis.utils.apm.*; \nimport org.productivity.java.syslog4j.impl.net.tcp.*; \nappender( SYSLOG , SyslogAppender) {  \nlayout(LogglyLayout) {        \napiToken =  XXXXX      \n}     \nsyslogConfig(TCPNetSyslogConfig) { \nhost =   logs-01.loggly.com \nport = 514\nident =  papertrail      \n} \n}", 
            "title": "Logging to Syslog Host"
        }, 
        {
            "location": "/Reference/Logging/#filtering-logs", 
            "text": "e.g  To filter out all sql SELECT statemetns with  db.debug=true :   import ch.qos.logback.core.filter.*\nimport ch.qos.logback.classic.boolex.*\nimport static ch.qos.logback.core.spi.FilterReply.*\n\nappender( STDOUT , ConsoleAppender) {\n    filter(EvaluatorFilter) {\n      evaluator(GEventEvaluator) {\n        expression = 'e.message.toLowerCase().startsWith( select )'\n      }\n      onMismatch = NEUTRAL\n      onMatch = DENY \n    }\n\n    // encoder(PatternLayoutEncoder)...\n\n}", 
            "title": "Filtering logs"
        }, 
        {
            "location": "/Reference/Logging/#logging-to-a-gelf-host", 
            "text": "Replace //gelf in the logback.groovy with:  appender( GELF , GelfAppender) { \nhost =  ${gelfHost} \nfilter(ThresholdFilter) { \nlevel = ${gelfLevel} \n} \nport = 12201 \nadditionalFields =  '{ threadName :  threadName ,  exception :  exception ,  loggerName :  loggerName ,  ip : ip , user : user , doc : doc }' \n}  The following properties will automate this setup:  gelf.host  and  gelf.level", 
            "title": "Logging to a GELF Host"
        }, 
        {
            "location": "/Reference/System-Nodes/", 
            "text": "The \nSystem\n node has a number of nodes that have special behaviours:\n\n\nSystem/images\n\n\nPaperTrail logo's are located here and can be updated with custom image's if required.  \n\n\n\n\nNote the contents of this folder are publicly accessible and should not be used to store sensitive images\n\n\n\n\nSystem/templates\n\n\nContains all the base document templates and also the email templates used for notification bodies:\n\n\nEmail templates can used layouts by appending the layout name to the filename e.g. \naccount-signup_notitication.html\n will use the the \nSystem/templates/layouts/notification.html\n layout to create pretty HTML emails.\n\n\nSystem/scripts\n\n\nContains groovy files that are run on startup - Often used for creating services\n\n\nSystem/jars\n\n\nContains precompiled JAR files that are loaded at runtime, functionally equivalent tot he local \ndeploy\n filesystem directory but offers simplified management especially due to backup/restores and solution deployment\n\n\nSystem/plugins\n\n\nAny \n.js\n file within subdirectories will be loaded into the browser to allow customization of the UI. Supported folders are:\n\n\n\n\nwebapps\n\n\nadmin\n\n\neSign\n\n\nAdminApp\n\n\nPortalApp\n\n\nBulkCapture\n\n\n\n\ne.g. \nSystem/plugins/PortalApp/plugins.js\n will be loaded for the modern portal UI", 
            "title": "System Nodes"
        }, 
        {
            "location": "/Reference/System-Nodes/#systemimages", 
            "text": "PaperTrail logo's are located here and can be updated with custom image's if required.     Note the contents of this folder are publicly accessible and should not be used to store sensitive images", 
            "title": "System/images"
        }, 
        {
            "location": "/Reference/System-Nodes/#systemtemplates", 
            "text": "Contains all the base document templates and also the email templates used for notification bodies:  Email templates can used layouts by appending the layout name to the filename e.g.  account-signup_notitication.html  will use the the  System/templates/layouts/notification.html  layout to create pretty HTML emails.", 
            "title": "System/templates"
        }, 
        {
            "location": "/Reference/System-Nodes/#systemscripts", 
            "text": "Contains groovy files that are run on startup - Often used for creating services", 
            "title": "System/scripts"
        }, 
        {
            "location": "/Reference/System-Nodes/#systemjars", 
            "text": "Contains precompiled JAR files that are loaded at runtime, functionally equivalent tot he local  deploy  filesystem directory but offers simplified management especially due to backup/restores and solution deployment", 
            "title": "System/jars"
        }, 
        {
            "location": "/Reference/System-Nodes/#systemplugins", 
            "text": "Any  .js  file within subdirectories will be loaded into the browser to allow customization of the UI. Supported folders are:   webapps  admin  eSign  AdminApp  PortalApp  BulkCapture   e.g.  System/plugins/PortalApp/plugins.js  will be loaded for the modern portal UI", 
            "title": "System/plugins"
        }, 
        {
            "location": "/Reference/health/", 
            "text": "Health checks should be conduced after every new installation, upgrade, custom deployment or major configuration change\n\n\nConducting Health Checks\n\n\n\n\nMonitor the log files under  (\nlogs\n) for any startup or migration errors\n\n\nCheck system health using \n/health\n and ensuring everything is \nGood\n\n\nLog into all applications used (\n/web/webapps\n, \n/web/admin\n,\n/web/portal\n, \n/web/capture\n etc..) and ensure they load and function correctly", 
            "title": "Health"
        }, 
        {
            "location": "/Reference/health/#conducting-health-checks", 
            "text": "Monitor the log files under  ( logs ) for any startup or migration errors  Check system health using  /health  and ensuring everything is  Good  Log into all applications used ( /web/webapps ,  /web/admin , /web/portal ,  /web/capture  etc..) and ensure they load and function correctly", 
            "title": "Conducting Health Checks"
        }, 
        {
            "location": "/Reference/licensing/", 
            "text": "Licensing Details\n\n\nFull\n\n\nFull\n - Full functionality including import via Desktop Agent and Office Add-In.\n\n\nFull v2\n - The same permissions as Full, but defaults to using the new UI\n\n\nCustom\n - Full but with a different starting page e.g. a custom tool or static form.\n\n\nSub Licenses\n\n\nSub licenses are not added directly. \nEach full license provides the ability to create 2 or more sub type users. \ne.g. 1 full user license allows 5 share users to be created.\n\n\nShare (5)\n - Cannot login, can only access PaperTrail from email links Sent via Share, Share Node and eSign actions.\n\n\nView (2)\n - View only functions, no import capabilities.\n\n\nDesktop (2)\n - Import only via Desktop Agent or PaperTrail Office Add-In, no login via front-end.\n\n\nPortal (External)\n\n\nPortal licenses are designed to allow external companies and users to login to a very minimal view to view documents that are logically owned by them e.g. Viewing invoices made out to you.\n\n\nPortal Users have the same permissions as \nView\n and are automatically redirected to the Classic Portal view:  http://\n:8080/web/portal/portal.html.\n\n\nScan\n\n\nSame as \nFull\n but also allows the use of the Web Scan client.\n\n\nDeprecated\n\n\nMobile\n Removed in 8.8.0, all users except desktop can use mobile.", 
            "title": "Licensing"
        }, 
        {
            "location": "/Reference/licensing/#licensing-details", 
            "text": "", 
            "title": "Licensing Details"
        }, 
        {
            "location": "/Reference/licensing/#full", 
            "text": "Full  - Full functionality including import via Desktop Agent and Office Add-In.  Full v2  - The same permissions as Full, but defaults to using the new UI  Custom  - Full but with a different starting page e.g. a custom tool or static form.", 
            "title": "Full"
        }, 
        {
            "location": "/Reference/licensing/#sub-licenses", 
            "text": "Sub licenses are not added directly. \nEach full license provides the ability to create 2 or more sub type users. \ne.g. 1 full user license allows 5 share users to be created.  Share (5)  - Cannot login, can only access PaperTrail from email links Sent via Share, Share Node and eSign actions.  View (2)  - View only functions, no import capabilities.  Desktop (2)  - Import only via Desktop Agent or PaperTrail Office Add-In, no login via front-end.", 
            "title": "Sub Licenses"
        }, 
        {
            "location": "/Reference/licensing/#portal-external", 
            "text": "Portal licenses are designed to allow external companies and users to login to a very minimal view to view documents that are logically owned by them e.g. Viewing invoices made out to you.  Portal Users have the same permissions as  View  and are automatically redirected to the Classic Portal view:  http:// :8080/web/portal/portal.html.", 
            "title": "Portal (External)"
        }, 
        {
            "location": "/Reference/licensing/#scan", 
            "text": "Same as  Full  but also allows the use of the Web Scan client.", 
            "title": "Scan"
        }, 
        {
            "location": "/Reference/licensing/#deprecated", 
            "text": "Mobile  Removed in 8.8.0, all users except desktop can use mobile.", 
            "title": "Deprecated"
        }, 
        {
            "location": "/Reference/linking_syntax/", 
            "text": "PaperTrail Document Linking Syntax\n\n\nRetrieving a document by docId\n\n\nGET: /public/file/100/test.doc\n{.sql}\n\n\ne.x : http://host:8080/public/file/100/test.doc\n \u00a0\n\n\nRetrieving a document by path\n\n\nGET: /public/file/Division/cabinet/test.doc/dummy.doc\n{.sql}\n\n\ne.x : http://host:8080/public/file/Division/cabinet/test.doc.\n\n\nNote : A dummy filename must be appended to the path e.g. dummy.doc\n \u00a0\n\n\nRetrieving an attachment\n\n\nGET: /public/file/100/test.doc?path=attachments/att01.doc\n{.sql}\n\n\ne.x : http://host:8080/public/file/Division/cabinet/test.doc?path=attachments/att01.doc\n \u00a0\n\n\nRetrieving a PDF for a document\n\n\nGET: /public/file/100/test.pdf?path=pdf\n{.sql}\n\n\ne.x : http://host:8080/public/file/100/test.pdf?path=pdf\n \u00a0\n\n\nRetrieving a version of a document\n\n\nGET: /public/file/100/test.doc?path=versions/0.2/source\n{.sql}\n\n\ne.x : http://host:8080/public/file/Division/cabinet/test.doc?path=versions/0.2/source\n \u00a0\n\n\nRetrieving a document via a query\n\n\nGET: /public/file/invoiceNo=AB123/test.doc\n{.sql}\n\n\ne.x : http://host:8080/public/file/Division/cabinet/test.doc?path=versions/0.2/source\n \u00a0\n\n\nQuery Syntax\n\n\n\n\n\n\n\n\nProperties\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nDivision/Cabinet/*\n\n\nReturns all documents directly under Division/Cabinet.\n\n\n\n\n\n\nDivision/Cabinet?recursive=true\n\n\nReturns all document under Division/Cabinet including documents in sub nodes.\n\n\n\n\n\n\nDivision/Cabinet/test.doc\n\n\nReturns the document where the filename is test.doc in Division/Cabinet.\n\n\n\n\n\n\nDivision/Cabinet/filename=test.doc\n\n\nEquivalent to the above query Division/Cabinet/filename=*.doc and Returns all documents that end in .doc\n\n\n\n\n\n\nDivision/Cabinet Division/Cabinet/filename*=test\n\n\nReturns all documents that begin with test in Division/Cabinet.\n\n\n\n\n\n\nDivision/Cabinet/test.doc?index1=value1\n\n\nReturns the document where the filename is test.doc and index1=value1 in Division/Cabinet\n\n\n\n\n\n\nDivision/Cabinet/index=value\n\n\nReturns all documents where index1=value1 in Division/Cabinet.\n\n\n\n\n\n\nDivision/Cabinet/index1=value1 \n index2=value2\n\n\nReturns all documents where index1=value1 and index2=value2 in Division/Cabinet.\n\n\n\n\n\n\n\n\nNote : index1=value2 : Returns all documents where index1=value1 in all nodes and folders Equals. \n\n\nEquals = Not Equals != Contains *=* Starts With *= Ends With =* Between \n=\n Bigger Than (Number) \n= Smaller Than (Number) \n= After (Date) \n= Before (Date) \n= Is Empty !=!", 
            "title": "Linking syntax"
        }, 
        {
            "location": "/Reference/linking_syntax/#papertrail-document-linking-syntax", 
            "text": "", 
            "title": "PaperTrail Document Linking Syntax"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-document-by-docid", 
            "text": "GET: /public/file/100/test.doc {.sql}  e.x : http://host:8080/public/file/100/test.doc", 
            "title": "Retrieving a document by docId"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-document-by-path", 
            "text": "GET: /public/file/Division/cabinet/test.doc/dummy.doc {.sql}  e.x : http://host:8080/public/file/Division/cabinet/test.doc.  Note : A dummy filename must be appended to the path e.g. dummy.doc", 
            "title": "Retrieving a document by path"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-an-attachment", 
            "text": "GET: /public/file/100/test.doc?path=attachments/att01.doc {.sql}  e.x : http://host:8080/public/file/Division/cabinet/test.doc?path=attachments/att01.doc", 
            "title": "Retrieving an attachment"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-pdf-for-a-document", 
            "text": "GET: /public/file/100/test.pdf?path=pdf {.sql}  e.x : http://host:8080/public/file/100/test.pdf?path=pdf", 
            "title": "Retrieving a PDF for a document"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-version-of-a-document", 
            "text": "GET: /public/file/100/test.doc?path=versions/0.2/source {.sql}  e.x : http://host:8080/public/file/Division/cabinet/test.doc?path=versions/0.2/source", 
            "title": "Retrieving a version of a document"
        }, 
        {
            "location": "/Reference/linking_syntax/#retrieving-a-document-via-a-query", 
            "text": "GET: /public/file/invoiceNo=AB123/test.doc {.sql}  e.x : http://host:8080/public/file/Division/cabinet/test.doc?path=versions/0.2/source", 
            "title": "Retrieving a document via a query"
        }, 
        {
            "location": "/Reference/linking_syntax/#query-syntax", 
            "text": "Properties  Description      Division/Cabinet/*  Returns all documents directly under Division/Cabinet.    Division/Cabinet?recursive=true  Returns all document under Division/Cabinet including documents in sub nodes.    Division/Cabinet/test.doc  Returns the document where the filename is test.doc in Division/Cabinet.    Division/Cabinet/filename=test.doc  Equivalent to the above query Division/Cabinet/filename=*.doc and Returns all documents that end in .doc    Division/Cabinet Division/Cabinet/filename*=test  Returns all documents that begin with test in Division/Cabinet.    Division/Cabinet/test.doc?index1=value1  Returns the document where the filename is test.doc and index1=value1 in Division/Cabinet    Division/Cabinet/index=value  Returns all documents where index1=value1 in Division/Cabinet.    Division/Cabinet/index1=value1   index2=value2  Returns all documents where index1=value1 and index2=value2 in Division/Cabinet.     Note : index1=value2 : Returns all documents where index1=value1 in all nodes and folders Equals.   Equals = Not Equals != Contains *=* Starts With *= Ends With =* Between  =  Bigger Than (Number)  = Smaller Than (Number)  = After (Date)  = Before (Date)  = Is Empty !=!", 
            "title": "Query Syntax"
        }, 
        {
            "location": "/Reference/maintenance/", 
            "text": "Maintenance Mode\n\n\n\n\nSetting maintenance mode is essential when conducting upgrades as it will ensure that no new documents/emails are imported after the upgrade is completed, as when a rollback is necessary, the imported documents will no longer be available in watched mailbox. \n\n\n\n\nTurning On Maintenance Mode:\n\n\n\n\nConfigure papertrail to start in maintenance mode by adding the following line to the \nconf/papertrail.properties\n\n\n\n\nmode=Maintenance\n\n\n\n\n\n\nRestart PaperTrail\n\n\n\n\nTurning Off Maintenance\n\n\n\n\nRemove or comment out the \nmode\n property in \nconf/papertrail.properties\n\n\nRestart PaperTrail", 
            "title": "Maintenance"
        }, 
        {
            "location": "/Reference/maintenance/#maintenance-mode", 
            "text": "Setting maintenance mode is essential when conducting upgrades as it will ensure that no new documents/emails are imported after the upgrade is completed, as when a rollback is necessary, the imported documents will no longer be available in watched mailbox.", 
            "title": "Maintenance Mode"
        }, 
        {
            "location": "/Reference/maintenance/#turning-on-maintenance-mode", 
            "text": "Configure papertrail to start in maintenance mode by adding the following line to the  conf/papertrail.properties   mode=Maintenance   Restart PaperTrail", 
            "title": "Turning On Maintenance Mode:"
        }, 
        {
            "location": "/Reference/maintenance/#turning-off-maintenance", 
            "text": "Remove or comment out the  mode  property in  conf/papertrail.properties  Restart PaperTrail", 
            "title": "Turning Off Maintenance"
        }, 
        {
            "location": "/Reference/pql/", 
            "text": "PQL\n\n\nPQL is an SQL-like language that can be used for querying and filtering data in PaperTrail. It can be used in the following places:  \n\n\n\n\n\n\nAnywhere where a query expression is used e.g. Advanced Search Reports, Queues, Scheduled Rules, Document linking etc.\n\n\n\n\n\n\nAs an alternative to groovy based expressions on node rule filters\ne.g. instead of:\n\nfilename == 'filename \n a == 'b'\n\nUse:\n\n\n\n\n\n\nWHERE filename = 'filename' AND a = 'b'\n\n\n\n\nPQL filters are fully case-insensitive and null safe so instead of: \nindex1 != null \n index1.toLowerCase() == 'abc'\n\nUse:\n\nWHERE index1 = 'abc'\n\n\nSyntax\n\n\nThe \nSELECT\n clause MUST contain exactly one of the following:\n\n\n\n\n\n\nA comma-separated list of one or more column names (node or document index names).  \n\n\n\n\nYou can use aliases to rename returned columns, e.g. column AS alias.  \n\n\nIf an explicit column list is provided: Only the columns listed will be returned and only in the order supplied.  \n\n\nNote : All standard indexes and any custom indexes will be returned in the default order  \n\n\nNote : Only custom indexes will be returned \n\n\n\n\n\n\n\n\nOne or more calls to aggregate functions.\n\n\n\n\nAggregate functions produce a single row output from multiple rows in a group.\n\n\n\n\n\n\n\n\nColumn Expressions\n\n\nGroovy expressions can be used to format data returned e.g. \n\n\nSELECT '${name[0]}' as Initial FROM Clients\n\n\n\n\nMultiple columns can also be referenced:\n\n\nSELECT '${LastName}, ${FirstName}' as FullName FROM Clients\n\n\n\n\nAs well as arithmetic on Number and Double indexes:\n\n\nSELECT '${total + vat}' as GrandTotal FROM 'Sales'\n\n\n\n\nWildcards\n\n\nPlain SQL wildcard works as expected - e.g. \nSELECT * FROM 'Sun/Clients'\n selects all the standard and custom indexes \nfrom Sun/Clients node. There's also doublewildcard syntax:\n\n\nSELECT ** FROM 'Sun/Clients'\n\n\n\n\n\n\nthis selects only custom indexes. \n\n\n\n\nFROM Clause\n\n\nThe FROM clause identifies which Virtual Table (Node) the query will be run against, as described in the previous section.\n\n\nThe FROM clause MUST contain the full path of a node, and MUST be single quoted if there are any spaces .e.g\n\n\nFROM parent/division\n\n\nFROM 'parent/sub folder/folder'\n\n\nWHERE\n\n\nThis clause identifies the constraints that rows MUST satisfy to be considered a result for the query.\n\n\nAll column names MUST be valid \u201cqueryName\u201d or their aliased values for properties that are defined as \u201cqueryable\u201d in the Object-Type(s) whose Virtual Tables are listed in the FROM clause.\n\n\nProperties are defined to not support a \u201cnull\u201d value, therefore the \n MUST be interpreted as testing the not set or set state of the specified property.\n\n\nComparisons permitted in the WHERE clause.\n\n\nPQL supports the following predicates:\n\n\n\n\n= (equals)  \n\n\n> (bigger than, after)  \n\n\n (smaller than, before)  \n\n\n\n\n\n\nNote: Bigger than / Less than and end equal to (\n=, \n=) are not supported\n\n\n\n\nDate values can be relative e.g.:\n\n\nSELECT docId FROM queryTests2 WHERE date1 \n '+7d'\n\n\n\n\n\n\ncontains\n\n\nnot contains\n\n\nstartsWith\n\n\nnot startsWith\n\n\nendWith\n\n\n\n\nnot endsWith\nBETWEEN and NOT BETWEEN predicates to compare on ranges\ne.g. column BETWEEN a AND b, is equivalent to column \n= a AND column \n= b \n\n\n\n\n\n\nIN  \n\n\n\n\nLIKE   \n\n\nIS NULL  \n\n\nIS NOT NULL  \n\n\nall_empty  \n\n\ne.g. a filter that matches when all 4 indexes are populated\nWHERE not all_empty (invoice_no,total,date,approved)\n\n\n\n\n\n\nnot all_empty  \n\n\nbefore, after   \n\n\n\n\nWHERE createdDate BEFORE '2015-01-01'\n\n\n\n\nWHERE Expressions\n\n\nExpressions can also be on both the left and and right side of WHERE clauses. e.g.\n\n\nSELECT name FROM Customers WHERE '${name[0]}' = 'A'\n\n\n\n\nOR\n\n\nSELECT number1 FROM queryTests2 WHERE 99 \n ${number1 + pqldouble1}\n\n\n\n\nORDER BY\n\n\n\n\nThis clause MUST use a single column to order by.\n\n\nAll column names referenced in this clause MUST be valid \u201cqueryName\u201d or alias (either for an aggregate function result or a column).\n\n\nOnly columns in the SELECT clause MAY be in the ORDER BY clause.\n\n\nORDER BY docId DESC\n doesn't currently work - use \nORDER BY createdDate DESC\n instead \n\n\n\n\nLIMIT N\n\n\nLIMIT N construct is supported - e.g. \n\n\nSELECT * FROM 'MyBank/KYC' WHERE loan_id=5 ORDER BY createdDate DESC LIMIT 1\n\n\n\n\nwill select last doc from MyBank/KYC node with given filter.\n\n\nGROUP BY\n\n\nThis clause specifies one or many columns to group by.\n\n\nSupported functions:\n\n\n\n\nCOUNT(column\n, \nCOUNT(*)\n - returns a number of entries in a group. COUNT(column) skips null values.\n\n\nAVG(column)\n - returns an average value of a column in a group.\n\n\nMIN(column)\n, \nMAX(column)\n - return a minimal or maximal value of a certain column in a group.\n\n\nSUM(column)\n - returns a sum of a column in a group.\n\n\n\n\nColumn references can also include groovy expressions e.g. \n\n\nSELECT sum(${time/60}) FROM Time  GROUP BY createdBy\n\n\n\n\nHAVING\n\n\nHaving is used to filter on values that have been grouped e.g.\n\n\nSELECT text1, SUM(number1) FROM queryTests2 GROUP BY text1 HAVING SUM(number1) \n 10\n\n\n\n\nOR\n\n\nSELECT text1, SUM(\\${number1 * 10}) AS totals FROM queryTests2 GROUP BY text1 HAVING totals \n 1000\n\n\n\n\nEscaping\n\n\nRepositories MUST support the escaping of characters using a backslash \n\\\n in the query statement.  The backslash character \n\\\n will be used to escape characters within quoted strings in the query as follows:\n\n\n\n\n\\\u2019 will represent a single-quote(\u2018) character\n\n\n\\ \\ will represent a backslash \n\\\n character\n\n\nWithin a LIKE string, \n\\%\n and \n\\_\n will represent the literal characters % and _, respectively.\n\n\nAll other instances of a \\ are errors.\n\n\n\n\nVirtual Data Sources\n\n\nFROM '@{VirtualDataSource}\n\n\n@WorkflowHistory\n\n\nThe workflow history virtual data source will return details about the unassigned and human tasks of a one or more documents e.g. \n\n\nSELECT * FROM '@WorkflowHistory' WHERE docId = 1\n\n\n\n\nWill return the following special columns:\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nallocation\n\n\nThe final user allocated\n\n\n\n\n\n\ncreatedBy\n\n\nWho the allocation was created by. This is not the creator of the document.\n\n\n\n\n\n\nposition\n\n\nThe workflow label of the task\n\n\n\n\n\n\nduration\n\n\nThe duration of the task e.g. 12 hours\n\n\n\n\n\n\nbusinessDuration\n\n\nThe duration of the task while in business hours e.g. 2 hours\n\n\n\n\n\n\nstart\n\n\nThe start date of the task\n\n\n\n\n\n\nend\n\n\nThe end date of the task\n\n\n\n\n\n\ndurationMillis\n\n\nThe duration of the task in milliseconds\n\n\n\n\n\n\n\n\nAny standard and custom indexes can also be merged into the results by adding them into the column list.\nAny standard search criteria can also be used\n\n\n@Activity\n\n\nReturns: \n\n\n\n\nDocument creations \n\n\nNew Notes \n\n\nAudits of configurable type = defaulting to Check In, Forward, Delete \n\n\n\n\nSELECT * FROM @Activity WHERE Node = 'Finance' AND user = 'X' \n\n\n\n\nequivalent to: \n\n\nSELECT * FROM @Activity/Finance WHERE user = 'X' \n\n\n\n\ndate\n is used for searching on the activity date (not the date of the document)\n\n\nSELECT * FROM @Activity WHERE date = '-7d' \n\n\n\n\n@QueueHistory", 
            "title": "Pql"
        }, 
        {
            "location": "/Reference/pql/#pql", 
            "text": "PQL is an SQL-like language that can be used for querying and filtering data in PaperTrail. It can be used in the following places:      Anywhere where a query expression is used e.g. Advanced Search Reports, Queues, Scheduled Rules, Document linking etc.    As an alternative to groovy based expressions on node rule filters\ne.g. instead of: filename == 'filename   a == 'b' \nUse:    WHERE filename = 'filename' AND a = 'b'  PQL filters are fully case-insensitive and null safe so instead of:  index1 != null   index1.toLowerCase() == 'abc' \nUse: WHERE index1 = 'abc'", 
            "title": "PQL"
        }, 
        {
            "location": "/Reference/pql/#syntax", 
            "text": "The  SELECT  clause MUST contain exactly one of the following:    A comma-separated list of one or more column names (node or document index names).     You can use aliases to rename returned columns, e.g. column AS alias.    If an explicit column list is provided: Only the columns listed will be returned and only in the order supplied.    Note : All standard indexes and any custom indexes will be returned in the default order    Note : Only custom indexes will be returned      One or more calls to aggregate functions.   Aggregate functions produce a single row output from multiple rows in a group.", 
            "title": "Syntax"
        }, 
        {
            "location": "/Reference/pql/#column-expressions", 
            "text": "Groovy expressions can be used to format data returned e.g.   SELECT '${name[0]}' as Initial FROM Clients  Multiple columns can also be referenced:  SELECT '${LastName}, ${FirstName}' as FullName FROM Clients  As well as arithmetic on Number and Double indexes:  SELECT '${total + vat}' as GrandTotal FROM 'Sales'", 
            "title": "Column Expressions"
        }, 
        {
            "location": "/Reference/pql/#wildcards", 
            "text": "Plain SQL wildcard works as expected - e.g.  SELECT * FROM 'Sun/Clients'  selects all the standard and custom indexes \nfrom Sun/Clients node. There's also doublewildcard syntax:  SELECT ** FROM 'Sun/Clients'   this selects only custom indexes.", 
            "title": "Wildcards"
        }, 
        {
            "location": "/Reference/pql/#from-clause", 
            "text": "The FROM clause identifies which Virtual Table (Node) the query will be run against, as described in the previous section.  The FROM clause MUST contain the full path of a node, and MUST be single quoted if there are any spaces .e.g  FROM parent/division  FROM 'parent/sub folder/folder'", 
            "title": "FROM Clause"
        }, 
        {
            "location": "/Reference/pql/#where", 
            "text": "This clause identifies the constraints that rows MUST satisfy to be considered a result for the query.  All column names MUST be valid \u201cqueryName\u201d or their aliased values for properties that are defined as \u201cqueryable\u201d in the Object-Type(s) whose Virtual Tables are listed in the FROM clause.  Properties are defined to not support a \u201cnull\u201d value, therefore the   MUST be interpreted as testing the not set or set state of the specified property.  Comparisons permitted in the WHERE clause.  PQL supports the following predicates:   = (equals)    > (bigger than, after)     (smaller than, before)      Note: Bigger than / Less than and end equal to ( =,  =) are not supported   Date values can be relative e.g.:  SELECT docId FROM queryTests2 WHERE date1   '+7d'   contains  not contains  startsWith  not startsWith  endWith   not endsWith\nBETWEEN and NOT BETWEEN predicates to compare on ranges\ne.g. column BETWEEN a AND b, is equivalent to column  = a AND column  = b     IN     LIKE     IS NULL    IS NOT NULL    all_empty    e.g. a filter that matches when all 4 indexes are populated\nWHERE not all_empty (invoice_no,total,date,approved)    not all_empty    before, after      WHERE createdDate BEFORE '2015-01-01'", 
            "title": "WHERE"
        }, 
        {
            "location": "/Reference/pql/#where-expressions", 
            "text": "Expressions can also be on both the left and and right side of WHERE clauses. e.g.  SELECT name FROM Customers WHERE '${name[0]}' = 'A'  OR  SELECT number1 FROM queryTests2 WHERE 99   ${number1 + pqldouble1}", 
            "title": "WHERE Expressions"
        }, 
        {
            "location": "/Reference/pql/#order-by", 
            "text": "This clause MUST use a single column to order by.  All column names referenced in this clause MUST be valid \u201cqueryName\u201d or alias (either for an aggregate function result or a column).  Only columns in the SELECT clause MAY be in the ORDER BY clause.  ORDER BY docId DESC  doesn't currently work - use  ORDER BY createdDate DESC  instead", 
            "title": "ORDER BY"
        }, 
        {
            "location": "/Reference/pql/#limit-n", 
            "text": "LIMIT N construct is supported - e.g.   SELECT * FROM 'MyBank/KYC' WHERE loan_id=5 ORDER BY createdDate DESC LIMIT 1  will select last doc from MyBank/KYC node with given filter.", 
            "title": "LIMIT N"
        }, 
        {
            "location": "/Reference/pql/#group-by", 
            "text": "This clause specifies one or many columns to group by.  Supported functions:   COUNT(column ,  COUNT(*)  - returns a number of entries in a group. COUNT(column) skips null values.  AVG(column)  - returns an average value of a column in a group.  MIN(column) ,  MAX(column)  - return a minimal or maximal value of a certain column in a group.  SUM(column)  - returns a sum of a column in a group.   Column references can also include groovy expressions e.g.   SELECT sum(${time/60}) FROM Time  GROUP BY createdBy", 
            "title": "GROUP BY"
        }, 
        {
            "location": "/Reference/pql/#having", 
            "text": "Having is used to filter on values that have been grouped e.g.  SELECT text1, SUM(number1) FROM queryTests2 GROUP BY text1 HAVING SUM(number1)   10  OR  SELECT text1, SUM(\\${number1 * 10}) AS totals FROM queryTests2 GROUP BY text1 HAVING totals   1000", 
            "title": "HAVING"
        }, 
        {
            "location": "/Reference/pql/#escaping", 
            "text": "Repositories MUST support the escaping of characters using a backslash  \\  in the query statement.  The backslash character  \\  will be used to escape characters within quoted strings in the query as follows:   \\\u2019 will represent a single-quote(\u2018) character  \\ \\ will represent a backslash  \\  character  Within a LIKE string,  \\%  and  \\_  will represent the literal characters % and _, respectively.  All other instances of a \\ are errors.", 
            "title": "Escaping"
        }, 
        {
            "location": "/Reference/pql/#virtual-data-sources", 
            "text": "FROM '@{VirtualDataSource}", 
            "title": "Virtual Data Sources"
        }, 
        {
            "location": "/Reference/pql/#workflowhistory", 
            "text": "The workflow history virtual data source will return details about the unassigned and human tasks of a one or more documents e.g.   SELECT * FROM '@WorkflowHistory' WHERE docId = 1  Will return the following special columns:     Column Name  Description      allocation  The final user allocated    createdBy  Who the allocation was created by. This is not the creator of the document.    position  The workflow label of the task    duration  The duration of the task e.g. 12 hours    businessDuration  The duration of the task while in business hours e.g. 2 hours    start  The start date of the task    end  The end date of the task    durationMillis  The duration of the task in milliseconds     Any standard and custom indexes can also be merged into the results by adding them into the column list.\nAny standard search criteria can also be used", 
            "title": "@WorkflowHistory"
        }, 
        {
            "location": "/Reference/pql/#activity", 
            "text": "Returns:    Document creations   New Notes   Audits of configurable type = defaulting to Check In, Forward, Delete    SELECT * FROM @Activity WHERE Node = 'Finance' AND user = 'X'   equivalent to:   SELECT * FROM @Activity/Finance WHERE user = 'X'   date  is used for searching on the activity date (not the date of the document)  SELECT * FROM @Activity WHERE date = '-7d'", 
            "title": "@Activity"
        }, 
        {
            "location": "/Reference/pql/#queuehistory", 
            "text": "", 
            "title": "@QueueHistory"
        }, 
        {
            "location": "/Reference/regex/", 
            "text": "Regular Expressions\n\n\nA regular expression is an expression (character string) that is used to match patterns in text.\n\n\nYou can use a regular expression to do these things:\n\n1. Extract indexes from the body of a document.\n\n2. Extract indexes from the filename of a document.\n\n3. Make sure that node indexes are correct. For example, make sure that an e-mail address or a phone number has the correct structure.  \n\n\nYou can use all the regular expressions \nhere\n. \n\n\nAdditionally, you can use a named capturing group.\n\n\nFor information about regular expressions, refer to \nRegexLib\n.\n\n\nExamples of Regular Expression\n\n\nSimple email validation\n\n\n[\\w-]+@([\\w-]+\\.)+[\\w-]+\n\n\n\n\nMatches: test@example.com\n\nMatches: test@example.c\n\nDoes not match: test@exa$mple.com  \n\n\nAdvanced Email Validation\n\n\n^[A-Za-z0-9._%+-]+@([A-Za-z0-9-_]+\\.)+[A-Za-z]{2,6}$\n\n\n\n\nMatches: test@example.com (and the e-mail address must be at the start of a line)\n\nDoes not match: test@example.c\n\nDoes not match: test@exa$mple.com  \n\n\nPhone number, style 1\n\n\n[0]\\d{2}-\\d{7}\n\n\n\n\nMatches: 011-8804411\n\nDoes not match: 011-880 4411  \n\n\nPhone number, style 2\n\n\n^\\([0]\\d{2}\\)\\d{7}\n\n\n\n\nMatches: (011)8804411 (and the phone number must be at the start of a line)\n\nDoes not match: (011) 880 4411\n\nDoes not match: (0118)804411  \n\n\nSouth African ID\n\n\n(((\\d{2}((0[13578]|1[02])(0[1-9]|[12]\\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\\d|30)|02(0[1-9]|1\\d|2[0-8])))|([02468][048]|[13579][26])0229))(( |-)(\\d{4})( |-)(\\d{3})|(\\d{7}))\n\n\n\n\nMatches: 8001015009087\n\nDoes not match: d001015009087  \n\n\nRefer \nNational Identification Number\n.", 
            "title": "Regex"
        }, 
        {
            "location": "/Reference/regex/#regular-expressions", 
            "text": "A regular expression is an expression (character string) that is used to match patterns in text.  You can use a regular expression to do these things: \n1. Extract indexes from the body of a document. \n2. Extract indexes from the filename of a document. \n3. Make sure that node indexes are correct. For example, make sure that an e-mail address or a phone number has the correct structure.    You can use all the regular expressions  here .   Additionally, you can use a named capturing group.  For information about regular expressions, refer to  RegexLib .", 
            "title": "Regular Expressions"
        }, 
        {
            "location": "/Reference/regex/#examples-of-regular-expression", 
            "text": "", 
            "title": "Examples of Regular Expression"
        }, 
        {
            "location": "/Reference/regex/#simple-email-validation", 
            "text": "[\\w-]+@([\\w-]+\\.)+[\\w-]+  Matches: test@example.com \nMatches: test@example.c \nDoes not match: test@exa$mple.com", 
            "title": "Simple email validation"
        }, 
        {
            "location": "/Reference/regex/#advanced-email-validation", 
            "text": "^[A-Za-z0-9._%+-]+@([A-Za-z0-9-_]+\\.)+[A-Za-z]{2,6}$  Matches: test@example.com (and the e-mail address must be at the start of a line) \nDoes not match: test@example.c \nDoes not match: test@exa$mple.com", 
            "title": "Advanced Email Validation"
        }, 
        {
            "location": "/Reference/regex/#phone-number-style-1", 
            "text": "[0]\\d{2}-\\d{7}  Matches: 011-8804411 \nDoes not match: 011-880 4411", 
            "title": "Phone number, style 1"
        }, 
        {
            "location": "/Reference/regex/#phone-number-style-2", 
            "text": "^\\([0]\\d{2}\\)\\d{7}  Matches: (011)8804411 (and the phone number must be at the start of a line) \nDoes not match: (011) 880 4411 \nDoes not match: (0118)804411", 
            "title": "Phone number, style 2"
        }, 
        {
            "location": "/Reference/regex/#south-african-id", 
            "text": "(((\\d{2}((0[13578]|1[02])(0[1-9]|[12]\\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\\d|30)|02(0[1-9]|1\\d|2[0-8])))|([02468][048]|[13579][26])0229))(( |-)(\\d{4})( |-)(\\d{3})|(\\d{7}))  Matches: 8001015009087 \nDoes not match: d001015009087    Refer  National Identification Number .", 
            "title": "South African ID"
        }, 
        {
            "location": "/Reference/standard_expression/", 
            "text": "Standard Expressions\n\n\nExpressions allow for values to be substituted at runtime. As an example of how expression values are substituted, if you are given a document with the following index values:\n\n\ncreatedDate = 2009-03-15  \nfilename = test.doc  \ntitle = sample title  \ndocid = 123  \n\n\n\n\nIf the basic syntax is \n${lookup?defaultValue:format}\n then this is how you would read the expression results using the values in the table in Document properties / indexes on page :\n\n\n\n\n\n\n\n\nStandard Expression\n\n\nOutput\n\n\n\n\n\n\n\n\n\n\n${createdDate:yyyy}\n\n\n2009\n\n\n\n\n\n\n${createdDate:yyyy-MM-dd}\n\n\n2009-13-15\n\n\n\n\n\n\n${createdDate:yyyyMM}\n\n\n200903\n\n\n\n\n\n\n${filename} - ${title} ($docid})\n\n\ntest.doc - sample (123)\n\n\n\n\n\n\n\n\nCustom Scripts\n\n\nCustom Groovy code can also be used e.g. to return the first 3 chars of a filename\n\n\n${filename.toLowerCase()[0..3]}\n\n\n\n\nSee \nGroovy JDK\n\n\n\n\nNote that due to the \n?\n and \n:\n being used to format values they cannot be used in code e.g. \n\n\n\n\ne.g. \n'${index1 == 'val' ? 'yes' : 'no }\n will not work, use \n${ if (index1 == 'val') then 'yes' else 'no' }\n\n\nSee \nDocument Properties\n for a full list of fields available.", 
            "title": "Standard expression"
        }, 
        {
            "location": "/Reference/standard_expression/#standard-expressions", 
            "text": "Expressions allow for values to be substituted at runtime. As an example of how expression values are substituted, if you are given a document with the following index values:  createdDate = 2009-03-15  \nfilename = test.doc  \ntitle = sample title  \ndocid = 123    If the basic syntax is  ${lookup?defaultValue:format}  then this is how you would read the expression results using the values in the table in Document properties / indexes on page :     Standard Expression  Output      ${createdDate:yyyy}  2009    ${createdDate:yyyy-MM-dd}  2009-13-15    ${createdDate:yyyyMM}  200903    ${filename} - ${title} ($docid})  test.doc - sample (123)", 
            "title": "Standard Expressions"
        }, 
        {
            "location": "/Reference/standard_expression/#custom-scripts", 
            "text": "Custom Groovy code can also be used e.g. to return the first 3 chars of a filename  ${filename.toLowerCase()[0..3]}  See  Groovy JDK   Note that due to the  ?  and  :  being used to format values they cannot be used in code e.g.    e.g.  '${index1 == 'val' ? 'yes' : 'no }  will not work, use  ${ if (index1 == 'val') then 'yes' else 'no' }  See  Document Properties  for a full list of fields available.", 
            "title": "Custom Scripts"
        }, 
        {
            "location": "/Troubleshooting/Performance/", 
            "text": "Performance\n\n\nCheck underlying system\n\n\n\n\nIs there enough memory? \u00a0There should always be at least 1 - 2GB\n    free memory in production to avoid using swap space\n\n\nIs CPU Usage high? Then check the\u00a0\nCPU Usage guide\n\n\nCheck network performance via ICMP ping and Browser developer tools\n    network tab - Response times of \n 250ms are good and \n 1s are\n    acceptable.\n\n\nCheck the following resources for identifying lower level\n    bottlenecks.\n\n        -   \nhttp://www.brendangregg.com/usemethod.html\n\n        -   \nhttp://www.brendangregg.com/linuxperf.html\n\n        -   \nhttp://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html", 
            "title": "Performance"
        }, 
        {
            "location": "/Troubleshooting/Performance/#performance", 
            "text": "", 
            "title": "Performance"
        }, 
        {
            "location": "/Troubleshooting/Performance/#check-underlying-system", 
            "text": "Is there enough memory? \u00a0There should always be at least 1 - 2GB\n    free memory in production to avoid using swap space  Is CPU Usage high? Then check the\u00a0 CPU Usage guide  Check network performance via ICMP ping and Browser developer tools\n    network tab - Response times of   250ms are good and   1s are\n    acceptable.  Check the following resources for identifying lower level\n    bottlenecks. \n        -    http://www.brendangregg.com/usemethod.html \n        -    http://www.brendangregg.com/linuxperf.html \n        -    http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html", 
            "title": "Check underlying system"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Client/", 
            "text": "Troubleshooting Server\n\n\nIsolate the Problem\n\n\n\n\nSolve the Problem\n\n\nTo solve the problem, we will need to collect the following.\n\n\n\n\nIsolate the cause : Browser version, release, etc.  \n\n\nReproducible environment . \n\n\nVersions of Browser, server etc.\n\n\nScreenshots of the issue.\n\n\nFiddler Logs.\n\n\nBrowser error logs.", 
            "title": "Troubleshooting Client"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Client/#troubleshooting-server", 
            "text": "", 
            "title": "Troubleshooting Server"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Client/#isolate-the-problem", 
            "text": "", 
            "title": "Isolate the Problem"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Client/#solve-the-problem", 
            "text": "To solve the problem, we will need to collect the following.   Isolate the cause : Browser version, release, etc.    Reproducible environment .   Versions of Browser, server etc.  Screenshots of the issue.  Fiddler Logs.  Browser error logs.", 
            "title": "Solve the Problem"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/", 
            "text": "Troubleshooting Server\n\n\nIsolate the Problem\n\n\n\n\nSolve the Problem\n\n\n\n\nStart with the client and release.  \n\n\nEnsure that all the steps are followed.  \n\n\nInclude any information used in troubleshooting logs, release testing etc that may help identifying the issue.  \n\n\nAny error must be accompanied by the corresponding log entry.  \n\n\nCheck the knowledge base first.  \n\n\nAsk for help in the Support Room only.  \n\n\nAdd knowledge base article.  \n\n\n\n\nLog Levels\n\n\nTo increase the log levels, navigate to  \nServices -\n Logging\n in PT Admin UI.  \n\n\n\n\nSelect the \nappropriate log level\n and click \nUpdate\n.  \n\n\nSelect the log level: \nTRACE = highest amount of information\n, \nERROR = Lowest amount of info\n.  \n\n\nSelect whether the increased logging level should remain after restart. It is recommended to not keep DEBUG and TRACE levels for extended period.  \n\n\nClick \nUpdate\n. \n\n\n\n\nRebuilding Indexes\n\n\nTo rebuild all indexes, Navigate to \nServices -\n Tasks -\n Indexing\n  \n\n\n\n\nRun a \nRepair all indexes\n when the indexes are mostly complete and there is only some out of date data.  \n\n\nRun a \nRebuild all indexes\n, when there is no index data.  \n\n\n\n\nMessage Queues\n\n\nTo clear / restart message queues:  \n\n\n\n\nNavigate to \nServices-\nMessaging\n. Select the \nmessage queue\n and\n\n\nClick \nReprocess Failed/Dead\n to reprocess messages.  \n\n\nClick \nClear All\n to clear any messages out of the queue.  \n\n\n\n\n\n\nWARNING: this may produce unexpected results e.g. partial email delivery, failed conversions not being retried etc.\n\n\n\n\n\n\n\n\n\n\nLoggers\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIndexUpdate.replicate\n\n\nIndex replications queue\n\n\n\n\n\n\nIndexUpdater.update\n\n\nUpdates to the search indexes\n\n\n\n\n\n\nEmailNotifierImpl.sendQueued\n\n\nQueued email messages\n\n\n\n\n\n\nRule.generatePdf\n\n\nOffice -\n PDF and Flash conversions\n\n\n\n\n\n\nRule.*\n\n\nAny asynchronous rule invocation\n\n\n\n\n\n\nreplicate\n\n\nData replication\n\n\n\n\n\n\n.write\n\n\nFile replications and online cloud backups\n\n\n\n\n\n\n\n\nDebug Mode\n\n\nTo start PaperTrail in Debug Mode in Windows: \n\n*   Start the \nconsole_debug.exe\n command line app.  \n\n\nTo start PaperTrail in Debug Mode in Linux: \n\n*   Add the following to the \nrun.sh\n just after the java command:   \n\n\n-Xdebug  \n-Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n  \n// Ex : java -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n -Xms512m -Xmx512m -XX:MaxPermSize=196m -classpath $(echo ../build/*.jar ../libs/*.jar . | sed 's/ /:/g'):conf com.egis.Startup\n\n\n\n\nRunning Jobs\n\n\nAny long running job will be listed under \nServices -\n Jobs\n. These include:  \n\n\n\n\nScheduled Rules.  \n\n\nIndex Repairs / Rebuilds.  \n\n\nFile Store Repairs.  \n\n\nDatabase Backups / Restores.  \n\n\n\n\nFailure to Start\n\n\nIf PaperTrail fails to start, follow these steps :  \n\n\n\n\nCheck that \nJava is installed\n and no other service is listening on the default port.  \n\n\nVerify that the \ndatabase is up\n and \naccepting connections from the configured user/password\n.  \n\n\nVerify that user, service run as user \nhas appropriate permissions to read and write to all directories\n in the installation directory.  \n\n\nReview the log files under logs - specifically \nerror.log, output.log, server.log\n.  \n\n\n\n\nLow Performance\n\n\n\n\nCheck the \nmemory usage\n. Take a snapshot and review the vminfo.txt file, the total GC time should be \nbelow 1% of uptime\n. If the total GC time is higher, it indicates that the \nheap space should be increased\n.  \n\n\nIf running on a \nvirtualization platform\n, ensure the host has enough resources.  \n\n\nCheck to ensure that there is enough \nIO capacity for the application\n.  \n\n\nVerify that \n3rd party application\n is not utilizing CPU, RAM and IO resources.  \n\n\nVerify that the Database has \nenough RAM and IO capacity\n.  \n\n\nVerify that \ndatabase indexes are created\n and statistics are up to date.  \n\n\nReview thread dump at \nhttp://host:8080/snapshot/threads\n for threads with high CPU usage.  \n\n\nVerify best practices.  \n\n\n\n\nChecking log files\n\n\n\n\nGo to \nhttp://host:8080/web/admin/log.html\n.  \n\n\nTake a snapshot \nhttp://host/snapshot\n.  \n\n\n\n\nRules debugging\n\n\nIf you expect some rule to be applied to created/updated/deleted document and it doesn't it's probably because that \ndocument doesn't get covered by rule's source conditions. \n\n\nTo see if that's the case, set \ncom.egis.index.query\n to DEBUG - see how in \nLog Levels\n section. \nThen you'll see the SQL queries and their result set counts in log console.", 
            "title": "Troubleshooting Server"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#troubleshooting-server", 
            "text": "", 
            "title": "Troubleshooting Server"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#isolate-the-problem", 
            "text": "", 
            "title": "Isolate the Problem"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#solve-the-problem", 
            "text": "Start with the client and release.    Ensure that all the steps are followed.    Include any information used in troubleshooting logs, release testing etc that may help identifying the issue.    Any error must be accompanied by the corresponding log entry.    Check the knowledge base first.    Ask for help in the Support Room only.    Add knowledge base article.", 
            "title": "Solve the Problem"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#log-levels", 
            "text": "To increase the log levels, navigate to   Services -  Logging  in PT Admin UI.     Select the  appropriate log level  and click  Update .    Select the log level:  TRACE = highest amount of information ,  ERROR = Lowest amount of info .    Select whether the increased logging level should remain after restart. It is recommended to not keep DEBUG and TRACE levels for extended period.    Click  Update .", 
            "title": "Log Levels"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#rebuilding-indexes", 
            "text": "To rebuild all indexes, Navigate to  Services -  Tasks -  Indexing      Run a  Repair all indexes  when the indexes are mostly complete and there is only some out of date data.    Run a  Rebuild all indexes , when there is no index data.", 
            "title": "Rebuilding Indexes"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#message-queues", 
            "text": "To clear / restart message queues:     Navigate to  Services- Messaging . Select the  message queue  and  Click  Reprocess Failed/Dead  to reprocess messages.    Click  Clear All  to clear any messages out of the queue.      WARNING: this may produce unexpected results e.g. partial email delivery, failed conversions not being retried etc.      Loggers  Description      IndexUpdate.replicate  Index replications queue    IndexUpdater.update  Updates to the search indexes    EmailNotifierImpl.sendQueued  Queued email messages    Rule.generatePdf  Office -  PDF and Flash conversions    Rule.*  Any asynchronous rule invocation    replicate  Data replication    .write  File replications and online cloud backups", 
            "title": "Message Queues"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#debug-mode", 
            "text": "To start PaperTrail in Debug Mode in Windows:  \n*   Start the  console_debug.exe  command line app.    To start PaperTrail in Debug Mode in Linux:  \n*   Add the following to the  run.sh  just after the java command:     -Xdebug  \n-Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n  \n// Ex : java -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n -Xms512m -Xmx512m -XX:MaxPermSize=196m -classpath $(echo ../build/*.jar ../libs/*.jar . | sed 's/ /:/g'):conf com.egis.Startup", 
            "title": "Debug Mode"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#running-jobs", 
            "text": "Any long running job will be listed under  Services -  Jobs . These include:     Scheduled Rules.    Index Repairs / Rebuilds.    File Store Repairs.    Database Backups / Restores.", 
            "title": "Running Jobs"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#failure-to-start", 
            "text": "If PaperTrail fails to start, follow these steps :     Check that  Java is installed  and no other service is listening on the default port.    Verify that the  database is up  and  accepting connections from the configured user/password .    Verify that user, service run as user  has appropriate permissions to read and write to all directories  in the installation directory.    Review the log files under logs - specifically  error.log, output.log, server.log .", 
            "title": "Failure to Start"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#low-performance", 
            "text": "Check the  memory usage . Take a snapshot and review the vminfo.txt file, the total GC time should be  below 1% of uptime . If the total GC time is higher, it indicates that the  heap space should be increased .    If running on a  virtualization platform , ensure the host has enough resources.    Check to ensure that there is enough  IO capacity for the application .    Verify that  3rd party application  is not utilizing CPU, RAM and IO resources.    Verify that the Database has  enough RAM and IO capacity .    Verify that  database indexes are created  and statistics are up to date.    Review thread dump at  http://host:8080/snapshot/threads  for threads with high CPU usage.    Verify best practices.", 
            "title": "Low Performance"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#checking-log-files", 
            "text": "Go to  http://host:8080/web/admin/log.html .    Take a snapshot  http://host/snapshot .", 
            "title": "Checking log files"
        }, 
        {
            "location": "/Troubleshooting/Troubleshooting Server/#rules-debugging", 
            "text": "If you expect some rule to be applied to created/updated/deleted document and it doesn't it's probably because that \ndocument doesn't get covered by rule's source conditions.   To see if that's the case, set  com.egis.index.query  to DEBUG - see how in  Log Levels  section. \nThen you'll see the SQL queries and their result set counts in log console.", 
            "title": "Rules debugging"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/", 
            "text": "Troubleshooting High CPU usage\n\n\nBefore doing anything else\n\n\nBefore restarting PaperTrail always try and get a snapshot:\n\n\nhttp://localhost:8080/snapshot\n  \n\n\nand/or a thread dump  \n\n\nhttp://localhost:8080/snapshot/threads\n\n\nIf the web interface is unresponsive, use the command line to retrieve a\nthread dump.\n\n\nOn Linux: \n/etc/init.d/papertrail heap\n\nOn Windows: In \n, \u00a0Run \njps\n to get the PID of the service and then \njstack\u00a0-dump:format=b,file=C:\\heap.bin \u00a0\nPID\n\n\nCommon Causes of high CPU usage\n\n\nIf a single CPU core is at 100%, the culprit would normally be single thread that reoccurs in every single thread dump.\n\n\nIf all CPU cores are at 100% or near 100%, the cause is either:\n\n\na) memory exhaustion - very little free memory,\u00a0 \njstat\n \u00a0would return\nvery high garbage collection times (GC)\n\nb) an endless loop\n\nc) too many worker threads and/or too few cores\n \u00a0\n\n\nAnalyzing a Thread Dump\n\n\nAnalyzing a thread dump involves looking through all the threads on the\nrunning system to identify a pattern.\n\n\n\n\n\n\nAny thread in a \nTIMED_WAITING\n or \nWAITING\n state can be safely ignored\nas these threads are sleeping waiting for something else to occur.\n\n\n\n\n\n\nJetty threads in the\u00a0\njava.net.SocketInputStream.socketRead RUNNING\nstate can also be ignored as they are waiting for a client to make a TCP/IP connection", 
            "title": "Cpu usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#troubleshooting-high-cpu-usage", 
            "text": "", 
            "title": "Troubleshooting High CPU usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#before-doing-anything-else", 
            "text": "Before restarting PaperTrail always try and get a snapshot:  http://localhost:8080/snapshot     and/or a thread dump    http://localhost:8080/snapshot/threads  If the web interface is unresponsive, use the command line to retrieve a\nthread dump.  On Linux:  /etc/init.d/papertrail heap \nOn Windows: In  , \u00a0Run  jps  to get the PID of the service and then  jstack\u00a0-dump:format=b,file=C:\\heap.bin \u00a0 PID", 
            "title": "Before doing anything else"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#common-causes-of-high-cpu-usage", 
            "text": "If a single CPU core is at 100%, the culprit would normally be single thread that reoccurs in every single thread dump.  If all CPU cores are at 100% or near 100%, the cause is either:  a) memory exhaustion - very little free memory,\u00a0  jstat  \u00a0would return\nvery high garbage collection times (GC) \nb) an endless loop \nc) too many worker threads and/or too few cores", 
            "title": "Common Causes of high CPU usage"
        }, 
        {
            "location": "/Troubleshooting/cpu-usage/#analyzing-a-thread-dump", 
            "text": "Analyzing a thread dump involves looking through all the threads on the\nrunning system to identify a pattern.    Any thread in a  TIMED_WAITING  or  WAITING  state can be safely ignored\nas these threads are sleeping waiting for something else to occur.    Jetty threads in the\u00a0 java.net.SocketInputStream.socketRead RUNNING state can also be ignored as they are waiting for a client to make a TCP/IP connection", 
            "title": "Analyzing a Thread Dump"
        }, 
        {
            "location": "/Troubleshooting/db-tuning/", 
            "text": "Database Performance Tuning\n\n\n\n\nUse READ COMMITTED default tx isolation level.\n\n\nUse a transaction logging mode that allows point in time recovery\n    (PITR) if possible\n\n\n\n\nRecommended PostgreSQL Settings\n\n\nmax_connections = 300 shared_buffers =\u00a01GB\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0# increase based on db and RAM size \ntemp_buffers = 1GB\u00a0\u00a0# increase based on db and RAM size \nmax_prepared_transactions = 0 \nwork_mem = 4MB \nmaintenance_work_mem = 512MB\neffective_io_concurrency = 4\u00a0\u00a0 \u00a0 \nwal_level = archive\u00a0\u00a0 \u00a0# allows PITR and restore \nfsync = on\u00a0\u00a0 # setting it to off can boost performance at the risk of full db corruption\nsynchronous_commit = on \u00a0# can be safely set to off full_page_writes = on\n\n\n\n\nRecommended MySQL Settings\n\n\ncharacter-set-server=utf8\ndefault-character-set=utf8\ndefault-storage-engine=INNODB\nmax_connections=800\n\n# 0 = log and flush once per second, set sync_binlog=2 # 2 = log on commit and flush once per second, set sync_binlog=2 \ninnodb_flush_log_at_trx_commit=1\u00a0 \nsync_binlog=1  \n\n# increase based on db size and RAM \ninnodb_buffer_pool_size=1G \ntx_isolation=READ-COMMITTED\nbinlog-format=ROW  \ntmp_table_size=64M \ninnodb_log_file_size=500M \nmax_allowed_packet=4M  \ninnodb_thread_concurrency=10 # make buffer pool instances roughly equal the size of the pool in GB's e.g. for an 8GB pool use: #innodb_buffer_pool_instances=8 \n\n# disable query cache \nquery_cache_size=0 \nquery_cache_type=0 \nthread_cache_size=10", 
            "title": "Db tuning"
        }, 
        {
            "location": "/Troubleshooting/db-tuning/#database-performance-tuning", 
            "text": "Use READ COMMITTED default tx isolation level.  Use a transaction logging mode that allows point in time recovery\n    (PITR) if possible", 
            "title": "Database Performance Tuning"
        }, 
        {
            "location": "/Troubleshooting/db-tuning/#recommended-postgresql-settings", 
            "text": "max_connections = 300 shared_buffers =\u00a01GB\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0# increase based on db and RAM size \ntemp_buffers = 1GB\u00a0\u00a0# increase based on db and RAM size \nmax_prepared_transactions = 0 \nwork_mem = 4MB \nmaintenance_work_mem = 512MB\neffective_io_concurrency = 4\u00a0\u00a0 \u00a0 \nwal_level = archive\u00a0\u00a0 \u00a0# allows PITR and restore \nfsync = on\u00a0\u00a0 # setting it to off can boost performance at the risk of full db corruption\nsynchronous_commit = on \u00a0# can be safely set to off full_page_writes = on", 
            "title": "Recommended PostgreSQL Settings"
        }, 
        {
            "location": "/Troubleshooting/db-tuning/#recommended-mysql-settings", 
            "text": "character-set-server=utf8\ndefault-character-set=utf8\ndefault-storage-engine=INNODB\nmax_connections=800\n\n# 0 = log and flush once per second, set sync_binlog=2 # 2 = log on commit and flush once per second, set sync_binlog=2 \ninnodb_flush_log_at_trx_commit=1\u00a0 \nsync_binlog=1  \n\n# increase based on db size and RAM \ninnodb_buffer_pool_size=1G \ntx_isolation=READ-COMMITTED\nbinlog-format=ROW  \ntmp_table_size=64M \ninnodb_log_file_size=500M \nmax_allowed_packet=4M  \ninnodb_thread_concurrency=10 # make buffer pool instances roughly equal the size of the pool in GB's e.g. for an 8GB pool use: #innodb_buffer_pool_instances=8 \n\n# disable query cache \nquery_cache_size=0 \nquery_cache_type=0 \nthread_cache_size=10", 
            "title": "Recommended MySQL Settings"
        }, 
        {
            "location": "/Troubleshooting/exceptions/", 
            "text": "Exceptions\n\n\nSystem cannot find the file specified\n\n\njava.io.IOException: Cannot run program \"pg\\_dump\": CreateProcess\nerror=2\n\nReason :\u00a0The system cannot find the file specified\n\nSolution : Add the Postgresql/bin directory to the System PATH environment variable\n\n\nSystem cannot find the file specified\n\n\njava.io.IOException: Cannot run program \"mysql\\_dump\"\n\nReason : The system cannot find the file specified\n\nSolution : Add the MySQL/bin directory to the System PATH environment variable\n \u00a0\n\n\nDatabase connection Pool exhausted\n\n\nJDBCExceptionReporter [:] Cannot get a connection, pool error Timeout\nwaiting for idle object Database connection pool is exhausted,\n  \n\n\nSolution : \n\n-  Check for database connection leak warning messages in the log files\nbeforehand\n\n-  Check database lookup configurations\n\n\n\n\nPermission denied\n\n\nfailed \nSocketConnector@0.0.0.0\n:80:\n[java.net](http://java.net/).BindException: Permission denied\n\n\nSolution : To run PaperTrail on port 80 you need to be root, change http.port=8080", 
            "title": "Exceptions"
        }, 
        {
            "location": "/Troubleshooting/exceptions/#exceptions", 
            "text": "", 
            "title": "Exceptions"
        }, 
        {
            "location": "/Troubleshooting/exceptions/#system-cannot-find-the-file-specified", 
            "text": "java.io.IOException: Cannot run program \"pg\\_dump\": CreateProcess\nerror=2 \nReason :\u00a0The system cannot find the file specified \nSolution : Add the Postgresql/bin directory to the System PATH environment variable", 
            "title": "System cannot find the file specified"
        }, 
        {
            "location": "/Troubleshooting/exceptions/#system-cannot-find-the-file-specified_1", 
            "text": "java.io.IOException: Cannot run program \"mysql\\_dump\" \nReason : The system cannot find the file specified \nSolution : Add the MySQL/bin directory to the System PATH environment variable", 
            "title": "System cannot find the file specified"
        }, 
        {
            "location": "/Troubleshooting/exceptions/#database-connection-pool-exhausted", 
            "text": "JDBCExceptionReporter [:] Cannot get a connection, pool error Timeout\nwaiting for idle object Database connection pool is exhausted,     Solution :  \n-  Check for database connection leak warning messages in the log files\nbeforehand \n-  Check database lookup configurations", 
            "title": "Database connection Pool exhausted"
        }, 
        {
            "location": "/Troubleshooting/exceptions/#permission-denied", 
            "text": "failed  SocketConnector@0.0.0.0 :80:\n[java.net](http://java.net/).BindException: Permission denied  Solution : To run PaperTrail on port 80 you need to be root, change http.port=8080", 
            "title": "Permission denied"
        }
    ]
}